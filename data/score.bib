
@article{10.1093/biosci/biw159,
  title = {Metaresearch for Evaluating Reproducibility in Ecology and Evolution},
  author = {Fidler, Fiona and Chee, Yung En and Wintle, Bonnie C. and Burgman, Mark A. and McCarthy, Michael A. and Gordon, Ascelin},
  year = {2017},
  month = jan,
  journal = {BioScience},
  volume = {67},
  number = {3},
  eprint = {https://academic.oup.com/bioscience/article-pdf/67/3/282/10803757/biw159.pdf},
  pages = {282--289},
  issn = {0006-3568},
  doi = {10.1093/biosci/biw159},
  abstract = {Recent replication projects in other disciplines have uncovered disturbingly low levels of reproducibility, suggesting that those research literatures may contain unverifiable claims. The conditions contributing to irreproducibility in other disciplines are also present in ecology. These include a large discrepancy between the proportion of ``positive'' or ``significant'' results and the average statistical power of empirical research, incomplete reporting of sampling stopping rules and results, journal policies that discourage replication studies, and a prevailing publish-or-perish research culture that encourages questionable research practices. We argue that these conditions constitute sufficient reason to systematically evaluate the reproducibility of the evidence base in ecology and evolution. In some cases, the direct replication of ecological research is difficult because of strong temporal and spatial dependencies, so here, we propose metaresearch projects that will provide proxy measures of reproducibility.},
  file = {/Users/awwillc/Zotero/storage/VRVX4T6S/Fidler et al. - 2017 - Metaresearch for evaluating reproducibility in eco.pdf}
}

@article{10.1145/2723872.2723882,
  title = {An Introduction to Docker for Reproducible Research},
  author = {Boettiger, Carl},
  year = {2015},
  month = jan,
  journal = {SIGOPS Oper. Syst. Rev.},
  volume = {49},
  number = {1},
  pages = {71--79},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  issn = {0163-5980},
  doi = {10/gdz6f9},
  abstract = {As computational work becomes more and more integral to many aspects of scientific research, computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments, the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper, I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues, including virtual machines and workflow systems, and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization, cross-platform portability, modular re-usable elements, versioning, and a 'DevOps' philosophy, to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.},
  issue_date = {January 2015},
  file = {/Users/awwillc/Zotero/storage/6L8J7VTA/Boettiger - 2015 - An introduction to docker for reproducible researc.pdf}
}

@inproceedings{10.1145/3322790.3330595,
  title = {Scientific Tests and Continuous Integration Strategies to Enhance Reproducibility in the Scientific Software Context},
  booktitle = {Proceedings of the 2nd International Workshop on Practical Reproducible Evaluation of Computer Systems},
  author = {Krafczyk, Matthew and Shi, August and Bhaskar, Adhithya and Marinov, Darko and Stodden, Victoria},
  year = {2019},
  series = {P-Recs '19},
  pages = {23--28},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10/ghv259},
  abstract = {Continuous integration (CI) is a well-established technique in commercial and open-source software projects, although not routinely used in scientific publishing. In the scientific software context, CI can serve two functions to increase reproducibility of scientific results: providing an established platform for testing the reproducibility of these results, and demonstrating to other scientists how the code and data generate the published results. We explore scientific software testing and CI strategies using two articles published in the areas of applied mathematics and computational physics. We discuss lessons learned from reproducing these articles as well as examine and discuss existing tests. We introduce the notion of a "scientific test" as one that produces computational results from a published article. We then consider full result reproduction within a CI environment. If authors find their work too time or resource intensive to easily adapt to a CI context, we recommend the inclusion of results from reduced versions of their work (e.g., run at lower resolution, with shorter time scales, with smaller data sets) alongside their primary results within their article. While these smaller versions may be less interesting scientifically, they can serve to verify that published code and data are working properly. We demonstrate such reduction tests on the two articles studied.},
  isbn = {978-1-4503-6756-1},
  keywords = {continuous integration,reproducibility,scientific software,software reliability,software testing}
}

@inproceedings{10.1145/3377814.3381711,
  title = {Understanding Devops Education with Grounded Theory},
  booktitle = {Proceedings of the {{ACM}}/{{IEEE}} 42nd International Conference on Software Engineering: {{Software}} Engineering Education and Training},
  author = {Pang, Candy and Hindle, Abram and Barbosa, Denilson},
  year = {2020},
  series = {{{ICSE}}-{{SEET}} '20},
  pages = {107--118},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10/gj32q3},
  abstract = {DevOps stands for Development-Operations. It arises from the IT industry as a movement aligning development and operations teams. DevOps is broadly recognized as an IT standard, and there is high demand for DevOps practitioners in industry. Since ACM \&amp; IEEE suggest that undergraduate computer science curricula "must adequately prepare [students] for the workforce", we studied whether undergraduates acquired adequate DevOps skills to fulfill the demand for DevOps practitioners in industry. We employed Grounded Theory (GT), a social science qualitative research methodology, to study DevOps education from academic and industrial perspectives. In academia, academics were not motivated to learn or adopt DevOps, and we did not find strong evidence of academics teaching DevOps. Academics need incentives to adopt DevOps, in order to stimulate interest in teaching DevOps. In industry, DevOps practitioners lack clearly defined roles and responsibilities, for the DevOps topic is diverse and growing too fast. Therefore, practitioners can only learn DevOps through hands-on working experience. As a result, academic institutions should provide fundamental DevOps education (in culture, procedure, and technology) to prepare students for their future DevOps advancement in industry. Based on our findings, we proposed five groups of future studies to advance DevOps education in academia.},
  isbn = {978-1-4503-7124-7},
  keywords = {continuous delivery,continuous integration,devops,education,grounded theory,software engineering},
  file = {/Users/awwillc/Zotero/storage/8EFC6XG2/Pang et al. - 2020 - Understanding devops education with grounded theor.pdf}
}

@inproceedings{10.1145/3391800.3398173,
  title = {Advancing Computational Reproducibility in the Dataverse Data Repository Platform},
  booktitle = {Proceedings of the 3rd International Workshop on Practical Reproducible Evaluation of Computer Systems},
  author = {Trisovic, Ana and Durbin, Philip and Schlatter, Tania and Durand, Gustavo and Barbosa, Sonia and Brooke, Danny and Crosas, Merc{\`e}},
  year = {2020},
  series = {P-Recs '20},
  pages = {15--20},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10/gh29zz},
  abstract = {Recent reproducibility case studies have raised concerns showing that much of the deposited research has not been reproducible. One of their conclusions was that the way data repositories store research data and code cannot fully facilitate reproducibility due to the absence of a runtime environment needed for the code execution. New specialized reproducibility tools provide cloud-based computational environments for code encapsulation, thus enabling research portability and reproducibility. However, they do not often enable research discoverability, standardized data citation, or long-term archival like data repositories do. This paper addresses the shortcomings of data repositories and reproducibility tools and how they could be overcome to improve the current lack of computational reproducibility in published and archived research outputs.},
  isbn = {978-1-4503-7977-9},
  keywords = {computational reproducibility,data management,data preservation,data repository,open code,open data},
  file = {/Users/awwillc/Zotero/storage/MVG93UU5/Trisovic et al. - 2020 - Advancing computational reproducibility in the dat.pdf}
}

@article{10.1371/journal.pcbi.1008316,
  title = {Ten Simple Rules for Writing {{Dockerfiles}} for Reproducible Data Science},
  author = {N{\"u}st, Daniel and Sochat, Vanessa and Marwick, Ben and Eglen, Stephen J. and Head, Tim and Hirst, Tony and Evans, Benjamin D.},
  year = {2020},
  month = nov,
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {11},
  pages = {1--24},
  publisher = {{Public Library of Science}},
  doi = {10.1371/journal.pcbi.1008316},
  abstract = {Computational science has been greatly improved by the use of containers for packaging software and data dependencies. In a scholarly context, the main drivers for using these containers are transparency and support of reproducibility; in turn, a workflow's reproducibility can be greatly affected by the choices that are made with respect to building containers. In many cases, the build process for the container's image is created from instructions provided in a Dockerfile format. In support of this approach, we present a set of rules to help researchers write understandable Dockerfiles for typical data science workflows. By following the rules in this article, researchers can create containers suitable for sharing with fellow scientists, for including in scholarly communication such as education or scientific papers, and for effective and sustainable personal workflows.},
  file = {/Users/awwillc/Zotero/storage/R3HL2XN6/Nüst et al. - 2020 - Ten simple rules for writing Dockerfiles for repro.pdf}
}

@article{AgileSoftwareDevelopment2020,
  title = {Agile Software Development},
  year = {2020},
  month = jun,
  journal = {Wikipedia},
  abstract = {In software development, agile (sometimes written Agile) approaches develop requirements and solutions through the collaborative effort of self-organizing and cross-functional teams and their customer(s)/end user(s). It advocates adaptive planning, evolutionary development, early delivery, and continual improvement, and it encourages flexible responses to change.It was popularized by the Manifesto for Agile Software Development. The values and principles espoused in this manifesto were derived from and underpin a broad range of software development frameworks, including Scrum and Kanban.While there is much anecdotal evidence that adopting agile practices and values improves the agility of software professionals, teams and organizations, some empirical studies have disputed that evidence.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  language = {en},
  annotation = {Page Version ID: 964890068},
  file = {/Users/awwillc/Zotero/storage/SZQMAL7J/index.html}
}

@article{agrawalDevopsNewApproach2019,
  title = {Devops, {{A New Approach To Cloud Development}} \& {{Testing}}},
  author = {Agrawal, Prashant and Rawat, Neelam},
  year = {2019},
  month = sep,
  journal = {2019 International Conference on Issues and Challenges in Intelligent Computing Techniques (ICICT), Issues and Challenges in Intelligent Computing Techniques (ICICT), 2019 International Conference on},
  volume = {1},
  pages = {1--4},
  issn = {978-1-7281-1772-0},
  doi = {10/ghkb9v},
  abstract = {Organization's proficiency to deliver services and applications at high velocity requires competing effectively in the market. The practices and tools for such management processes demands the quick and reliable model. Changes need to start at the software engineering level when building applications in the cloud, so there is a need to automate our DevOps processes using cloud and non-cloud DevOps automation tools. The aim of this paper is to move DevOps to Cloud and become more agile at software development and operations. In parallel, consideration of how to extend those DevOps process and automation into public and/or private clouds are the prime approach for this research. While investigating the emergence of DevOps, this paper paints it as a dramatic change in IT world for process improvement. Goal is to understand how the DevOps and Cloud work together to help businesses achieve their transformation goals.},
  keywords = {Agile,Cloud Computing,Cloud Development,Cloud Testing,Communication; Networking and Broadcast Technologies,Computing and Processing,DevOps,Engineering Profession,General Topics for Engineers},
  annotation = {mlzsync1:0036\{"extrafields":\{"publisher":"IEEE"\}\}}
}

@article{agungputrapasaribuPreliminaryStudyShifting2017,
  title = {A {{Preliminary Study}} on {{Shifting}} from {{Virtual Machine}} to {{Docker Container}} for {{Insilico Drug Discovery}} in the {{Cloud}}},
  author = {{Agung Putra Pasaribu} and {Muhammad Fajar Siddiq} and {Muhammad Irfan Fadhila} and {Muhammad H. Hilman} and {Arry Yanuar} and {Heru Suhartanto}},
  year = {2017},
  month = jul,
  journal = {International Journal of Technology},
  volume = {8},
  number = {4},
  pages = {611--621},
  issn = {2086-9614},
  doi = {10.14716/ijtech.v8i4.580},
  abstract = {The rapid growth of information technology and internet access has moved many offline activities online. Cloud computing is an easy and inexpensive solution, as supported by virtualization servers that allow easier access to personal computing resources. Unfortunately, current virtualization technology has some major disadvantages that can lead to suboptimal server performance. As a result, some companies have begun to move from virtual machines to containers. While containers are not new technology, their use has increased recently due to the Docker container platform product. Docker's features can provide easier solutions. In this work, insilico drug discovery applications from molecular modelling to virtual screening were tested to run in Docker. The results are very promising, as Docker beat the virtual machine in most tests and reduced the performance gap that exists when using a virtual machine (VirtualBox). The virtual machine placed third in test performance, after the host itself and Docker.},
  keywords = {⚠️ Invalid DOI,Cloud computing,Docker container,Molecular modeling,T1-995,Technology,Technology (General),Virtual screening},
  annotation = {mlzsync1:0053\{"extrafields":\{"publisher":"Universitas Indonesia"\}\}},
  file = {/Users/awwillc/Zotero/storage/G3WYFP83/Agung Putra Pasaribu et al. - 2017 - A Preliminary Study on Shifting from Virtual Machi.pdf}
}

@article{amaradriContinuousIntegrationDeployment2016,
  title = {Continuous {{Integration}}, {{Deployment}} and {{Testing}} in {{DevOps Environment}}},
  author = {Amaradri, Anand Srivatsav and Nutalapati, Swetha Bindu},
  year = {2016},
  month = jan,
  abstract = {Context. Owing to a multitude of factors like rapid changes in technology, market needs, and business competitiveness, software companies these days are facing pressure to deliver software rapidly and on a frequent basis. For frequent and faster delivery, companies should be lean and agile in all phases of the software development life cycle. An approach called DevOps, which is based on agile principles has come into play. DevOps bridges the gap between development and operations teams and facilitates faster product delivery. The DevOps phenomenon has gained a wide popularity in the past few years, and several companies are adopting DevOps to leverage its perceived benefits. However, the organizations may face several challenges while adopting DevOps. There is a need to obtain a clear understanding of how DevOps functions in an organization. Objectives. The main aim of this study is to provide a clear understanding about how DevOps works in an organization to researchers and software practitioners. The objectives of the study are to identify the benefits of implementing DevOps in organizations where agile development is in practice, the challenges faced by organizations during DevOps adoption, to identify the solutions/ mitigation strategies, to overcome the challenges,the DevOps practices, and the problems faced by DevOps teams during continuous integration, deployment and testing. Methods. A mixed methods approach having both qualitative and quantitative research methods is used to accomplish the research objectives.A Systematic Literature Review is conducted to identify the benefits and challenges of DevOps adoption, and the DevOps practices. Interviews are conducted to further validate the SLR findings, and identify the solutions to overcome DevOps adoption challenges, and the DevOps practices. The SLR and interview results are mapped, and a survey questionnaire is designed.The survey is conducted to validate the qualitative data, and to identify the other benefits and challenges of DevOps adoption, solutions to overcome the challenges, DevOps practices, and the problems faced by DevOps teams during continuous integration, deployment and testing. Results. 31 primary studies relevant to the research are identified for conducting the SLR. After analysing the primary studies, an initial list of the benefits and challenges of DevOps adoption, and the DevOps practices is obtained. Based on the SLR findings, a semi-structured interview questionnaire is designed, and interviews are conducted. The interview data is thematically coded, and a list of the benefits, challenges of DevOps adoption and solutions to overcome them, DevOps practices, and problems faced by DevOps teams is obtained. The survey responses are statistically analysed, and a final list of the benefits of adopting DevOps, the adoption challenges and solutions to overcome them, DevOps practices and problems faced by DevOps teams is obtained. Conclusions. Using the mixed methods approach, a final list of the benefits of adopting DevOps, DevOps adoption challenges, solutions to overcome the challenges, practices of DevOps, and the problems faced by DevOps teams during continuous integration, deployment and testing is obtained. The list is clearly elucidated in the document. The final list can aid researchers and software practitioners in obtaining a better understanding regarding the functioning and adoption of DevOps. Also, it has been observed that there is a need for more empirical research in this domain.},
  keywords = {⛔ No DOI found,benefits,challenges,development,DevOps,operations,practices,principles,software development}
}

@article{amritEffectivenessTestDrivenDevelopment2018,
  title = {Effectiveness of {{Test}}-{{Driven Development}} and {{Continuous Integration}}: {{A Case Study}}},
  author = {Amrit, Chintan and Meijberg, Yoni},
  year = {2018},
  month = jan,
  journal = {IT Professional, IT Prof.},
  volume = {20},
  number = {1},
  pages = {27--35},
  issn = {1520-9202},
  doi = {10/ghkb83},
  abstract = {In a case study where a Dutch small-to-medium enterprise (SME) implemented test-driven development and continuous integration, researchers observed that the SME discovered a higher number of defects compared to a baseline case study, and that there was an increase in the focus on quality and test applications.},
  keywords = {Components; Circuits; Devices and Systems,Computer bugs,Computing and Processing,continuous integration,Engineering Profession,Medical services,Performance evaluation,Power; Energy and Industry Applications,Productivity,SME,software,software development,Software measurement,Software quality,TDD,test applications,test driven development,Testing},
  annotation = {mlzsync1:0050\{"extrafields":\{"place":"USA","publisher":"IEEE"\}\}},
  file = {/Users/awwillc/Zotero/storage/UTJHRZT7/Amrit and Meijberg - 2018 - Effectiveness of Test-Driven Development and Conti.pdf}
}

@misc{amruthnathHowUseCI2020,
  title = {How to Use {{CI}}/{{CD}} for Your {{ML Projects}}?},
  author = {Amruthnath, Nagdev},
  year = {2020},
  month = aug,
  journal = {R-bloggers},
  abstract = {{$<$}div style = "width:60\%; display: inline-block; float:left; "{$>$}  The terms CI/CD stands for Continuous Integration and Continuous Delivery \textendash{} Deployment. Before we jump into how all these work, let's take a step back and walk through the process of ML. Most of the data scientists do their data analytics on their laptops. For every data analytics projects ...{$<$}/div{$><$}div style = "width: 40\%; display: inline-block; float:right;"{$><$}img src=' https://www.iamnagdev.com/wp-content/uploads/2020/08/git-1024x452.png' width = "200"  style = "padding: 10px;" /{$><$}/div{$><$}div style="clear: both;"{$><$}/div{$>$}},
  language = {en-US},
  file = {/Users/awwillc/Zotero/storage/LZPRMT6T/how-to-use-ci-cd-for-your-ml-projects.html}
}

@article{Archmiller20201012,
  title = {Computational Reproducibility in the Wildlife Society's Flagship Journals},
  author = {Archmiller, A.A. and Johnson, A.D. and Nolan, J. and Edwards, M. and Elliott, L.H. and Ferguson, J.M. and Iannarilli, F. and V{\'e}lez, J. and Vitense, K. and Johnson, D.H. and Fieberg, J.},
  year = {2020},
  journal = {Journal of Wildlife Management},
  volume = {84},
  number = {5},
  pages = {1012--1017},
  publisher = {{Wiley-Blackwell}},
  issn = {0022541X},
  doi = {10.1002/jwmg.21855},
  abbrev_source_title = {J. Wildl. Manage.},
  abstract = {Scientific progress depends upon the accumulation of empirical knowledge via reproducible methodology. Although reproducibility is a main tenet of the scientific method, recent studies have highlighted widespread failures in adherence to this ideal. The goal of this study was to gauge the level of computational reproducibility, or the ability to obtain the same results using the same data and analytic methods as in the original publication, in the field of wildlife science. We randomly selected 80 papers published in the Journal of Wildlife Management and Wildlife Society Bulletin between 1 June 2016 and 1 June 2018. Of those that were suitable for reproducibility review (n = 74), we attempted to obtain study data from online repositories or directly from authors. Forty-two authors did not respond to our requests, and we were further unable to obtain data from authors of 13 other studies. Of the 19 studies for which we were able to obtain data and complete our analysis, we judged that 13 were mostly or fully reproducible. We conclude that the studies with publicly available data or data shared upon request were largely reproducible, but we remain concerned about the difficulty in obtaining data from recently published papers. We recommend increased data-sharing, data organization and documentation, communication, and training to advance computational reproducibility in the wildlife sciences. \textcopyright{} 2020 The Authors. The Journal of Wildlife Management published by Wiley Periodicals, Inc. on behalf of The Wildlife Society. \textcopyright{} 2020 The Authors. The Journal of Wildlife Management published by Wiley Periodicals, Inc. on behalf of The Wildlife Society},
  affiliation = {Biology Department, Concordia College, 901 8\textexclamdown sup\textquestiondown th\textexclamdown/sup\textquestiondown{} St S, Moorhead, MN 56562, United States; Concordia College, 901 8\textexclamdown sup\textquestiondown th\textexclamdown/sup\textquestiondown{} St S, Moorhead, MN 56562, United States; Department of Fisheries, Wildlife and Conservation Biology, University of Minnesota, 2003 Upper Buford Circle, Suite 135, Saint Paul, MN 55108, United States; Department of Biology, University of Hawai'i at M\=anoa, 2538 McCarthy Mall, Honolulu, HI 96822, United States},
  author_keywords = {data sharing; meta-analysis; open science; reproducibility; research methods; statistical methods},
  coden = {JWMAA},
  correspondence_address1 = {Archmiller, A.A.; Biology Department, 901 8\textexclamdown sup\textquestiondown th\textexclamdown/sup\textquestiondown{} St S, United States; email: althea.archmiller@gmail.com},
  document_type = {Article},
  language = {English},
  source = {Scopus},
  keywords = {communication,data acquisition,documentary source,empirical analysis,knowledge,publishing,training},
  file = {/Users/awwillc/Zotero/storage/PGKMM4L4/Archmiller et al. - 2020 - Computational reproducibility in the wildlife soci.pdf}
}

@article{archmillerComputationalReproducibilityWildlife2020,
  title = {Computational {{Reproducibility}} in {{The Wildlife Society}}'s {{Flagship Journals}}},
  author = {Archmiller, Althea and Johnson, Andrew and Nolan, Jane and Edwards, Margaret and Elliott, Lisa and Ferguson, Jake and Iannarilli, Fabiola and V{\'e}lez, Juliana and Vitense, Kelsey and Johnson, Douglas and Fieberg, John},
  year = {2020},
  month = mar,
  journal = {The Journal of Wildlife Management},
  volume = {84},
  doi = {10/gg66q7},
  abstract = {Scientific progress depends upon the accumulation of empirical knowledge via reproducible methodology. Although reproducibility is a main tenet of the scientific method, recent studies have highlighted widespread failures in adherence to this ideal. The goal of this study was to gauge the level of computational reproducibility, or the ability to obtain the same results using the same data and analytic methods as in the original publication, in the field of wildlife science. We randomly selected 80 papers published in the Journal of Wildlife Management and Wildlife Society Bulletin between 1 June 2016 and 1 June 2018. Of those that were suitable for reproducibility review (n = 74), we attempted to obtain study data from online repositories or directly from authors. Forty-two authors did not respond to our requests, and we were further unable to obtain data from authors of 13 other studies. Of the 19 studies for which we were able to obtain data and complete our analysis, we judged that 13 were mostly or fully reproducible. We conclude that the studies with publicly available data or data shared upon request were largely reproducible, but we remain concerned about the difficulty in obtaining data from recently published papers. We recommend increased data-sharing, data organization and documentation, communication, and training to advance computational reproducibility in the wildlife sciences. \textcopyright{} 2020 The Authors. The Journal of Wildlife Management published by Wiley Periodicals, Inc. on behalf of The Wildlife Society. We tested studies published in the Journal of Wildlife Management and the Wildlife Society Bulletin for computational reproducibility. We found that the authors who were willing to share their data were largely using reproducible techniques but that our overall difficulty in obtaining data necessary to review reproducibility indicates that we can improve the scientific process within the wildlife sciences.}
}

@article{arieldeardorffAssessingImpactIntroductory2020,
  title = {Assessing the Impact of Introductory Programming Workshops on the Computational Reproducibility of Biomedical Workflows.},
  author = {{Ariel Deardorff}},
  year = {2020},
  month = jan,
  journal = {PLoS ONE},
  volume = {15},
  number = {7},
  pages = {e0230697-e0230697},
  issn = {1932-6203},
  doi = {10/ghhx4k},
  abstract = {INTRODUCTION:As biomedical research becomes more data-intensive, computational reproducibility is a growing area of importance. Unfortunately, many biomedical researchers have not received formal computational training and often struggle to produce results that can be reproduced using the same data, code, and methods. Programming workshops can be a tool to teach new computational methods, but it is not always clear whether researchers are able to use their new skills to make their work more computationally reproducible. METHODS:This mixed methods study consisted of in-depth interviews with 14 biomedical researchers before and after participation in an introductory programming workshop. During the interviews, participants described their research workflows and responded to a quantitative checklist measuring reproducible behaviors. The interview data was analyzed using a thematic analysis approach, and the pre and post workshop checklist scores were compared to assess the impact of the workshop on the computational reproducibility of the researchers' workflows. RESULTS:Pre and post scores on a checklist of reproducible behaviors did not change in a statistically significant manner. The qualitative interviews revealed that several participants had made small changes to their workflows including switching to open source programming languages for their data cleaning, analysis, and visualization. Overall many of the participants indicated higher levels of programming literacy, and an interest in further training. Factors that enabled change included supportive environments and an immediate research need, while barriers included collaborators that were resistant to new tools, and a lack of time. CONCLUSION:While none of the workshop participants completely changed their workflows, many of them did incorporate new practices, tools, or methods that helped make their work more reproducible and transparent to other researchers. This indicates that programming workshops now offered by libraries and other organizations contribute to computational reproducibility training for researchers.},
  keywords = {Medicine,Science},
  annotation = {mlzsync1:0064\{"extrafields":\{"publisher":"Public Library of Science (PLoS)"\}\} QID: Q97437301},
  file = {/Users/awwillc/Zotero/storage/U5X44E6W/Ariel Deardorff - 2020 - Assessing the impact of introductory programming w.pdf}
}

@misc{atlassianContinuousIntegrationVs,
  title = {Continuous Integration vs. Continuous Delivery vs. Continuous Deployment},
  author = {Atlassian},
  journal = {Atlassian},
  abstract = {CI is a practice that makes preparing for a release easier. CD may refer to \&quot;delivery\&quot; or \&quot;deployment,\&quot; which are similar but not quite the same.},
  howpublished = {https://www.atlassian.com/continuous-delivery/principles/continuous-integration-vs-delivery-vs-deployment},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/JNNFR7NI/continuous-integration-vs-delivery-vs-deployment.html}
}

@article{ayerConquaireArchitectureSupporting2017,
  title = {Conquaire : Towards an Architecture Supporting Continuous Quality Control to Ensure Reproducibility of Research},
  author = {Ayer, Vidya},
  year = {2017},
  month = jan,
  journal = {D-Lib magazine},
  issn = {1082-9873},
  abstract = {General Note: Includes illustration, references, table},
  keywords = {⛔ No DOI found,Database management,Electronic data processing -- Quality control,Reproducible research},
  annotation = {QID: Q59058281}
}

@article{Baer2018,
  title = {Responding to the Growing Issue of Research Reproducibility},
  author = {Baer, D.R. and Gilmore, I.S.},
  year = {2018},
  journal = {Journal of Vacuum Science and Technology A: Vacuum, Surfaces and Films},
  volume = {36},
  number = {6},
  publisher = {{AVS Science and Technology Society}},
  issn = {07342101},
  doi = {10.1116/1.5049141},
  abbrev_source_title = {J. Vac. Sci. Technol. A Vac. Surf. Films},
  abstract = {An increasing number of studies, surveys, and editorials highlight experimental and computational reproducibility and replication issues that appear to pervade most areas of modern science. This perspective examines some of the multiple and complex causes of what has been called a "reproducibility crisis," which can impact materials, interface/(bio)interphase, and vacuum sciences. Reproducibility issues are not new to science, but they are now appearing in new forms requiring innovative solutions. Drivers include the increasingly multidiscipline, multimethod nature of much advanced science, increased complexity of the problems and systems being addressed, and the large amounts and multiple types of experimental and computational data being collected and analyzed in many studies. Sustained efforts are needed to address the causes of reproducibility problems that can hinder the rate of scientific progress and lower public and political regard for science. The initial efforts of the American Vacuum Society to raise awareness of a new generation of reproducibility challenges and provide tools to help address them serve as examples of mitigating actions that can be undertaken. \textcopyright{} 2018 Author(s).},
  affiliation = {Pacific Northwest National Laboratory, Richland, WA 99352, United States; National Physical Laboratory, Teddington, TW11 0LW, United Kingdom},
  art_number = {068502},
  coden = {JVTAD},
  document_type = {Article},
  language = {English},
  source = {Scopus},
  keywords = {Advanced science,Computational data,Computational reproducibility,Condensed matter physics,Innovative solutions,Modern science,Multi disciplines,Reproducibilities,Scientific progress,Vacuum,Vacuum applications}
}

@inproceedings{Barghi2019943,
  title = {Predicting Computational Reproducibility of Data Analysis Pipelines in Large Population Studies Using Collaborative Filtering},
  author = {Barghi, S. and Scaria, L. and Salari, A. and Glatard, T.},
  editor = {Song Y., Liu B., Abe N., Pu C., Qiao M., Ahmed N., Kossmann D., Saltz J., Tang J., He J., Liu H., Hu X., Lee K.},
  year = {2019},
  series = {Proceedings - 2018 {{IEEE International Conference}} on {{Big Data}}, {{Big Data}} 2018},
  pages = {943--950},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  doi = {10.1109/bigdata.2018.8622095},
  abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, Big Data},
  abstract = {Evaluating the computational reproducibility of data analysis pipelines has become a critical issue. It is, however, a cumbersome process for analyses that involve data from large populations of subjects, due to their computational and storage requirements. We present a method to predict the computational reproducibility of data analysis pipelines in large population studies. We formulate the problem as a collaborative filtering process, with constraints on the construction of the training set. We propose 6 different strategies to build the training set, which we evaluate on 2 datasets, a synthetic one modeling a population with a growing number of subject types, and a real one obtained with neuroinformatics pipelines. Results show that one sampling method, \guillemotright Random File Numbers (Uniform)\guillemotright{} is able to predict computational reproducibility with a good accuracy. We also analyze the relevance of including file and subject biases in the collaborative filtering model. We conclude that the proposed method is able to speedup reproducibility evaluations substantially, with a reduced accuracy loss. \textcopyright{} 2018 IEEE.},
  affiliation = {Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada},
  art_number = {8622095},
  document_type = {Conference Paper},
  isbn = {978-1-5386-5035-6},
  language = {English},
  source = {Scopus},
  keywords = {Accuracy loss,Big data,Collaborative filtering,Computational reproducibility,Critical issues,Data handling,Digital storage,Forecasting,Large population,Neuroinformatics,Pipelines,Population statistics,Reproducibilities,Sampling method,Storage requirements}
}

@article{baxterScientificSoftwareDevelopment2006,
  title = {Scientific {{Software Development Is Not}} an {{Oxymoron}}},
  author = {Baxter, Susan M. and Day, Steven W. and Fetrow, Jacquelyn S. and Reisinger, Stephanie J.},
  year = {2006},
  journal = {PLoS Computational Biology},
  volume = {2},
  number = {9},
  pages = {e87},
  issn = {1553-734X, 1553-7358},
  doi = {10/bs5b5b},
  language = {en},
  keywords = {Research Software Engineering},
  annotation = {QID: Q21145679},
  file = {/Users/awwillc/Zotero/storage/9EQDHX2I/Baxter et al. - 2006 - Scientific Software Development Is Not an Oxymoron.pdf}
}

@article{beaulieu-jonesReproducibilityComputationalWorkflows2017,
  title = {Reproducibility of Computational Workflows Is Automated Using Continuous Analysis},
  author = {{Beaulieu-Jones}, Brett K and Greene, Casey S},
  year = {2017},
  journal = {Nature Biotechnology},
  number = {4},
  pages = {342},
  issn = {1087-0156},
  abstract = {Replication, validation and extension of experiments are crucial for scientific progress. Computational experiments are scriptable and should be easy to reproduce. However, computational analyses are designed and run in a specific computing environment, which may be difficult or impossible to match using written instructions. We report the development of continuous analysis, a workflow that enables reproducible computational analyses. Continuous analysis combines Docker, a container technology akin to virtual machines, with continuous integration, a software development technique, to automatically rerun a computational analysis whenever updates or improvements are made to source code or data. This enables researchers to reproduce results without contacting the study authors. Continuous analysis allows reviewers, editors or readers to verify reproducibility without manually downloading and rerunning code and can provide an audit trail for analyses of data that cannot be shared.},
  pmcid = {PMC6103790},
  pmid = {28288103},
  keywords = {*Machine Learning,*Software,*User-Computer Interface,*Workflow,Company business management,Computational Biology/*methods,Gene Expression Profiling/*methods,Reproducibility of Results,Science publishing -- Management,Sensitivity and Specificity},
  annotation = {mlzsync1:0055\{"extrafields":\{"publisher":"Nature Publishing Group"\}\}tex.ids: beaulieu-jonesReproducibilityComputationalWorkflows2017a, beaulieu-jonesReproducibilityComputationalWorkflows2017b},
  file = {/Users/awwillc/Zotero/storage/8FC6PNTZ/Beaulieu-Jones and Greene - 2017 - Reproducibility of computational workflows is auto.pdf;/Users/awwillc/Zotero/storage/NPIE3MTS/Beaulieu-Jones and Greene - 2017 - Reproducibility of computational workflows is auto.pdf;/Users/awwillc/Zotero/storage/5QD8UBBF/nbt.html}
}

@article{beaulieu-jonesReproducibilityComputationalWorkflows2017a,
  title = {Reproducibility of Computational Workflows Is Automated Using Continuous Analysis},
  author = {{Beaulieu-Jones}, Brett K and Greene, Casey S},
  year = {2017},
  journal = {Nature Biotechnology},
  number = {4},
  pages = {342},
  issn = {1087-0156},
  doi = {10/f9ttx6},
  abstract = {Author(s): Brett K Beaulieu-Jones [1]; Casey S Greene (corresponding author) [2] Leading scientific journals have highlighted a need for improved reproducibility to increase confidence in results and reduce the number [...]},
  keywords = {Company business management,Science publishing -- Management},
  annotation = {mlzsync1:0055\{"extrafields":\{"publisher":"Nature Publishing Group"\}\}}
}

@techreport{beaulieu-jonesReproducibleComputationalWorkflows2016,
  type = {Preprint},
  title = {Reproducible {{Computational Workflows}} with {{Continuous Analysis}}},
  author = {{Beaulieu-Jones}, Brett K. and Greene, Casey S.},
  year = {2016},
  month = jun,
  institution = {{Bioinformatics}},
  doi = {10.1101/056473},
  abstract = {Abstract                        Reproducing experiments is vital to science. Being able to replicate, validate and extend previous work also speeds new research projects. Reproducing computational biology experiments, which are scripted, should be straightforward. But reproducing such work remains challenging and time consuming. In the ideal world we would be able to quickly and easily rewind to the precise computing environment where results were generated. We would then be able to reproduce the original analysis or perform new analyses. We introduce a process termed ``continuous analysis'' which provides inherent reproducibility to computational research at a minimal cost to the researcher. Continuous analysis combines Docker, a container service similar to virtual machines, with continuous integration, a popular software development technique, to automatically re-run computational analysis whenever relevant changes are made to the source code. This allows results to be reproduced quickly, accurately and without needing to contact the original authors. Continuous analysis also provides an audit trail for analyses that use data with sharing restrictions. This allows reviewers, editors, and readers to verify reproducibility without manually downloading and rerunning any code. Example configurations are available at our online repository (             https://github.com/greenelab/continuous\_analysis             ).},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/9L9RQQ45/Beaulieu-Jones and Greene - 2016 - Reproducible Computational Workflows with Continuo.pdf}
}

@article{Bedo20201,
  title = {Unifying Package Managers, Workflow Engines, and Containers: {{Computational}} Reproducibility with {{BioNix}}},
  author = {Bedo, J. and Di Stefano, L. and Papenfuss, A.T.},
  year = {2020},
  journal = {GigaScience},
  volume = {9},
  number = {11},
  pages = {1--12},
  publisher = {{Oxford University Press}},
  issn = {2047217X},
  doi = {10.1093/gigascience/giaa121},
  abbrev_source_title = {GigaScience},
  abstract = {Motivation: A challenge for computational biologists is to make our analyses reproducible-i.e. to rerun, combine, and share, with the assurance that equivalent runs will generate identical results. Current best practice aims at this using a combination of package managers, workflow engines, and containers. Results: We present BioNix, a lightweight library built on the Nix deployment system. BioNix manages software dependencies, computational environments, and workflow stages together using a single abstraction: Pure functions. This lets users specify workflows in a clean, uniform way, with strong reproducibility guarantees. \textcopyright{} 2020 The Author(s). Published by Oxford University Press GigaScience.},
  affiliation = {Bioinformatics Division, Walter and Eliza Hall Institute of Medical Research, 1G Royal Pde., Parkville, VIC 3052, Australia; School of Computing and Information Systems, University of Melbourne, Melbourne, VIC 3010, Australia; Peter MacCallum Cancer Centre, 305 Grattan St., Melbourne, VIC 3000, Australia; Department of Medical Biology, University of Melbourne, Melbourne, VIC 3010, Australia; Sir Peter MacCallum Department of Oncology, University of Melbourne, Melbourne, VIC 3010, Australia; School of Mathematics and Statistics, University of Melbourne, Melbourne, VIC 3010, Australia; Department of Biostatistics, Bloomberg School of Public Health, Johns Hopkins University, 615 N. Wolfe Street, Baltimore, MD, United States},
  correspondence_address1 = {Bedo, J.; Bioinformatics Division, 1G Royal Pde., Australia; email: cu@cua0.org; Bedo, J.; School of Computing and Information Systems, Australia; email: cu@cua0.org},
  document_type = {Article},
  language = {English},
  pubmed_id = {33205815},
  source = {Scopus},
  keywords = {Article,cloud computing,computer language,information processing,information system,mathematical computing,priority journal,reproducibility,software,technology,workflow},
  file = {/Users/awwillc/Zotero/storage/ND8I8YL9/Bedo et al. - 2020 - Unifying package managers, workflow engines, and c.pdf}
}

@misc{BestPracticesContinuous2018,
  title = {Best {{Practices}} for {{Continuous Deployment}} | {{Lucidchart Blog}}},
  year = {2018},
  month = aug,
  abstract = {In today's fast-paced development environment, businesses and organizations have to move quickly to remain competitive. Learn best practices for continuous deployment, the ongoing delivery of software features.},
  howpublished = {/blog/continuous-deployment-best-practices},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/MX47JT8M/continuous-deployment-best-practices.html}
}

@incollection{bobrovTeachingDevOpsAcademia2020,
  title = {Teaching {{DevOps}} in {{Academia}} and {{Industry}}: {{Reflections}} and {{Vision}}},
  shorttitle = {Teaching {{DevOps}} in {{Academia}} and {{Industry}}},
  author = {Bobrov, Evgeny and Bucchiarone, Antonio and Capozucca, Alfredo and Guelfi, Nicolas and Mazzara, Manuel and Masyagin, Sergey},
  year = {2020},
  month = jan,
  pages = {1--14},
  doi = {10.1007/978-3-030-39306-9_1},
  abstract = {The new century brought us a kind of renaissance in software development methods. The advent of the Agile manifesto has led to greater appreciation of methodologies aimed at producing valuable software through continuous incremental cycles. More recently, a new set of practices enclosed under the term DevOps has appeared to attain manifesto's objectives in more efficient manner. The software development community has already noticed the benefits brought by DevOps. Thus, the necessity of education in the field becomes more and more important, both from the technical and organisational point of view. This paper describes parallel experiences of teaching both undergraduate and graduate students at the university, and junior professional developers in industry, compares the two approaches and sums up the lessons learnt. A vision driven by the DevOps practices aimed at implementing a shift in the Software Engineering Higher Education curricula to takeover its current limitations is also reported at the end of the paper.},
  isbn = {978-3-030-39305-2},
  file = {/Users/awwillc/Zotero/storage/KXUXZHTH/Bobrov et al. - 2020 - Teaching DevOps in Academia and Industry Reflecti.pdf}
}

@inproceedings{Boettiger201571,
  title = {An Introduction to {{Docker}} for Reproducible Research},
  author = {Boettiger, C.},
  year = {2015},
  series = {Operating {{Systems Review}} ({{ACM}})},
  volume = {49},
  pages = {71--79},
  publisher = {{Association for Computing Machinery}},
  issn = {01635980},
  doi = {10.1145/2723872.2723882},
  abbrev_source_title = {Oper Syst Rev ACM},
  abstract = {As computational work becomes more and more integral to many aspects of scientific research, computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments, the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper, I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues, including virtual machines and workflow systems, and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization, cross-platform portability, modular re-usable elements, versioning, and a 'DevOps' philosophy, to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.},
  affiliation = {Center for Stock Assessment Research, 110 Shaffer Rd, Santa Cruz, CA 95050, United States},
  coden = {OSRED},
  correspondence_address1 = {Boettiger, C.; Center for Stock Assessment Research, 110 Shaffer Rd, United States; email: cboettig@gmail.com},
  document_type = {Conference Paper},
  funding_details = {National Science FoundationNational Science Foundation, NSF, 1306697},
  language = {English},
  source = {Scopus},
  keywords = {Computational reproducibility,Computational work,Computer environments,Emerging technologies,Java programming language,Middleware,Network security,Physical experiments,Reproducible research,Scientific researches,System virtualization}
}

@article{boettigerIntroductionRockerDocker2017,
  title = {An {{Introduction}} to {{Rocker}}: {{Docker Containers}} for {{R}}},
  shorttitle = {An {{Introduction}} to {{Rocker}}},
  author = {Boettiger, Carl and Eddelbuettel, Dirk},
  year = {2017},
  journal = {The R Journal},
  volume = {9},
  number = {2},
  pages = {527},
  issn = {2073-4859},
  doi = {10/ghgdtz},
  abstract = {We describe the Rocker project, which provides a widely-used suite of Docker images with customized R environments for particular tasks. We discuss how this suite is organized, and how these tools can increase portability, scaling, reproducibility, and convenience of R users and developers.},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/VVNNBZCF/Boettiger and Eddelbuettel - 2017 - An Introduction to Rocker Docker Containers for R.pdf}
}

@article{borgmanWhoGotData2012,
  title = {Who's {{Got}} the {{Data}}? {{Interdependencies}} in {{Science}} and {{Technology Collaborations}}},
  shorttitle = {Who's {{Got}} the {{Data}}?},
  author = {Borgman, Christine L. and Wallis, Jillian C. and Mayernik, Matthew S.},
  year = {2012},
  month = dec,
  journal = {Computer Supported Cooperative Work (CSCW)},
  volume = {21},
  number = {6},
  pages = {485--523},
  issn = {1573-7551},
  doi = {10/ghj72z},
  abstract = {Science and technology always have been interdependent, but never more so than with today's highly instrumented data collection practices. We report on a long-term study of collaboration between environmental scientists (biology, ecology, marine sciences), computer scientists, and engineering research teams as part of a five-university distributed science and technology research center devoted to embedded networked sensing. The science and technology teams go into the field with mutual interests in gathering scientific data. ``Data'' are constituted very differently between the research teams. What are data to the science teams may be context to the technology teams, and vice versa. Interdependencies between the teams determine the ability to collect, use, and manage data in both the short and long terms. Four types of data were identified, which are managed separately, limiting both reusability of data and replication of research. Decisions on what data to curate, for whom, for what purposes, and for how long, should consider the interdependencies between scientific and technical processes, the complexities of data collection, and the disposition of the resulting data.},
  language = {en},
  annotation = {QID: Q66677677},
  file = {/Users/awwillc/Zotero/storage/X5JVD775/Borgman et al. - 2012 - Who’s Got the Data Interdependencies in Science a.pdf}
}

@article{braatzReproducibleResearchEditor2014,
  title = {Reproducible Research [{{From}} the {{Editor}}]},
  author = {Braatz, R.},
  year = {2014},
  month = aug,
  journal = {IEEE Control Systems, Control Systems, IEEE, IEEE Control Syst.},
  volume = {34},
  number = {4},
  pages = {6--7},
  issn = {1066-033X},
  doi = {10/ghkb92},
  abstract = {One of the concerns of the broader field of computational research is whether the results that are published are reproducible. When the author had a position as a senior research scientist at the National Center for Supercomputing Applications in the late 1990s, he had a conversation with a computational physicist who said that most simulation codes in his field were not made publicly available, and it was his opinion that at least 95\% of those codes contained major errors that result in technically incorrect results regularly being published. Because he was a generally balanced and agreeable fellow and had worked for many years at the U.S. Department of Energy national laboratories responsible for the development of most of the foundational computational software used today the author considered his estimate of 95\% reasonably accurate. This computational physicist said that the solution to the high occurrence of errors is that all computational codes should be made publicly available so that errors can be found and fixed, and he commented that computational research would progress much more quickly if this simple practice were employed. He later received a major national award based largely on the computational codes that he had developed over his career, all of which he had made publicly available. So the author asks readers: "Should authors in the control field be expected or compelled to make their software public, as a way to reduce errors and to facilitate progress in the field?"},
  keywords = {Robotics and Control Systems},
  annotation = {mlzsync1:0050\{"extrafields":\{"place":"USA","publisher":"IEEE"\}\}},
  file = {/Users/awwillc/Zotero/storage/Q4BUMNSS/Braatz - 2014 - Reproducible research [From the Editor].pdf}
}

@article{bradyDockerContainerSecurity2020,
  title = {Docker {{Container Security}} in {{Cloud Computing}}},
  author = {Brady, Kelly and Moon, Seung and Nguyen, Tuan and Coffman, Joel},
  year = {2020},
  month = jan,
  journal = {2020 10th Annual Computing and Communication Workshop and Conference (CCWC), Computing and Communication Workshop and Conference (CCWC), 2020 10th Annual},
  pages = {0975--0980},
  issn = {978-1-7281-3783-4},
  doi = {10/ghkb8x},
  abstract = {Docker is popular within the software development community due to the versatility, portability, and scalability of containers. However, concerns over vulnerabilities have grown as the security of applications become increasingly dependent on the security of the images that serve as the applications' building blocks. As more development processes migrate to the cloud, validating the security of images that are pulled from various repositories is paramount. In this paper, we describe a continuous integration and continuous deployment (CI/CD) system that validates the security of Docker images throughout the software development life cycle. We introduce images with vulnerabilities and measure the effectiveness of our approach at identifying the vulnerabilities. In addition, we use dynamic analysis to assess the security of Docker containers based on their behavior and show that it complements the static analyses typically used for security assessments.},
  keywords = {Communication; Networking and Broadcast Technologies,Components; Circuits; Devices and Systems,Computing and Processing,containers,Containers,continuous integration / continuous deployment (CI/CD),Docker,Engineered Materials; Dielectrics and Plasmas,Fields; Waves and Electromagnetics,Malware,Photonics and Electrooptics,Pipelines,Power; Energy and Industry Applications,Robotics and Control Systems,Security,Signal Processing and Analysis,Static analysis,Tools,Transportation,vulnerability analysis},
  annotation = {mlzsync1:0036\{"extrafields":\{"publisher":"IEEE"\}\}}
}

@article{britoRecommendationsEnhanceRigor2020,
  title = {Recommendations to Enhance Rigor and Reproducibility in Biomedical Research},
  author = {Brito, Jaqueline J. and Li, Jun and Moore, Jason H. and Greene, Casey S. and Nogoy, Nicole A. and Garmire, Lana X. and Mangul, Serghei},
  year = {2020},
  month = jun,
  journal = {GigaScience},
  volume = {9},
  number = {6},
  doi = {10/ggzr3d},
  abstract = {Abstract. Biomedical research depends increasingly on computational tools, but mechanisms ensuring open data, open software, and reproducibility are variably en},
  language = {en},
  annotation = {mlzsync1:0047\{"extrafields":\{"publisher":"Oxford Academic"\}\}},
  file = {/Users/awwillc/Zotero/storage/FWF5B483/Brito et al. - 2020 - Recommendations to enhance rigor and reproducibili.pdf}
}

@article{brunnertPerformanceorientedDevOpsResearch2015,
  title = {Performance-Oriented {{DevOps}}: {{A Research Agenda}}},
  author = {Brunnert, Andreas and {van Hoorn}, Andre and Willnecker, Felix and Danciu, Alexandru and Hasselbring, Wilhelm and Heger, Christoph and Herbst, Nikolas and Jamshidi, Pooyan and Jung, Reiner and {von Kistowski}, Joakim and Koziolek, Anne and Kro{\ss}, Johannes and Spinner, Simon and V{\"o}gele, Christian and Walter, J{\"u}rgen and Wert, Alexander},
  year = {2015},
  abstract = {DevOps is a trend towards a tighter integration between development (Dev) and operations (Ops) teams. The need for such an integration is driven by the requirement to continuously adapt enterprise applications (EAs) to changes in the business environment. As of today, DevOps concepts have been primarily introduced to ensure a constant flow of features and bug fixes into new releases from a functional perspective. In order to integrate a non-functional perspective into these DevOps concepts this report focuses on tools, activities, and processes to ensure one of the most important quality attributes of a software system, namely performance. Performance describes system properties concerning its timeliness and use of resources. Common metrics are response time, throughput, and resource utilization. Performance goals for EAs are typically defined by setting upper and/or lower bounds for these metrics and specific business transactions. In order to ensure that such performance goals can be met, several activities are required during development and operation of these systems as well as during the transition from Dev to Ops. Activities during development are typically summarized by the term Software Performance Engineering (SPE), whereas activities during operations are called Application Performance Management (APM). SPE and APM were historically tackled independently from each other, but the newly emerging DevOps concepts require and enable a tighter integration between both activity streams. This report presents existing solutions to support this integration as well as open research challenges in this area.},
  keywords = {⛔ No DOI found,Computer Science - Performance,Computer Science - Software Engineering},
  file = {/Users/awwillc/Zotero/storage/MRUU8ZK9/Brunnert et al. - 2015 - Performance-oriented DevOps A Research Agenda.pdf}
}

@misc{campiseWhyFutureData2017,
  title = {Why {{The Future}} of {{Data Science Is Data Psychology}}},
  author = {Campise, Kat},
  year = {2017},
  month = apr,
  journal = {RTInsights},
  abstract = {Some data science tasks may be offloaded to machines, but there is still a "data psychology" gap between the data and choosing the best course of action.},
  chapter = {Analytics},
  language = {en-US},
  file = {/Users/awwillc/Zotero/storage/QCWRGMV2/Campise - 2017 - Why The Future of Data Science Is Data Psychology.pdf;/Users/awwillc/Zotero/storage/USKTBRIG/why-the-future-of-data-science-is-data-psychology.html}
}

@article{chenContinuousDeliveryOvercoming2017,
  title = {Continuous {{Delivery}}: {{Overcoming}} Adoption Challenges},
  author = {Chen, Lianping},
  year = {2017/06/01/June 2017///},
  journal = {The Journal of Systems \& Software},
  volume = {128},
  pages = {72--86},
  issn = {0164-1212},
  doi = {10/ghkb93},
  abstract = {Highlights \textbullet Present six strategies to overcome Continuous Delivery (CD) adoption challenges.\textbullet Identify and elaborate eight further challenges for research.\textbullet They are based on four years' CD adoption experience at a multi-billion-euro company.},
  keywords = {Adoption,Agile Software Development,Continuous Delivery,Continuous Deployment,Continuous Software Engineering,DevOps},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Elsevier Inc."\}\} QID: Q60142372},
  file = {/Users/awwillc/Zotero/storage/VGKMEJTH/Chen - 2017 - Continuous Delivery Overcoming adoption challenge.pdf}
}

@article{chihProjectBenefitManagement2015,
  title = {Project Benefit Management: {{A}} Conceptual Framework of Target Benefit Formulation},
  author = {Chih, Ying-Yi and Zwikael, Ofer},
  year = {2015},
  month = feb,
  journal = {International Journal of Project Management},
  volume = {33},
  number = {2},
  pages = {352--362},
  issn = {0263-7863},
  doi = {10/f6zjfg},
  abstract = {Successful realization of project benefits is strongly associated with organizational performance. Formulating project target benefits is regarded as the first and critical step in the benefit management process. In this study, we drew upon relevant theories and conducted in-depth interviews with senior managers in Australia to develop a conceptual framework of project target benefit formulation and corresponding propositions. Our findings highlight the important role of project target benefits in funding decision-making and suggest seven criteria for their appraisal (strategic fit, target value, measurability, realism, target date, accountability and comprehensiveness) and four constructs which improve the formulated target benefits (a formal benefit formulation process, senior executive leadership, senior executive supports, and public service motivation). These findings extend the current literature on project benefit management by providing a holistic view on how project target benefits should be formulated and appraised.},
  keywords = {Project benefit realization,Project funding decision-making,Public sector,Target benefit formulation}
}

@article{Chirigati201695,
  title = {A Collaborative Approach to Computational Reproducibility},
  author = {Chirigati, F. and Capone, R. and Rampin, R. and Freire, J. and Shasha, D.},
  year = {2016},
  journal = {Information Systems},
  volume = {59},
  pages = {95--97},
  publisher = {{Elsevier Ltd}},
  issn = {03064379},
  doi = {10.1016/j.is.2016.03.002},
  abbrev_source_title = {Inf. Syst.},
  affiliation = {New York University, United States; Elsevier Inc., United States},
  coden = {INSYD},
  document_type = {Editorial},
  funding_details = {National Science FoundationNational Science Foundation, NSF, 1229185, 1405927},
  language = {English},
  source = {Scopus}
}

@misc{CloudAgnosticCI,
  title = {Cloud {{Agnostic CI}}/{{CD Pipeline}} for {{DevOps}} \textendash{} \#3 {{Process Steps}}},
  abstract = {Get the insides of CICD blueprint process~steps. The last blog gave you an overview about the building blocks of the blueprint.~The CI/CD process is managed by a single horizontal layer to trigger the four building blocks \{1:Code, 2:Build, 3:Deploy, 4:Consume\}. The beauty of this approach is the architecture, as replacing the building blocks with different [\ldots ]},
  howpublished = {https://gblogs.cisco.com/ch-tech/how-to-devops-cloud-agnostic-cicd-pipeline-process-steps/},
  language = {en},
  keywords = {DevOps},
  file = {/Users/awwillc/Zotero/storage/I3LPRBXG/how-to-devops-cloud-agnostic-cicd-pipeline-process-steps.html}
}

@inproceedings{Clyburne-Sherin2019449,
  title = {Preparing Code and Data for Computational Reproducibility},
  author = {{Clyburne-Sherin}, A. and Fei, X.},
  editor = {Bonn M., Wu D., Martaus A., Downie S.J.},
  year = {2019},
  series = {Proceedings of the {{ACM}}/{{IEEE Joint Conference}} on {{Digital Libraries}}},
  volume = {2019-June},
  pages = {449--450},
  publisher = {{Institute of Electrical and Electronics Engineers Inc.}},
  issn = {15525996},
  doi = {10.1109/jcdl.2019.00114},
  abbrev_source_title = {Proc. ACM IEEE Joint Conf. Digit. Libr.},
  affiliation = {Code Ocean, United States},
  art_number = {8791160},
  document_type = {Conference Paper},
  isbn = {978-1-72811-547-4},
  language = {English},
  source = {Scopus}
}

@article{Cohen-Boulakia2017284,
  title = {Scientific Workflows for Computational Reproducibility in the Life Sciences: {{Status}}, Challenges and Opportunities},
  author = {{Cohen-Boulakia}, S. and Belhajjame, K. and Collin, O. and Chopard, J. and Froidevaux, C. and Gaignard, A. and Hinsen, K. and Larmande, P. and Bras, Y.L. and Lemoine, F. and Mareuil, F. and M{\'e}nager, H. and Pradal, C. and Blanchet, C.},
  year = {2017},
  journal = {Future Generation Computer Systems},
  volume = {75},
  pages = {284--298},
  publisher = {{Elsevier B.V.}},
  issn = {0167739X},
  doi = {10.1016/j.future.2017.01.012},
  abbrev_source_title = {Future Gener Comput Syst},
  abstract = {With the development of new experimental technologies, biologists are faced with an avalanche of data to be computationally analyzed for scientific advancements and discoveries to emerge. Faced with the complexity of analysis pipelines, the large number of computational tools, and the enormous amount of data to manage, there is compelling evidence that many if not most scientific discoveries will not stand the test of time: increasing the reproducibility of computed results is of paramount importance. The objective we set out in this paper is to place scientific workflows in the context of reproducibility. To do so, we define several kinds of reproducibility that can be reached when scientific workflows are used to perform experiments. We characterize and define the criteria that need to be catered for by reproducibility-friendly scientific workflow systems, and use such criteria to place several representative and widely used workflow systems and companion tools within such a framework. We also discuss the remaining challenges posed by reproducible scientific workflows in the life sciences. Our study was guided by three use cases from the life science domain involving in silico experiments. \textcopyright{} 2017 Elsevier B.V.},
  affiliation = {Laboratoire de Recherche en Informatique, Universit\'e Paris-Sud, CNRS UMR 8623, Universit\'e Paris-Saclay, Orsay, France; Inria, VirtualPlants, Montpellier, France; Inria, Zenith, Montpellier, France; University Paris-Dauphine, PSL Research University, CNRS, UMR 7243, Centre Lamsade, Paris, 75016, France; IRISA, Rennes, France; INRA, UMR729, MISTEA, Montpellier, F-34060, France; Nantes Academic Hospital, CHU de Nantes, France; Centre de Biophysique Mol\'eculaire (CNRS UPR4301, Orl\'eans), France; IRD, DIADE, Montpellier, F-34394, France; EnginesOn / INRIA, Rennes, France; Institut Pasteur, Unit\'e Bioinformatique Evolutive, Centre de Bioinformatique, Biostatistique et Biologie Int\'egrative (C3BI, USR 3756 IP CNRS), Paris, France; Institut Pasteur, Hub Bioinformatique et Biostatistique, Centre de Bioinformatique, Biostatistique et Biologie Int\'egrative (C3BI, USR 3756 IP CNRS), Paris, France; Institut Pasteur, Centre d'Informatique pour la Biologie, Direction des Syst\`emes d'Information, Paris, France; CIRAD, UMR AGAP, Montpellier, France; CNRS, UMS 3601; Institut Fran\c{c}ais de Bioinformatique, IFB-core, Avenue de la Terrasse, Gif-sur-Yvette, F-91190, France},
  author_keywords = {Packaging environments; Provenance; Reproducibility; Scientific workflows},
  coden = {FGCSE},
  correspondence_address1 = {Cohen-Boulakia, S.; Laboratoire de Recherche en Informatique, France; email: cohen@lri.fr},
  document_type = {Article},
  funding_details = {Horizon 2020 Framework ProgrammeHorizon 2020 Framework Programme, H2020, 654241, 675728, 676559, 730976, 823830, 824087},
  language = {English},
  source = {Scopus},
  keywords = {Computational reproducibility,Computational tools,Hardware,Life-sciences,nocv1,Provenance,Reproducibilities,Scientific discovery,Scientific workflows,Software engineering,Work-flow systems}
}

@article{cohen-boulakiaScientificWorkflowsComputational2017,
  title = {Scientific Workflows for Computational Reproducibility in the Life Sciences: {{Status}}, Challenges and Opportunities},
  author = {{Cohen-Boulakia}, Sarah and Belhajjame, Khalid and Collin, Olivier and Chopard, J{\'e}r{\^o}me and Froidevaux, Christine and Gaignard, Alban and Hinsen, Konrad and Larmande, Pierre and Bras, Yvan Le and Lemoine, Fr{\'e}d{\'e}ric and Mareuil, Fabien and M{\'e}nager, Herv{\'e} and Pradal, Christophe and Blanchet, Christophe},
  year = {2017/10/01/October 2017///},
  journal = {Future Generation Computer Systems},
  volume = {75},
  pages = {284--298},
  issn = {0167-739X},
  doi = {10/ggb87f},
  abstract = {With the development of new experimental technologies, biologists are faced with an avalanche of data to be computationally analyzed for scientific advancements and discoveries to emerge. Faced with the complexity of analysis pipelines, the large number of computational tools, and the enormous amount of data to manage, there is compelling evidence that many if not most scientific discoveries will not stand the test of time: increasing the reproducibility of computed results is of paramount importance.The objective we set out in this paper is to place scientific workflows in the context of reproducibility. To do so, we define several kinds of reproducibility that can be reached when scientific workflows are used to perform experiments. We characterize and define the criteria that need to be catered for by reproducibility-friendly scientific workflow systems, and use such criteria to place several representative and widely used workflow systems and companion tools within such a framework. We also discuss the remaining challenges posed by reproducible scientific workflows in the life sciences. Our study was guided by three use cases from the life science domain involving in silico experiments.},
  keywords = {Packaging environments,Provenance,Reproducibility,Scientific workflows},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Elsevier B.V."\}\} QID: Q57971792},
  file = {/Users/awwillc/Zotero/storage/87TDTVPX/Cohen-Boulakia et al. - 2017 - Scientific workflows for computational reproducibi.pdf}
}

@article{colomo-palaciosCaseAnalysisEnabling2018,
  title = {A Case Analysis of Enabling Continuous Software Deployment through Knowledge Management.},
  author = {{Colomo-Palacios}, Ricardo and Fernandes, Eduardo and {Soto-Acosta}, Pedro and Larrucea, Xabier},
  year = {2018},
  month = jun,
  journal = {International Journal of Information Management},
  volume = {40},
  pages = {186--189},
  issn = {02684012},
  doi = {10/ghkb8z},
  abstract = {Continuous software engineering aims to accelerate software development by automating the whole software development process. Knowledge management is a cornerstone for continuous integration between software development and its operational deployment, which must be implemented using sound methodologies and solid tools. In this paper, the authors present and analyse a case study on the adoption of such practices by a software company. Results show that, beyond tools, knowledge management practices are the main enablers of continuous software engineering adoption and success. [ABSTRACT FROM AUTHOR]},
  keywords = {Case study,Computer software,Computer software development,Computer software industry,Continuous deployment,Continuous software engineering,DevOps,Knowledge management,Software engineering}
}

@misc{ContinuousIntegrationVs,
  title = {Continuous {{Integration}} vs. {{Continuous Delivery}} vs. {{Continuous Deployment}}},
  journal = {Stack Overflow},
  howpublished = {https://stackoverflow.com/questions/28608015/continuous-integration-vs-continuous-delivery-vs-continuous-deployment},
  file = {/Users/awwillc/Zotero/storage/2Z8P698S/continuous-integration-vs-continuous-delivery-vs-continuous-deployment.html}
}

@article{Culina:2018dn,
  title = {Navigating the Unfolding Open Data Landscape in Ecology and Evolution},
  author = {et al. Culina, Antica},
  year = {2018},
  journal = {Nature Ecology \& Evolution},
  pages = {1--7},
  abstract = {Nature Ecology \& Evolution, doi:10.1038/s41559-017-0458-2},
  keywords = {⛔ No DOI found,data provenance,ecology and evolution,meta-analysis,metadata,ontology,open data,open science,reproducibility}
}

@inproceedings{d.huljenicProjectManagementResearch2005,
  title = {Project Management in Research Projects},
  booktitle = {Proceedings of the 8th {{International Conference}} on {{Telecommunications}}, 2005. {{ConTEL}} 2005.},
  author = {{D. Huljenic} and {S. Desic} and {M. Matijasevic}},
  year = {2005},
  month = jun,
  volume = {2},
  pages = {663--669},
  doi = {10/ds9d75},
  keywords = {Communications technology,Costs,Engineering management,Meeting planning,Project management,Prototypes,Quality of service,Research and development,Research and development management,Virtual environment},
  file = {/Users/awwillc/Zotero/storage/ZJS2CQKD/D. Huljenic et al. - 2005 - Project management in research projects.pdf}
}

@misc{davidWorkflowToolThat,
  title = {R Is a {{Workflow Tool}} ({{That Also Does Some Stats}})},
  author = {David},
  journal = {https://rfortherestofus.com/},
  abstract = {I get asked this question a lot:~is the work I do too basic to take advantage of R? It's a reasonable question given~R's reputation as a tool for the extremely quantitatively inclined. But R can do a ton for you even if your statistical analysis needs are simple.~I~only~ever use R\ldots},
  language = {en\_US},
  file = {/Users/awwillc/Zotero/storage/KHE42398/r-workflow-tool.html}
}

@article{davis-turakGenomicsPipelinesData2017,
  title = {Genomics Pipelines and Data Integration: Challenges and Opportunities in the Research Setting.},
  author = {{Davis-Turak}, Jeremy and Courtney, Sean M and Hazard, E Starr and Glen, Jr, W Bailey and {da Silveira}, Willian A and Wesselman, Timothy and Harbin, Larry P and Wolf, Bethany J and Chung, Dongjun and Hardiman, Gary},
  year = {2017},
  month = mar,
  journal = {Expert review of molecular diagnostics},
  volume = {17},
  number = {3},
  pages = {225--237},
  issn = {1744-8352},
  doi = {10/ghkb9x},
  abstract = {Introduction: The emergence and mass utilization of high-throughput (HT) technologies, including sequencing technologies (genomics) and mass spectrometry (proteomics, metabolomics, lipids), has allowed geneticists, biologists, and biostatisticians to bridge the gap between genotype and phenotype on a massive scale. These new technologies have brought rapid advances in our understanding of cell biology, evolutionary history, microbial environments, and are increasingly providing new insights and applications towards clinical care and personalized medicine. Areas covered: The very success of this industry also translates into daunting big data challenges for researchers and institutions that extend beyond the traditional academic focus of algorithms and tools. The main obstacles revolve around analysis provenance, data management of massive datasets, ease of use of software, interpretability and reproducibility of results. Expert commentary: The authors review the challenges associated with implementing bioinformatics best practices in a large-scale setting, and highlight the opportunity for establishing bioinformatics pipelines that incorporate data tracking and auditing, enabling greater consistency and reproducibility for basic research, translational or clinical settings.},
  keywords = {analysis provenance*,bioinformatics best practices*,bioinformatics pipelines*,Computational Biology*/instrumentation,Computational Biology*/methods,Computational Biology*/trends,ExomeSeq*,Genetic Research*,genomic data management*,Genomics*/instrumentation,Genomics*/methods,Genomics*/trends,High throughput sequencing*,reproducible computational research*,RNAseq*,variant calling*},
  annotation = {mlzsync1:0066\{"extrafields":\{"place":"England","publisher":"Taylor \& Francis"\}\} QID: Q31154892},
  file = {/Users/awwillc/Zotero/storage/VBWI2TMM/Davis-Turak et al. - 2017 - Genomics pipelines and data integration challenge.pdf}
}

@article{Deardorff2020,
  title = {Assessing the Impact of Introductory Programming Workshops on the Computational Reproducibility of Biomedical Workflows},
  author = {Deardorff, A.},
  year = {2020},
  journal = {PLoS ONE},
  volume = {15},
  number = {7 July 2020},
  publisher = {{Public Library of Science}},
  issn = {19326203},
  doi = {10.1371/journal.pone.0230697},
  abbrev_source_title = {PLoS ONE},
  abstract = {Introduction As biomedical research becomes more data-intensive, computational reproducibility is a growing area of importance. Unfortunately, many biomedical researchers have not received formal computational training and often struggle to produce results that can be reproduced using the same data, code, and methods. Programming workshops can be a tool to teach new computational methods, but it is not always clear whether researchers are able to use their new skills to make their work more computationally reproducible. Methods This mixed methods study consisted of in-depth interviews with 14 biomedical researchers before and after participation in an introductory programming workshop. During the interviews, participants described their research workflows and responded to a quantitative checklist measuring reproducible behaviors. The interview data was analyzed using a thematic analysis approach, and the pre and post workshop checklist scores were compared to assess the impact of the workshop on the computational reproducibility of the researchers' workflows. Results Pre and post scores on a checklist of reproducible behaviors did not change in a statistically significant manner. The qualitative interviews revealed that several participants had made small changes to their workflows including switching to open source programming languages for their data cleaning, analysis, and visualization. Overall many of the participants indicated higher levels of programming literacy, and an interest in further training. Factors that enabled change included supportive environments and an immediate research need, while barriers included collaborators that were resistant to new tools, and a lack of time. Conclusion While none of the workshop participants completely changed their workflows, many of them did incorporate new practices, tools, or methods that helped make their work more reproducible and transparent to other researchers. This indicates that programming workshops now offered by libraries and other organizations contribute to computational reproducibility training for researchers. \textcopyright{} 2020 Ariel Deardorff.},
  affiliation = {University of California, Ucsf Library, San Francisco, CA, United States},
  art_number = {e0230697},
  coden = {POLNC},
  document_type = {Article},
  language = {English},
  pubmed_id = {32639955},
  source = {Scopus},
  keywords = {adult,article,Biomedical Research,checklist,cleaning,computer language,education,human,Humans,interview,library,literacy,medical research,organization,quantitative analysis,reproducibility,Reproducibility of Results,software,Software,thematic analysis,workflow,Workflow},
  file = {/Users/awwillc/Zotero/storage/ZGVKBF8T/Deardorff - 2020 - Assessing the impact of introductory programming w.pdf}
}

@inproceedings{debayserResearchOpsCaseDevOps2015,
  title = {{{ResearchOps}}: {{The}} Case for {{DevOps}} in Scientific Applications},
  shorttitle = {{{ResearchOps}}},
  booktitle = {2015 {{IFIP}}/{{IEEE International Symposium}} on {{Integrated Network Management}} ({{IM}})},
  author = {{de Bayser}, Maximilien and Azevedo, Leonardo G. and Cerqueira, Renato},
  year = {2015},
  month = may,
  pages = {1398--1404},
  publisher = {{IEEE}},
  address = {{Ottawa, ON, Canada}},
  doi = {10/ghkb9s},
  abstract = {DevOps (a portmanteau of ``development'' and ``operations'') is a software development method that extends the agile philosophy to rapidly produce software products and services and to improve operations performance and quality assurance. It was born to accelerate the delivery of web-based systems and quickly bring new value to users. Many web-based systems evolve according to usage trends without a clear longterm goal. Before the widespread use of web services, most software with a clear goal were delivered as packages that users installed on their own system. New versions were delivered with a much lower frequency, with periods in between versions ranging from months to years. Development cycles were divided into large design, coding and testing phases culminating in the release of a new stable version. In software development in the context of applied science, even when the goal is clear, the process to attain it is not. Hence, working releases that capture the current software state must be released frequently in order to reduce the risks for all stakeholders and to make it possible to assess the current state of a project and steer it in the right direction. This paper explores the usefulness of DevOps concepts to improve the development of software that supports scientific projects. We establish the similarities and differences between scientific projects and web applications development, and discuss where the related methodologies need to be extended. Unique challenges are discussed herewith developed solutions, and still open questions. Lessons learned are highlighted as best practices to be followed in research projects. This discussion is rooted in our experience in real-life projects at the IBM Research Brazil Lab, which just as well apply to other research institutions.},
  isbn = {978-1-4799-8241-7},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/C6GZ6738/de Bayser et al. - 2015 - ResearchOps The case for DevOps in scientific app.pdf}
}

@article{debroyOvercomingChallengesContinuous2020,
  title = {Overcoming {{Challenges With Continuous Integration}} and {{Deployment Pipelines}}: {{An Experience Report From}} a {{Small Company}}},
  author = {Debroy, V. and Miller, S.},
  year = {2020},
  month = may,
  journal = {IEEE Software, Software, IEEE, IEEE Softw.},
  volume = {37},
  number = {3},
  pages = {21--29},
  issn = {0740-7459},
  doi = {10/ghkb84},
  abstract = {We moved from a monolithic to a microservice-based architecture for the next generation of our applications at Varidesk. This initiative created challenges such as the inability to scale. In this article, we detail how we tackled the problems.},
  keywords = {Automation,Cloud computing,Companies,Computer architecture,Computing and Processing,Containerization,Continuous Deployment,Continuous Integration,DevOps,Microservices,Orchestration,Software development management,Task analysis},
  annotation = {mlzsync1:0050\{"extrafields":\{"place":"USA","publisher":"IEEE"\}\}},
  file = {/Users/awwillc/Zotero/storage/9ML7S8KB/Debroy and Miller - 2020 - Overcoming Challenges With Continuous Integration .pdf}
}

@book{diazDevOpsPracticePreliminary2019,
  title = {{{DevOps}} in {{Practice}} -- {{A}} Preliminary {{Analysis}} of Two {{Multinational Companies}}},
  author = {D{\'i}az, Jessica and {P{\'e}rez-Mart{\'i}nez}, Jorge and Yague, Agustin and Villegas, Andrea and Antona, Antonio},
  year = {2019},
  month = oct,
  abstract = {DevOps is a cultural movement that aims the collaboration of all the stakeholders involved in the development, deployment and operation of soft-ware to deliver a quality product or service in the shortest possible time. DevOps is relatively recent, and companies have developed their DevOps prac-tices largely from scratch. Our research aims to conduct an analysis on practic-ing DevOps in +20 software-intensive companies to provide patterns of DevOps practices and identify their benefits and barriers. This paper presents the preliminary analysis of an exploratory case study based on the interviews to relevant stakeholders of two (multinational) companies. The results show the benefits (software delivery performance) and barriers that these companies are dealing with, as well as DevOps team topology they approached during their DevOps transformation. This study aims to help practitioners and researchers to better understand DevOps transformations and the contexts where the practices worked. This, hopefully, will contribute to strengthening the evidence regarding DevOps and supporting practitioners in making better informed decisions about the return of investment when adopting DevOps.},
  file = {/Users/awwillc/Zotero/storage/R9BSPX7X/Díaz et al. - 2019 - DevOps in Practice -- A preliminary Analysis of tw.pdf}
}

@article{diazWhyAreMany2020,
  title = {Why Are Many Business Instilling a {{DevOps}} Culture into Their Organization?},
  author = {Diaz, Jessica and {L{\'o}pez-Fern{\'a}ndez}, Daniel and Perez, Jorge and {Gonz{\'a}lez-Prieto}, {\'A}ngel},
  year = {2020},
  abstract = {DevOps can be defined as a cultural movement and a technical solution to improve and accelerate the delivery of business value by making the collaboration between development and operations effective, which is rapidly spreading in software industry. However this movement is relatively recent, being necessary more empirical evidence about the real reasons why companies move to DevOps and what results they expect to obtain when adopting DevOps culture. This paper describes empirical research on practicing DevOps through an exploratory multiple case study of 30 multinational software-intensive companies that consists of interviews to relevant stakeholders. This study aims to help practitioners and researchers to better understand the context and the problems that many companies face day to day in their organizations when they do not reach the levels of innovation and software delivery they expect, as well as the main drivers that move these companies to adopting DevOps. This would contribute to strengthening the evidence and support practitioners in making better informed decisions. Furthermore, we have made available the methods to increase the reliability of findings and the instruments used in this study to motivate others to provide similar evidence to help mature DevOps research and practice.},
  keywords = {⛔ No DOI found,Computer Science - Software Engineering}
}

@article{dielCommunicationChallengesStrategies2016,
  title = {Communication {{Challenges}} and {{Strategies}} in {{Distributed DevOps}}},
  author = {Diel, Elisa and Marczak, Sabrina and Cruzes, Daniela S.},
  year = {2016},
  month = aug,
  journal = {2016 IEEE 11th International Conference on Global Software Engineering (ICGSE), Global Software Engineering (ICGSE), 2016 IEEE 11th International Conference on, Global Software Engineering (ICGSE), 2014 IEEE 9th International Conference on},
  pages = {24--28},
  issn = {978-1-5090-2680-7},
  doi = {10/ghkb9t},
  abstract = {Even though agile actively seeks collaboration from all its stakeholders, most agile projects do not extend themselves toward the operations people. To solve this problem, DevOps is introduced. DevOps is a conceptual framework for reintegrating development and operations of Information Systems, which is able to break the wall between developers and operations professionals. DevOps improves the work through a collection of principles and practices, centered around close collaboration between Development and Operations personnel. However, both sides have paid little attention to issues faced by each other. Communication gaps is a recurrent problem in agile teams that is also eminent in the relationship between developers and operations. Literature offers little research on this aspect of communication in DevOps. This position paper describes the communication practices from a distributed agile team composed of developers and operations based on communication challenges (geographical, socio-cultural, and temporal distance) and strategies (frequency, direction, modality, and content). From the results we outline possible research focus for future work, aiming to enrich the academia research on the matter as well as to help practitioners to improve their working practices.},
  keywords = {Collaboration,communication challenges,communication strategy,Companies,Computing and Processing,DevOps,distributed teams,Engineering Profession,Interviews,Personnel,Production,Software},
  annotation = {mlzsync1:0036\{"extrafields":\{"publisher":"IEEE"\}\}},
  file = {/Users/awwillc/Zotero/storage/58Z5ISHC/Diel et al. - 2016 - Communication Challenges and Strategies in Distrib.pdf}
}

@article{dikertChallengesSuccessFactors2016,
  title = {Challenges and Success Factors for Large-Scale Agile Transformations: {{A}} Systematic Literature Review},
  author = {Dikert, Kim and Paasivaara, Maria and Lassenius, Casper},
  year = {2016},
  month = sep,
  journal = {Journal of Systems and Software},
  volume = {119},
  pages = {87--108},
  issn = {0164-1212},
  doi = {10/gftrbh},
  abstract = {Agile methods have become an appealing alternative for companies striving to improve their performance, but the methods were originally designed for small and individual teams. This creates unique challenges when introducing agile at scale, when development teams must synchronize their activities, and there might be a need to interface with other organizational units. In this paper we present a systematic literature review on how agile methods and lean software development has been adopted at scale, focusing on reported challenges and success factors in the transformation. We conducted a systematic literature review of industrial large-scale agile transformations. Our keyword search found 1875 papers. We included 52 publications describing 42 industrial cases presenting the process of taking large-scale agile development into use. Almost 90\% of the included papers were experience reports, indicating a lack of sound academic research on the topic. We identified 35 reported challenges grouped into nine categories, and 29 success factors, grouped into eleven categories. The most salient success factor categories were management support, choosing and customizing the agile model, training and coaching, and mindset and alignment.},
  keywords = {Adopting agile software development,Agile software development,Challenges,Large-scale agile,Organizational transformation,Success factors,Systematic literature review},
  file = {/Users/awwillc/Zotero/storage/KYKEGK7U/Dikert et al. - 2016 - Challenges and success factors for large-scale agi.pdf}
}

@misc{dronavalliCICDEssentials2019,
  title = {{{CI}}/{{CD}} Essentials from Scratch with {{Gitlab}}.},
  author = {Dronavalli, Saikrishna},
  year = {2019},
  month = jul,
  journal = {Medium},
  abstract = {Being part of the development team I heard my infra team talking about enabling CI/CD to the projects that are being implemented. If you\ldots},
  howpublished = {https://medium.com/faun/ci-cd-essentials-from-scratch-with-gitlab-61502acf318e},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/953U5MY8/ci-cd-essentials-from-scratch-with-gitlab-61502acf318e.html}
}

@book{duvallContinuousIntegrationImproving2007,
  title = {Continuous {{Integration}}: {{Improving Software Quality}} and {{Reducing Risk}}. [Electronic Resource]},
  author = {Duvall, Paul and Matyas, Steve and Glover, Andrew},
  year = {2007},
  series = {Safari {{Books Online}}},
  edition = {1st edition.},
  publisher = {{Addison-Wesley Professional}},
  abstract = {Summary: For any software developer who has spent days in ``integration hell,'' cobbling together myriad software components, Continuous Integration: Improving Software Quality and Reducing Risk illustrates how to transform integration from a necessary evil into an everyday part of the development process. The key, as the authors show, is to integrate regularly and often using continuous integration (CI) practices and techniques. The authors first examine the concept of CI and its practices from the ground up and then move on to explore other effective processes performed by CI systems, such as database integration, testing, inspection, deployment, and feedback. Through more than forty CI-related practices using application examples in different languages, readers learn that CI leads to more rapid software development, produces deployable software at every step in the development lifecycle, and reduces the time between defect introduction and detection, saving time and lowering costs. With successful implementation of CI, developers reduce risks and repetitive manual processes, and teams receive better project visibility. The book covers How to make integration a ``non-event'' on your software development projects How to reduce the amount of repetitive processes you perform when building your software Practices and techniques for using CI effectively with your teams Reducing the risks of late defect discovery, low-quality software, lack of visibility, and lack of deployable software Assessments of different CI servers and related tools on the market The book's companion Web site, www.integratebutton.com, provides updates and code examples.},
  keywords = {Electronic books},
  file = {/Users/awwillc/Zotero/storage/MH8GDYMZ/Duvall et al. - 2007 - Continuous Integration Improving Software Quality.pdf}
}

@article{ebertGeneralConceptConsistent2015,
  title = {A General Concept for Consistent Documentation of Computational Analyses.},
  author = {Ebert, Peter and M{\"u}ller, Fabian and Nordstr{\"o}m, Karl and Lengauer, Thomas and Schulz, Marcel H.},
  year = {2015},
  month = jan,
  journal = {Database: The Journal of Biological Databases \& Curation},
  volume = {2015},
  pages = {1--11},
  issn = {17580463},
  abstract = {The ever-growing amount of data in the field of life sciences demands standardized ways of high-throughput computational analysis. This standardization requires a thorough documentation of each step in the computational analysis to enable researchers to understand and reproduce the results. However, due to the heterogeneity in software setups and the high rate of change during tool development, reproducibility is hard to achieve. One reason is that there is no common agreement in the research community on how to document computational studies. In many cases, simple flat files or other unstructured text documents are provided by researchers as documentation, which are often missing software dependencies, versions and sufficient documentation to understand the workflow and parameter settings. As a solution we suggest a simple and modest approach for documenting and verifying computational analysis pipelines. We propose a two-part scheme that defines a computational analysis using a Process and an Analysis metadata document, which jointly describe all necessary details to reproduce the results. In this design we separate the metadata specifying the process from the metadata describing an actual analysis run, thereby reducing the effort of manual documentation to an absolute minimum. Our approach is independent of a specific software environment, results in human readable XML documents that can easily be shared with other researchers and allows an automated validation to ensure consistency of the metadata. Because our approach has been designed with little to no assumptions concerning the workflow of an analysis, we expect it to be applicable in a wide range of computational research fields. Database URL: http://deep.mpi-inf.mpg.de/DAC/cmds/pub/pyvalid.zip [ABSTRACT FROM AUTHOR]},
  keywords = {⛔ No DOI found,DOCUMENTATION,HETEROGENEITY,LIFE sciences,METADATA,REPRODUCIBLE research},
  annotation = {mlzsync1:0061\{"extrafields":\{"publisher":"Oxford University Press / USA"\}\} QID: Q35698739}
}

@article{emamikhoonsariInteroperableScalableData2019,
  title = {Interoperable and Scalable Data Analysis with Microservices: {{Applications}} in Metabolomics},
  author = {Emami Khoonsari, Payam and Moreno, Pablo and Bergmann, Sven and Burman, 1974, Joachim and Capuccini, Marco and Carone, Matteo and Cascante, Marta and {de Atauri}, Pedro and Foguet, Carles and {Gonzalez-Beltran}, Alejandra N. and Hankemeier, Thomas and Haug, Kenneth and He, Sijin and Herman, Stephanie and Johnson, David and Kale, Namrata and Larsson, Anders and Neumann, Steffen and Peters, Kristian and Pireddu, Luca and {Rocca-Serra}, Philippe and Roger, Pierrick and Rueedi, Rico and Ruttkies, Christoph and Sadawi, Noureddin and Salek, Reza M. and Sansone, Susanna-Assunta and Schober, Daniel and Selivanov, Vitaly and Th{\'e}venot, Etienne A. and {van Vliet}, Michael and Zanetti, Gianluigi and Steinbeck, Christoph and Kultima, Kim and Spjuth, Docent, Ola},
  year = {2019},
  month = jan,
  journal = {Bioinformatics},
  volume = {35},
  number = {19},
  pages = {3752--3760},
  issn = {1367-4803},
  doi = {10/ghkb9z},
  abstract = {MotivationDeveloping a robust and performant data analysis workflow that integrates all necessary components whilst still being able to scale over multiple compute nodes is a challenging task. We introduce a generic method based on the microservice architecture, where software tools are encapsulated as Docker containers that can be connected into scientific workflows and executed using the Kubernetes container orchestrator.ResultsWe developed a Virtual Research Environment (VRE) which facilitates rapid integration of new tools and developing scalable and interoperable workflows for performing metabolomics data analysis. The environment can be launched on-demand on cloud resources and desktop computers. IT-expertise requirements on the user side are kept to a minimum, and workflows can be re-used effortlessly by any novice user. We validate our method in the field of metabolomics on two mass spectrometry, one nuclear magnetic resonance spectroscopy and one fluxomics study. We showed that the method scales dynamically with increasing availability of computational resources. We demonstrated that the method facilitates interoperability using integration of the major software suites resulting in a turn-key workflow encompassing all steps for mass-spectrometry-based metabolomics including preprocessing, statistics and identification. Microservices is a generic methodology that can serve any scientific discipline and opens up for new types of large-scale integrative science.},
  keywords = {Bioinformatics,Bioinformatics (Computational Biology),Bioinformatik (beräkningsbiologi),Computer and Information Sciences,container,Data- och informationsvetenskap,Docker,e-infrastructure,kubernetes,metabolomics,microservices,Natural Sciences,Naturvetenskap},
  file = {/Users/awwillc/Zotero/storage/HLHD5XF3/Emami Khoonsari et al. - 2019 - Interoperable and scalable data analysis with micr.pdf}
}

@incollection{erichDevOpsSimplyInteraction2019,
  title = {{{DevOps}} Is {{Simply Interaction Between Development}} and {{Operations}}: {{First International Workshop}}, {{DEVOPS}} 2018, {{Chateau}} de {{Villebrumier}}, {{France}}, {{March}} 5-6, 2018, {{Revised Selected Papers}}},
  author = {Erich, Floris},
  year = {2019},
  month = jan,
  pages = {89--99},
  doi = {10.1007/978-3-030-06019-0_7},
  abstract = {Based on a systematic literature review and interviews with six organizations regarding their use of DevOps, we take a look at a number of differing perspectives on what DevOps entails. We argue for a definition of DevOps as simply being ``interaction between development and operations''. This simple definition implies that DevOps is not a new thing which only certain organizations practice, but rather a fundamental characteristic of software and systems engineering that every organization is confronted with and manages to a certain extent.},
  isbn = {978-3-030-06018-3},
  file = {/Users/awwillc/Zotero/storage/8QHEEY9F/Erich - 2019 - DevOps is Simply Interaction Between Development a.pdf}
}

@article{erichQualitativeStudyDevOps2017,
  title = {A {{Qualitative Study}} of {{DevOps Usage}} in {{Practice}}},
  author = {Erich, Floris and Amrit, Chintan and Daneva, Maya},
  year = {2017},
  month = jun,
  journal = {Journal of Software: Evolution and Process},
  volume = {00},
  doi = {10/ghkb9k},
  abstract = {Organizations are introducing agile and lean software development techniques in operations to increase the pace of their software development process and to improve the quality of their software. They use the term DevOps, a portmanteau of development and operations, as an umbrella term to describe their efforts. In this paper we describe the ways in which organizations implement DevOps and the outcomes they experience. We first summarize the results of a Systematic Literature Review that we performed to discover what researchers have written about DevOps. We then describe the results of an exploratory interview-based study involving six organizations of various sizes that are active in various industries. As part of our findings, we observed that all organizations were positive about their experiences and only minor problems were encountered while adopting DevOps.},
  file = {/Users/awwillc/Zotero/storage/X84QKG4P/(PDF) A Qualitative Study of DevOps Usage in Pract.pdf}
}

@article{essawyTaxonomyReproducibleReplicable2020,
  title = {A Taxonomy for Reproducible and Replicable Research in Environmental Modelling},
  author = {Essawy, Bakinam T. and Goodall, Jonathan L. and Voce, Daniel and Morsy, Mohamed M. and Sadler, Jeffrey M. and Choi, Young Don and Tarboton, David G. and Malik, Tanu},
  year = {2020/01/01///},
  journal = {Environmental Modelling and Software},
  issn = {1364-8152},
  abstract = {Despite the growing acknowledgment of reproducibility crisis in computational science, there is still a lack of clarity around what exactly constitutes a reproducible or replicable study in many computational fields, including environmental modelling. To this end, we put forth a taxonomy that defines an environmental modelling study as being either 1) repeatable, 2) runnable, 3) reproducible, or 4) replicable. We introduce these terms with illustrative examples using the Structure for Unifying Multiple Modeling Alternatives (SUMMA) hydrologic modelling framework along with cyberinfrastructure aimed at fostering reproducibility. Using this taxonomy as a guide, we argue that containerization is a key missing component in environmental modelling and is necessary to achieve the goal of computational reproducibility. The provided examples demonstrate how new tools, including a user-friendly tool for containerization of computational analyses called Sciunit, can lower the barrier to reproducibility and replicability in the environmental modelling community.},
  keywords = {⛔ No DOI found,Containers,Docker,Replicability,Reproducibility,Singularity},
  annotation = {mlzsync1:0044\{"extrafields":\{"publisher":"Elsevier Ltd"\}\}}
}

@book{felidreContinuousIntegrationTheater2019,
  title = {Continuous {{Integration Theater}}},
  author = {Felidr{\'e}, Wagner and Furtado, Leonardo and Costa, Daniel and Cartaxo, Bruno and Pinto, Gustavo},
  year = {2019},
  month = jul,
  abstract = {Background: Continuous Integration (CI) systems are now the bedrock of several software development practices. Several tools such as TravisCI, CircleCI, and Hudson, that implement CI practices, are commonly adopted by software engineers. However, the way that software engineers use these tools could lead to what we call "Continuous Integration Theater", a situation in which software engineers do not employ these tools effectively, leading to unhealthy CI practices. Aims: The goal of this paper is to make sense of how commonplace are these unhealthy continuous integration practices being employed in practice. Method: By inspecting 1,270 open-source projects that use TravisCI, the most used CI service, we quantitatively studied how common is to use CI (1) with infrequent commits, (2) in a software project with poor test coverage, (3) with builds that stay broken for long periods, and (4) with builds that take too long to run. Results: We observed that 748 (\$sim\$60\%) projects face infrequent commits, which essentially makes the merging process harder. Moreover, we were able to find code coverage information for 51 projects. The average code coverage was 78\%, although Ruby projects have a higher code coverage than Java projects (86\% and 63\%, respectively). However, some projects with very small coverage (\$sim\$4\%) were found. Still, we observed that 85\% of the studied projects have at least one broken build that take more than four days to be fixed. Interestingly, very small projects (up to 1,000 lines of code) are the ones that take the longest to fix broken builds. Finally, we noted that, for the majority of the studied projects, the build is executed under the 10 minutes rule of thumb. Conclusions: Our results are important to an increasing community of software engineers that employ CI practices on daily basis but may not be aware of bad practices that are eventually employed.},
  file = {/Users/awwillc/Zotero/storage/X5TCFTWT/Felidré et al. - 2019 - Continuous Integration Theater.pdf}
}

@article{fitzgeraldContinuousSoftwareEngineering2017,
  title = {Continuous Software Engineering: {{A}} Roadmap and Agenda.},
  author = {Fitzgerald, Brian and Stol, Klaas-Jan},
  year = {2017},
  month = jan,
  journal = {Journal of Systems \& Software},
  volume = {123},
  pages = {176--189},
  issn = {01641212},
  doi = {10/gftq5d},
  abstract = {Throughout its short history, software development has been characterized by harmful disconnects between important activities such as planning, development and implementation. The problem is further exacerbated by the episodic and infrequent performance of activities such as planning, testing, integration and releases. Several emerging phenomena reflect attempts to address these problems. For example, Continuous Integration is a practice which has emerged to eliminate discontinuities between development and deployment. In a similar vein, the recent emphasis on DevOps recognizes that the integration between software development and its operational deployment needs to be a continuous one. We argue a similar continuity is required between business strategy and development, BizDev being the term we coin for this. These disconnects are even more problematic given the need for reliability and resilience in the complex and data-intensive systems being developed today. We identify a number of continuous activities which together we label as `Continuous * ' (i.e. Continuous Star ) which we present as part of an overall roadmap for Continuous Software engineering. We argue for a continuous (but not necessarily rapid) software engineering delivery pipeline. We conclude the paper with a research agenda. [ABSTRACT FROM AUTHOR]},
  keywords = {Business development,Business planning,Computer software development,Continuous software engineering,DevOps,Lean software development,Road maps,Software engineering},
  annotation = {QID: Q57098243}
}

@article{forsgrenAccelerateScienceLean2018,
  title = {Accelerate : {{The Science}} of {{Lean Software}} and {{DevOps}}: {{Building}} and {{Scaling High Performing Technology Organizations}}},
  author = {Forsgren, Nicole},
  year = {2018},
  issn = {978-1-942788-35-5},
  abstract = {Ideal for management at every level, this book will show you how to measure the performance of your teams, and what capabilities you should invest in to drive higher performance and accelerate your organization to win in the marketplace.},
  keywords = {⛔ No DOI found,Computer software -- Development,Electronic books,Operating systems (Computers),Software architecture},
  annotation = {mlzsync1:0051\{"extrafields":\{"publisher":"IT Revolution Press"\}\}},
  file = {/Users/awwillc/Zotero/storage/HC87SB34/Forsgren - Accelerate The Science of Lean Software and DevOp.pdf}
}

@article{Fortunato2021,
  title = {The Case for Free and Open Source Software in Research and Scholarship},
  author = {Fortunato, L. and Galassi, M.},
  year = {2021},
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {379},
  number = {2197},
  publisher = {{Royal Society Publishing}},
  issn = {1364503X},
  doi = {10.1098/rsta.2020.0079},
  abbrev_source_title = {Philos. Trans. R. Soc. A Math. Phys. Eng. Sci.},
  abstract = {Free and open source software (FOSS) is any computer program released under a licence that grants users rights to run the program for any purpose, to study it, to modify it, and to redistribute it in original or modified form. Our aim is to explore the intersection between FOSS and computational reproducibility. We begin by situating FOSS in relation to other 'open' initiatives, and specifically open science, open research, and open scholarship. In this context, we argue that anyone who actively contributes to the research process today is a computational researcher, in that they use computers to manage and store information. We then provide a primer to FOSS suitable for anyone concerned with research quality and sustainability-including researchers in any field, as well as support staff, administrators, publishers, funders, and so on. Next, we illustrate how the notions introduced in the primer apply to resources for scientific computing, with reference to the GNU Scientific Library as a case study. We conclude by discussing why the common interpretation of 'open source' as 'open code' is misplaced, and we use this example to articulate the role of FOSS in research and scholarship today. This article is part of the theme issue 'Reliability and reproducibility in computational science: implementing verification, validation and uncertainty quantification in silico'. \textcopyright{} 2021 The Author(s).},
  affiliation = {Institute of Cognitive and Evolutionary Anthropology, University of Oxford, 64 Banbury Road, Oxford, OX2 6PN, United Kingdom; Santa Fe Institute, 1399 Hyde Park Road, Santa Fe, NM 87501, United States; Space Science and Applications Group, Los Alamos National Laboratory, Los Alamos, NM 87545, United States},
  art_number = {20200079},
  author_keywords = {free and open source software (FOSS); GNU Scientific Library (GSL); open research; open scholarship; open science; reproducibility},
  correspondence_address1 = {Fortunato, L.; Institute of Cognitive and Evolutionary Anthropology, 64 Banbury Road, United Kingdom; email: laura.fortunato@anthro.ox.ac.uk},
  document_type = {Article},
  language = {English},
  pubmed_id = {33775148},
  source = {Scopus},
  keywords = {administrative personnel,article,Computational reproducibility,Computational science,computer model,Free and open source softwares,GNU scientific library,human,Open source software,Open systems,reliability,Reproducibilities,reproducibility,Research process,Research quality,software,uncertainty,Uncertainty quantifications},
  file = {/Users/awwillc/Zotero/storage/CSXLUI5P/Fortunato and Galassi - 2021 - The case for free and open source software in rese.pdf}
}

@inproceedings{Freire2012593,
  title = {Computational Reproducibility: {{State}}-of-the-Art, Challenges, and Database Research Opportunities},
  author = {Freire, J. and Bonnet, P. and Shasha, D.},
  year = {2012},
  series = {Proceedings of the {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  pages = {593--596},
  issn = {07308078},
  doi = {10.1145/2213836.2213908},
  abbrev_source_title = {Proc. ACM SIGMOD Int. Conf. Manage. Data},
  abstract = {Computational experiments have become an integral part of the scientific method, but reproducing, archiving, and querying them is still a challenge. The first barrier to a wider adoption is the fact that it is hard both for authors to derive a compendium that encapsulates all the components needed to reproduce a result and for reviewers to verify the results. In this tutorial, we will present a series of guidelines and, through hands-on examples, review existing tools to help authors create of reproducible results. We will also outline open problems and new directions for database-related research having to do with querying computational experiments. \textcopyright{} 2012 ACM.},
  affiliation = {NYU Poly, Brooklyn, NY, United States; IT University of Copenhagen, Copenhagen, Denmark; New York University, New York, NY, United States},
  author_keywords = {computational reproducibility; reproducible publications},
  correspondence_address1 = {Freire, J.; NYU Poly, Brooklyn, NY, United States; email: juliana.freire@nyu.edu},
  document_type = {Conference Paper},
  isbn = {978-1-4503-1247-9},
  language = {English},
  source = {Scopus},
  keywords = {Computational experiment,Database research,Database systems,Experiments,Integral part,Reproducibilities,reproducible publications,Scientific method}
}

@article{gaowangScriptScriptsPragmatic2019,
  title = {Script of {{Scripts}}: {{A}} Pragmatic Workflow System for Daily Computational Research.},
  author = {{Gao Wang} and {Bo Peng}},
  year = {2019},
  month = feb,
  journal = {PLoS Computational Biology},
  volume = {15},
  number = {2},
  pages = {e1006843-e1006843},
  issn = {1553-734X},
  doi = {10/gfwcb4},
  abstract = {Computationally intensive disciplines such as computational biology often require use of a variety of tools implemented in different scripting languages and analysis of large data sets using high-performance computing systems. Although scientific workflow systems can powerfully organize and execute large-scale data-analysis processes, creating and maintaining such workflows usually comes with nontrivial learning curves and engineering overhead, making them cumbersome to use for everyday data exploration and prototyping. To bridge the gap between interactive analysis and workflow systems, we developed Script of Scripts (SoS), an interactive data-analysis platform and workflow system with a strong emphasis on readability, practicality, and reproducibility in daily computational research. For exploratory analysis, SoS has a multilanguage scripting format that centralizes otherwise-scattered scripts and creates dynamic reports for publication and sharing. As a workflow engine, SoS provides an intuitive syntax for creating workflows in process-oriented, outcome-oriented, and mixed styles, as well as a unified interface for executing and managing tasks on a variety of computing platforms with automatic synchronization of files among isolated file systems. As illustrated herein by real-world examples, SoS is both an interactive analysis tool and pipeline platform suitable for different stages of method development and data-analysis projects. In particular, SoS can be easily adopted in existing data analysis routines to substantially improve organization, readability, and cross-platform computation management of research projects.},
  keywords = {Biology (General),QH301-705.5},
  annotation = {mlzsync1:0064\{"extrafields":\{"publisher":"Public Library of Science (PLoS)"\}\} QID: Q64097215},
  file = {/Users/awwillc/Zotero/storage/NHXZ382E/Gao Wang and Bo Peng - 2019 - Script of Scripts A pragmatic workflow system for.pdf}
}

@article{Garcia-Serrano2021141,
  title = {Computational Reproducibility of Named Entity Recognition Methods in the Biomedical Domain [{{Reproducci\'on}} Computacional de M\'etodos de Reconocimiento de Entidades Nombradas En Un Dominio Biom\'edico]},
  author = {{Garcia-Serrano}, A. and Hennig, S. and N{\"u}rnberger, A.},
  year = {2021},
  journal = {Procesamiento de Lenguaje Natural},
  volume = {66},
  pages = {141--152},
  publisher = {{Sociedad Espanola para el Procesamiento del Lenguaje Natural}},
  issn = {11355948},
  doi = {10.26342/2021-66-12},
  abbrev_source_title = {Proces. Lenguaje Nat.},
  abstract = {Unsupervised Named Entity Recognition (NER) approaches do not depend on labelled data to function properly but rather on a source of knowledge, in which promising candidates can be looked up to find the corresponding concept. In the biomedical domain knowledge source like this already exists; namely the Unified Medical Language System (UMLS). In this paper, three different unsupervised NER models using UMLS, namely MetaMap, cTakes and MetaMapLite are evaluated and compared from the results published by Demner-Fushman, Rogers and Aronson (2017) and Reategui and Ratte (2018). The Unsupervised Biomedical Named Entity Recognition framework (UB-NER) is developed, with which the results of the experiments of the three models, five datasets and two NER tasks are presented. \textcopyright{} 2021 Sociedad Espanola para el Procesamiento del Lenguaje Natural. All rights reserved.},
  affiliation = {ETSI Informatica - UNED; Computer science Department, OVGU},
  author_keywords = {Biomedical; Named Entity Recognition (NER); Supervised and unsupervised models; Unified Medical Language System},
  document_type = {Article},
  language = {English},
  source = {Scopus},
  keywords = {⚠️ Invalid DOI}
}

@article{geirkjetilsandveTenSimpleRules2013,
  title = {Ten Simple Rules for Reproducible Computational Research.},
  author = {{Geir Kjetil Sandve} and {Anton Nekrutenko} and {James Taylor} and {Eivind Hovig}},
  year = {2013},
  month = oct,
  journal = {PLoS Computational Biology},
  volume = {9},
  number = {10},
  pages = {e1003285-e1003285},
  issn = {1553-734X},
  doi = {10/pjb},
  keywords = {Biology (General),QH301-705.5},
  annotation = {mlzsync1:0064\{"extrafields":\{"publisher":"Public Library of Science (PLoS)"\}\} QID: Q28974699},
  file = {/Users/awwillc/Zotero/storage/R284JR7B/Geir Kjetil Sandve et al. - 2013 - Ten simple rules for reproducible computational re.pdf}
}

@article{gordonAreReplicationRates,
  title = {Are Replication Rates the Same across Academic Fields? {{Community}} Forecasts from the {{DARPA SCORE}} Programme},
  shorttitle = {Are Replication Rates the Same across Academic Fields?},
  author = {Gordon, Michael and Viganola, Domenico and Bishop, Michael and Chen, Yiling and Dreber, Anna and Goldfedder, Brandon and Holzmeister, Felix and Johannesson, Magnus and Liu, Yang and Twardy, Charles and Wang, Juntao and Pfeiffer, Thomas},
  journal = {Royal Society Open Science},
  volume = {7},
  number = {7},
  pages = {200566},
  doi = {10/ghkb9f},
  abstract = {The Defense Advanced Research Projects Agency (DARPA) programme `Systematizing Confidence in Open Research and Evidence' (SCORE) aims to generate confidence scores for a large number of research claims from empirical studies in the social and behavioural sciences. The confidence scores will provide a quantitative assessment of how likely a claim will hold up in an independent replication. To create the scores, we follow earlier approaches and use prediction markets and surveys to forecast replication outcomes. Based on an initial set of forecasts for the overall replication rate in SCORE and its dependence on the academic discipline and the time of publication, we show that participants expect replication rates to increase over time. Moreover, they expect replication rates to differ between fields, with the highest replication rate in economics (average survey response 58\%), and the lowest in psychology and in education (average survey response of 42\% for both fields). These results reveal insights into the academic community's views of the replication crisis, including for research fields for which no large-scale replication studies have been undertaken yet.},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Royal Society"\}\} QID: Q98894183},
  file = {/Users/awwillc/Zotero/storage/WEEUXK5N/Gordon et al. - Are replication rates the same across academic fie.pdf;/Users/awwillc/Zotero/storage/2KEEIEGT/rsos.html}
}

@article{gruningPracticalComputationalReproducibility2018,
  title = {Practical {{Computational Reproducibility}} in the {{Life Sciences}}},
  author = {Gruning, Bjorn and Chilton, John and Koster, Johannes and Dale, Ryan and Soranzo, Nicola and {van den Beek}, Marius and Goecks, Jeremy and Backofen, Rolf and Nekrutenko, Anton and Taylor, James},
  year = {2018},
  journal = {Cell Systems},
  number = {6},
  issn = {2405-4712},
  doi = {10/ggdv3z},
  abstract = {Many areas of research suffer from poor reproducibility, particularly in computationally intensive domains where results rely on a series of complex methodological decisions that are not well captured by traditional publication approaches. Various guidelines have emerged for achieving reproducibility, but implementation of these practices remains difficult due to the challenge of assembling software tools plus associated libraries, connecting tools together into pipelines, and specifying parameters. Here, we discuss a suite of cutting-edge technologies that make computational reproducibility not just possible, but practical in both time and effort. This suite combines three well-tested components--a system for building highly portable packages of bioinformatics software, containerization and virtualization technologies for isolating reusable execution environments for these packages, and workflow systems that automatically orchestrate the composition of these packages for entire pipelines--to achieve an unprecedented level of computational reproducibility. We also provide a practical implementation and five recommendations to help set a typical researcher on the path to performing data analyses reproducibly. Author Affiliation: (1) Albert Ludwigs University, Freiburg, Germany (2) The Pennsylvania State University, University Park, PA, USA (3) University of Duisburg-Essen, Essen, Germany (4) National Institute of Diabetes and Digestive and Kidney Diseases, Bethesda, MD, USA (5) Earlham Institute, Norwich, UK (6) Institut Curie, Paris, France (7) Oregon Health \& Sciences University, Portland, OR, USA (8) Johns Hopkins University, Baltimore, MD, USA * Corresponding author Byline: Bjorn Gruning (1), John Chilton (2), Johannes Koster (3), Ryan Dale (4), Nicola Soranzo (5), Marius van den Beek (6), Jeremy Goecks (7), Rolf Backofen [backofen@informatik.uni-freiburg.de] (1,*), Anton Nekrutenko [anton@nekrut.org] (2,**), James Taylor [james@taylorlab.org] (8,***)},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Elsevier B.V."\}\}},
  file = {/Users/awwillc/Zotero/storage/TB6DSVX4/Gruning et al. - 2018 - Practical Computational Reproducibility in the Lif.pdf}
}

@book{guerreroWhatThereDevOps2019,
  title = {What Is There about {{DevOps}}? {{Preliminary Findings}} from a {{Systematic Mapping Study}}},
  author = {Guerrero, Jonathan and Certuche D{\'i}az, Samuel and Z{\'u}{\~n}iga, Karen and Calvache, C{\'e}sar},
  year = {2019},
  month = jun,
  abstract = {One of the main worries of the software development companies (SDC) in recent years is how to automate, speed up and increase even more its productivity. DevOps appears as a solution to these issues throught the integration and coordination of efforts and activities carried out between the Development and Operations teams. However, DevOps is relatively a young research subject and so far there is no evidence about a standard or framework with sufficient level of detail to facilitate its correct adoption, operation and/or control. For that reason, the goal of this systematic mapping is to collect the current knowledge about the DevOps adoption in SDC, in order to establish the most important features to keep in mind when developing a guide to adopt DevOps. The results obtained show that, there are few studies related to DevOps, therefore, there is a need to elaborate a guide to adopt this in SDC.}
}

@article{guptaQuantitativeTextbasedCharacterization2019,
  title = {A Quantitative and Text-Based Characterization of Big Data Research.},
  author = {Gupta, Vedika and Singh, Vivek Kumar and Ghose, Udayan and Mukhija, Pankaj and Pinto, David and Singh, Vivek},
  year = {2019},
  month = may,
  journal = {Journal of Intelligent \& Fuzzy Systems},
  volume = {36},
  number = {5},
  pages = {4659--4675},
  issn = {10641246},
  doi = {10/ghkb9p},
  abstract = {This paper tries to map the research work carried out in the field of Big Data through a detailed analysis of scholarly articles published on the theme during 2010-16, as indexed in Scopus. We have collected and analyzed all relevant publications on Big Data, as indexed in Scopus, through a quantitative as well as textual characterization. The analysis attempts to dwell into parameters like research productivity, growth of research and citations, thematic trends, top publication sources and emerging topics in this field. The analytical study also investigates country-wise publications output and impact in terms of average citations per paper, country-level collaboration patterns, authorship and leading contributors (countries, institutions) etc. The scholarly publication data is also subjected to a detailed textual analysis method to identify key themes in Big Data research, disciplinary variations and thematic trends and patterns. The results produce interesting inferences. Quantitative measures show that there has been a tremendous increase in number of publications related to Big Data during last few years. Research work in Big Data, though primarily considered a sub-discipline of Computer Science, is now carried out by researchers in many disciplines. Thematic analysis of publications in Big Data show that it's a discipline involving research interest from fields as diverse as Medicine to Social Sciences. The paper also identifies major keywords now associated with Big Data research such as Cloud Computing, Deep Learning, Social Media and Data Analytics. This helps in a thorough understanding and visualization of the Big Data research area. [ABSTRACT FROM AUTHOR]},
  keywords = {Big data,big data analytics,Computer science,Content analysis,data science,Deep learning,Information visualization,scientometrics,Social medicine,Thematic analysis},
  annotation = {mlzsync1:0041\{"extrafields":\{"publisher":"IOS Press"\}\}},
  file = {/Users/awwillc/Zotero/storage/PIBPW5L3/Gupta et al. - 2019 - A quantitative and text-based characterization of .pdf}
}

@article{hamdanQualityFrameworkSoftware2015,
  title = {A {{Quality Framework}} for {{Software Continuous Integration}}},
  author = {Hamdan, Saba and Alramouni, Suad},
  year = {2015/01/01/January 2015///},
  journal = {Procedia Manufacturing},
  volume = {3},
  pages = {2019--2025},
  issn = {2351-9789},
  doi = {10/ghkb8w},
  abstract = {The research in this paper combines two main areas, the first one is software quality and the second is the agile practices of continuous integration. Software quality has been an important topic since the beginning of the software development and production. Many researches have been conducted to discuss how the quality of software is a critical factor to its success [1\textendash 5]. Because software became an important part of almost every task in our daily life, having high quality software that meets the users' expectations is important [6]. Software integration is a stage in every software development lifecycle, it is defined as the process to assemble the software components and produce a single product. It has been shown that software integration and integration testing can make more than 40\% of the overall project cost, so it is important that they are done efficiently and easily to be able to manage the involved risks [7]. A software engineering practice called continuous integration (CI) was introduced by Kent Beck and Ron Jeffries to mitigate the risks of software integration, enhance its process and improve its quality [8]. In this research, the principles of CI are identified and applied to a case study in order to analyze their impact on the software development process quality factors.},
  keywords = {Agile,Continuous integration,Extreme programming,ISO,Software development,Software quality framework},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Elsevier B.V."\}\}}
}

@article{hasselbringOpenSourceResearch2020,
  title = {Open {{Source Research Software}}},
  author = {Hasselbring, W. and Carr, L. and Hettrick, S. and Packer, H. and Tiropanis, T.},
  year = {2020},
  month = aug,
  journal = {Computer},
  volume = {53},
  number = {8},
  pages = {84--88},
  issn = {0018-9162},
  doi = {10/ghhx4m},
  abstract = {Reports on the need to make make software open source. It should be both archived for reproducibility and actively maintained for reusability. In computational and computer science, research software is a central asset for development activities. For good scientific practice, the resulting research software should be open source. Established open source software licenses provide sufficient options for granting permissions such that it should be the rare exception to keep research software closed. Proper engineering is required for obtaining reusable and sustainable research software. This way, software engineering methods may improve research in other disciplines. However, research in software engineering and computer science itself will also benefit when programs are reused. To study the state of the art in this field, we analyzed research software publishing practices in computer and computational science and observed significant differences: computational science emphasizes reproducibility, while computer science emphasizes reuse.},
  keywords = {Artificial intelligence,Computing and Processing,Licenses,Open source software,Scientific computing,Software engineering},
  annotation = {mlzsync1:0050\{"extrafields":\{"place":"USA","publisher":"IEEE"\}\} QID: Q50991581},
  file = {/Users/awwillc/Zotero/storage/WNWUF6PY/Hasselbring et al. - 2020 - Open Source Research Software.pdf}
}

@article{Hatton2019137,
  title = {Computational Reproducibility: {{The}} Elephant in the Room},
  author = {Hatton, L. and Van Genuchten, M.},
  year = {2019},
  journal = {IEEE Software},
  volume = {36},
  number = {2},
  pages = {137--144},
  publisher = {{IEEE Computer Society}},
  issn = {07407459},
  doi = {10.1109/ms.2018.2883805},
  abbrev_source_title = {IEEE Software},
  affiliation = {Kingston University, London, United Kingdom; VitalHealth Software, United Kingdom},
  art_number = {8648256},
  coden = {IESOE},
  document_type = {Article},
  language = {English},
  source = {Scopus},
  file = {/Users/awwillc/Zotero/storage/I78Y7EZY/Hatton and Van Genuchten - 2019 - Computational reproducibility The elephant in the.pdf}
}

@article{hattonComputationalReproducibilityElephant2019,
  title = {Computational {{Reproducibility}}: {{The Elephant}} in the {{Room}}},
  author = {Hatton, L. and {van Genuchten}, M.},
  year = {2019},
  month = mar,
  journal = {IEEE Software, Software, IEEE, IEEE Softw.},
  volume = {36},
  number = {2},
  pages = {137--144},
  publisher = {{IEEE}},
  address = {{USA}},
  issn = {0740-7459},
  doi = {10/ggkvtr},
  abstract = {Examines the concept of computational reproducibility. Reports on the development of software programming and addresses the challenges of managing software development and developing reliability software update and maintenance procedures.},
  keywords = {Computing and Processing,Software engineering,Software maintenance,Software reliability},
  file = {/Users/awwillc/Zotero/storage/APJWLD4Y/Hatton and van Genuchten - 2019 - Computational Reproducibility The Elephant in the.pdf}
}

@article{hidalgoAdaptingScrumFramework2019,
  title = {Adapting the Scrum Framework for Agile Project Management in Science: Case Study of  a Distributed Research Initiative.},
  author = {Hidalgo, Enric Senabre},
  year = {2019},
  month = mar,
  journal = {Heliyon},
  volume = {5},
  number = {3},
  pages = {e01447},
  issn = {2405-8440 2405-8440 2405-8440},
  doi = {10/ghkb9h},
  abstract = {This article explores the adoption of agile methods for the management of projects  in collaborative research initiatives. The use of the scrum framework, a specific  set of agile principles and practices for self-organizing cross-functional teams in  software development projects, is currently being expanded to other types of  organizations and knowledge management processes. The study addresses the extent to  which key principles and tools usually used in scrum, due to their potentially  positive influence on team dynamics and efficiency, can contribute to the  collaborative management and coordination of tasks in research processes. The  responses from interviews with 17 researchers, as well as participant observation  and analysis of online activity, are examined and presented as a case study on the  adoption of scrum practices in a distributed research centre dedicated to the  evaluation of public policies. Results indicate that integrating agile methods and  principles for interdisciplinary collaboration requires a high degree of flexibility  and a "learn by doing" approach.},
  language = {eng},
  pmcid = {PMC6441834},
  pmid = {30976706},
  keywords = {Information science,Sociology},
  annotation = {QID: Q64103026},
  file = {/Users/awwillc/Zotero/storage/ZN7N7RJT/Hidalgo - 2019 - Adapting the scrum framework for agile project man.pdf}
}

@article{hinsenActivePapersPlatformPublishing2015,
  title = {{{ActivePapers}}: A Platform for Publishing and Archiving Computer-Aided Research},
  shorttitle = {{{ActivePapers}}},
  author = {Hinsen, Konrad},
  year = {2015},
  month = jul,
  journal = {F1000Research},
  volume = {3},
  pages = {289},
  issn = {2046-1402},
  doi = {10/gfrkvv},
  language = {en},
  annotation = {QID: Q28646852},
  file = {/Users/awwillc/Zotero/storage/4V8HB4FM/Hinsen - 2015 - ActivePapers a platform for publishing and archiv.pdf}
}

@article{hocquetEpistemicIssuesComputational2021,
  title = {Epistemic Issues in Computational Reproducibility: Software as the Elephant in the Room},
  author = {Hocquet, Alexandre and Wieber, Fr{\'e}d{\'e}ric},
  year = {2021},
  journal = {European Journal for Philosophy of Science},
  volume = {11},
  number = {2},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  issn = {1879-4912},
  doi = {10/gkm94m},
  abstract = {Computational reproducibility (i.e. issues of reproducibility stemming from the computer as a scientific tool) possesses its own dynamics and narratives of crisis. Alongside the difficulties of computing as an ubiquitous yet complex scientific activity, computational reproducibility suffers from a naive expectancy of total reproducibility and a moral imperative to embrace the principles of free software as a non-negotiable epistemic virtue. We argue that the epistemic issues at stake in actual practices of computational reproducibility are best unveiled by focusing on software as a pivotal concept, one that is surprisingly often overlooked in accounts of reproducibility issues. Software is not only about designing and coding but also about maintaining, supporting, distributing, licensing, and governance; it is not only about developers but also about users. We focus on openness debates among computational chemists involved in molecular modeling software packages as empirical grounding for our argument. We then identify and analyse four epistemic characteristics (transparency, consistency, sustainability and inclusivity) as key to the role of software in computational reproducibility.},
  keywords = {Computational chemistry,Computational reproducibility,Consistency,Inclusivity,Software,Sustainability,Transparency}
}

@article{hoickCONTINUOUSINTEGRATIONQUALITY2003,
  title = {{{CONTINUOUS INTEGRATION AND QUALITY ASSURANCE}}: {{A CASE STUDY OF TWO OPEN SOURCE PROJECTS}}.},
  author = {Hoick, Jesper and Jorgensen, Niels},
  year = {2003///2003/2004 Special Issue},
  journal = {AJIS: Australian Journal of Information Systems},
  pages = {40},
  issn = {10397841},
  abstract = {A decentralized variant of continuous integration can be defined in terms of two fundamental rules: (1) Developers' access to add contributions to the development version at any time, and (2) developers' obligation to integrate their own contributions properly. Decentralized, continuous integration may adapt well to organizations where developers work relatively independently, as in many open source projects. The approach raises the issue of how these organizations can exercise central control, as attaining the benefits of continuous integration requires that contributions are useful and satisfy the project's definition of successful integration. We have investigated the use of continuous integration in FreeBSD and Mozilla. Our account of quality assurance activities in the two open source projects distinguishes between Mintzberg's three complementary forms of central control: Standardization and control of work output, work processes, and worker skills. Our study indicates that two major challenges face projects using decentralized, continuous integration: (1) To balance the access to add contributions against the need to stabilize and mature the software prior to a release, and (2) to consider the developers' limited time and resources when interpreting their obligation to integrate their changes properly. [ABSTRACT FROM AUTHOR]},
  keywords = {⛔ No DOI found,COMPUTER science,COMPUTER software developers,COMPUTER software development,OPEN source software,SYSTEMS development}
}

@article{hollmannTenSimpleRules2020,
  title = {Ten Simple Rules on How to Write a Standard Operating Procedure.},
  author = {Hollmann, Susanne and Frohme, Marcus and Endrullat, Christoph and Kremer, Andreas and D'Elia, Domenica and Regierer, Babette and Nechyporenko, Alina},
  year = {2020},
  month = sep,
  journal = {PLoS Computational Biology},
  volume = {16},
  number = {9},
  pages = {1--10},
  issn = {1553734X},
  abstract = {Research publications and data nowadays should be publicly available on the internet and, theoretically, usable for everyone to develop further research, products, or services. The long-term accessibility of research data is, therefore, fundamental in the economy of the research production process. However, the availability of data is not sufficient by itself, but also their quality must be verifiable. Measures to ensure reuse and reproducibility need to include the entire research life cycle, from the experimental design to the generation of data, quality control, statistical analysis, interpretation, and validation of the results. Hence, high-quality records, particularly for providing a string of documents for the verifiable origin of data, are essential elements that can act as a certificate for potential users (customers). These records also improve the traceability and transparency of data and processes, therefore, improving the reliability of results. Standards for data acquisition, analysis, and documentation have been fostered in the last decade driven by grassroot initiatives of researchers and organizations such as the Research Data Alliance (RDA). Nevertheless, what is still largely missing in the life science academic research are agreed procedures for complex routine research workflows. Here, well-crafted documentation like standard operating procedures (SOPs) offer clear direction and instructions specifically designed to avoid deviations as an absolute necessity for reproducibility. Therefore, this paper provides a standardized workflow that explains step by step how to write an SOP to be used as a starting point for appropriate research documentation. [ABSTRACT FROM AUTHOR]},
  keywords = {⛔ No DOI found,ACQUISITION of data,DOCUMENTATION standards,QUALITY control,STANDARD operating procedure,WORKFLOW management},
  annotation = {mlzsync1:0057\{"extrafields":\{"publisher":"Public Library of Science"\}\} QID: Q98938891}
}

@article{iainemsleyFrameworkPreservationDocker2018,
  title = {A {{Framework}} for the {{Preservation}} of a {{Docker Container}}},
  author = {{Iain Emsley} and {David De Roure}},
  year = {2018},
  month = apr,
  journal = {International Journal of Digital Curation},
  volume = {12},
  number = {2},
  issn = {1746-8256},
  doi = {10/ghkb9b},
  abstract = {Reliably building and maintaining systems across environments is a continuing problem. A project or experiment may run for years. Software and hardware may change as can the operating system. Containerisation is a technology that is used in a variety of companies, such as Google, Amazon and IBM, and scientific projects to rapidly deploy a set of services repeatably. Using Dockerfiles to ensure that a container is built repeatably, to allow conformance and easy updating when changes take place are becoming common within projects. Its seen as part of sustainable software development. Containerisation technology occupies a dual space: it is both a repository of software and software itself. In considering Docker in this fashion, we should verify that the Dockerfile can be reproduced. Using a subset of the Dockerfile specification, a domain specific language is created to ensure that Docker files can be reused at a later stage to recreate the original environment. We provide a simple framework to address the question of the preservation of containers and its environment. We present experiments on an existing Dockerfile and conclude with a discussion of future work. Taking our work, a pipeline was implemented to check that a defined Dockerfile conforms to our desired model, extracts the Docker and operating system details. This will help the reproducibility of results by creating the machine environment and package versions. It also helps development and testing through ensuring that the system is repeatably built and that any changes in the software environment can be equally shared in the Dockerfile. This work supports not only the citation process it also the open scientific one by providing environmental details of the work. As a part of the pipeline to create the container, we capture the processes used and put them into the W3C PROV ontology. This provides the potential for providing it with a persistent identifier and traceability of the processes used to preserve the metadata. Our future work will look at the question of linking this output to a workflow ontology to preserve the complete workflow with the commands and parameters to be given to the containers. We see this provenance within the build process useful to provide a complete overview of the workflow.},
  keywords = {Bibliography. Library science. Information resources},
  annotation = {mlzsync1:0055\{"extrafields":\{"publisher":"University of Edinburgh"\}\} QID: Q59586893},
  file = {/Users/awwillc/Zotero/storage/PWC334B3/Iain Emsley and David De Roure - 2018 - A Framework for the Preservation of a Docker Conta.pdf}
}

@misc{ImageDevOpsWorkflow,
  title = {Image: {{DevOps}} Workflow | {{Agile}} Software Development, {{Enterprise}} ...},
  shorttitle = {Image},
  abstract = {Found on Google from pinterest.com.au},
  howpublished = {https://www.google.com.au/imgres?imgurl=https\%3A\%2F\%2Fi.pinimg.com\%2Foriginals\%2F72\%2F25\%2Ff7\%2F7225f75466bf0de1be720e52a135b18b.jpg\&imgrefurl=https\%3A\%2F\%2Fwww.pinterest.com.au\%2Fpin\%2F5699937009304675\%2F\&tbnid=YlFbJZPBmfoyTM\&vet=12ahUKEwja39DkmrPrAhWXW30KHRbqDa0QMygOegUIARDiAQ..i\&docid=PWdJVEpOVplp5M\&w=689\&h=827\&itg=1\&q=DevOps\%20workflow\&ved=2ahUKEwja39DkmrPrAhWXW30KHRbqDa0QMygOegUIARDiAQ},
  language = {en-AU},
  keywords = {CD},
  file = {/Users/awwillc/Zotero/storage/LTY7DAGX/imgres.html}
}

@misc{InteroperabilityGettingMost,
  title = {Interoperability: {{Getting}} the {{Most Out}} of {{Your Analytic Investments}}},
  shorttitle = {Interoperability},
  abstract = {No single platform meets all the analytic needs of every organization. To avoid productivity-sapping complexity and underutilized infrastructure, encourage Interoperability so that your data scientists can access everything they need from their native tools.},
  howpublished = {https://blog.rstudio.com/2020/07/15/interoperability-maximize-analytic-investments/},
  language = {en-us},
  file = {/Users/awwillc/Zotero/storage/8SRUH9SA/interoperability-maximize-analytic-investments.html}
}

@article{ISI:000378458400006,
  type = {Editorial Material},
  title = {A Collaborative Approach to Computational Reproducibility},
  author = {Chirigati, Fernando and Capone, Rebecca and Rampin, Remi and Freire, Juliana and Shasha, Dennis},
  year = {2016},
  month = jul,
  journal = {INFORMATION SYSTEMS},
  volume = {59},
  number = {SI},
  pages = {95--97},
  publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
  address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
  issn = {0306-4379},
  doi = {10.1016/j.is.2016.03.002},
  affiliation = {Chirigati, F (Corresponding Author), NYU, New York, NY 10003 USA. Chirigati, Fernando; Rampin, Remi; Freire, Juliana; Shasha, Dennis, NYU, New York, NY 10003 USA. Capone, Rebecca, Elsevier Inc, Amsterdam, Netherlands.},
  cited-references = {Begley CG, 2012, NATURE, V483, P531, DOI 10.1038/483531a. Boettiger Carl, 2015, ACM SIGOPS Operating Systems Review, V49, P71. Bonnet P, 2011, SIGMOD REC, V40, P45, DOI 10.1145/2034863.2034873. Brody T., 2006, THESIS. Chirigati F., 2016, P SIGMOD 16 DEM SESS. Collberg C., 2015, 1404 TR U AR. Crook SM, 2013, 20 YEARS COMPUTATION, P73, DOI DOI 10.1007/978-1-4614-1424-7\_4. Donoho DL, 2009, COMPUT SCI ENG, V11, P8, DOI 10.1109/MCSE.2009.15. HITCHCOCK S, 2009, EFFECT OPEN ACCESS D. Kovacevic J, 2007, INT CONF ACOUST SPEE, P1273. Lawrence S, 2001, NATURE, V411, P521, DOI 10.1038/35079151. Nuzzo R, 2015, NATURE, V526, P182, DOI 10.1038/526182a. Piwowar HA, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000308. Tenopir C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021101. Vandewalle P, 2009, IEEE SIGNAL PROC MAG, V26, P37, DOI 10.1109/MSP.2009.932122. Wolke A., 2016, INF SYST. Wolke A, 2015, INFORM SYST, V52, P83, DOI 10.1016/j.is.2015.03.003.},
  da = {2021-06-23},
  doc-delivery-number = {DP4IA},
  eissn = {1873-6076},
  funding-acknowledgement = {Division Of Computer and Network SystemsNational Science Foundation (NSF)NSF - Directorate for Computer \& Information Science \& Engineering (CISE) [1405927, 1229185] Funding Source: National Science Foundation},
  journal-iso = {Inf. Syst.},
  language = {English},
  number-of-cited-references = {17},
  orcid-numbers = {Freire, Juliana/0000-0003-3915-7075 Rampin, Remi/0000-0002-0524-2282 Chirigati, Fernando/0000-0002-9566-5835},
  research-areas = {Computer Science},
  researcherid-numbers = {Freire, Juliana/AAQ-4484-2020},
  times-cited = {3},
  unique-id = {ISI:000378458400006},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {3},
  web-of-science-categories = {Computer Science, Information Systems}
}

@article{ISI:000379685700001,
  type = {Review},
  title = {Tools and Techniques for Computational Reproducibility},
  author = {Piccolo, Stephen R. and Frampton, Michael B.},
  year = {2016},
  month = jul,
  journal = {GIGASCIENCE},
  volume = {5},
  publisher = {{OXFORD UNIV PRESS}},
  address = {{GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND}},
  issn = {2047-217X},
  doi = {10.1186/s13742-016-0135-4},
  abstract = {When reporting research findings, scientists document the steps they followed so that others can verify and build upon the research. When those steps have been described in sufficient detail that others can retrace the steps and obtain similar results, the research is said to be reproducible. Computers play a vital role in many research disciplines and present both opportunities and challenges for reproducibility. Computers can be programmed to execute analysis tasks, and those programs can be repeated and shared with others. The deterministic nature of most computer programs means that the same analysis tasks, applied to the same data, will often produce the same outputs. However, in practice, computational findings often cannot be reproduced because of complexities in how software is packaged, installed, and executed-and because of limitations associated with how scientists document analysis steps. Many tools and techniques are available to help overcome these challenges; here we describe seven such strategies. With a broad scientific audience in mind, we describe the strengths and limitations of each approach, as well as the circumstances under which each might be applied. No single strategy is sufficient for every scenario; thus we emphasize that it is often useful to combine approaches.},
  affiliation = {Piccolo, SR (Corresponding Author), Brigham Young Univ, Dept Biol, Provo, UT 84602 USA. Piccolo, Stephen R., Brigham Young Univ, Dept Biol, Provo, UT 84602 USA. Frampton, Michael B., Brigham Young Univ, Dept Comp Sci, Provo, UT USA.},
  article-number = {30},
  author-email = {stephen\_piccolo@byu.edu},
  cited-references = {Afgan E, 2011, NAT BIOTECHNOL, V29, P972, DOI 10.1038/nbt.2028. Albrecht M., 2012, P 1 ACM SIGMOD WORKS. Altintas I, 2004, 16TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, PROCEEDINGS, P423. Anderson D. P., 2004, P 5 IEEE ACM INT WOR, P4. [Anonymous], 2015, NAT BIOTECHNOL, V33, P319, DOI 10.1038/nbt.3202. [Anonymous], 2014, NATURE, V514, P536, DOI 10.1038/514536a. [Anonymous], 2014, NAT METHODS, V11, P211, DOI 10.1038/nmeth.2880. [Anonymous], 2013, NATURE, V496, P398, DOI 10.1038/496398a. [Anonymous], 2012, NATURE, V487, P406, DOI 10.1038/487406a. [Anonymous], 2016, GENEPATTERN PLATFORM. [Anonymous], 2016, AG DEP MAN. [Anonymous], 2016, CLOUDBIOLINUX CONFIG. [Anonymous], 2016, ARCHIVE ENABLING REP. [Anonymous], 2016, IMCTFY LET ME CONTAI. Baggerly KA, 2009, ANN APPL STAT, V3, P1309, DOI 10.1214/09-AOAS291. Barton M., NUCLEOTIDES GENOME A. Belmann P, 2015, GIGASCIENCE, V4, DOI 10.1186/s13742-015-0087-0. Biasini M, 2013, ACTA CRYSTALLOGR D, V69, P701, DOI 10.1107/S0907444913007051. Bilal E, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003047. Bild AH, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001744. Bird I, 2011, ANNU REV NUCL PART S, V61, P99, DOI [10.1146/annurev-nucl-102010-l30059, 10.1146/annurev-nucl-102010-130059]. Blischak JD, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004668. Bradnam KR, 2013, GIGASCIENCE, V2, DOI 10.1186/2047-217X-2-10. Bremges A, 2015, GIGASCIENCE, V4, DOI 10.1186/s13742-015-0073-6. Brown CT., 2012, VIRTUAL MACHINES CON. Callahan S.P., 2006, P 2006 ACM SIGMOD IN, P745, DOI DOI 10.1145/1142473.1142574. Cassey P, 2006, BIOSCIENCE, V56, P958, DOI 10.1641/0006-3568(2006)56[958:RARIE]2.0.CO;2. Chambers JM, 1985, P 17 S INT STAT COMP, P211. Claerbout JF, 1992, M SOC EXPL GEOPH NEW. Collins FS, 2014, NATURE, V505, P612, DOI 10.1038/505612a. Crick T., SHARE ENJOY PUBLISHI. DAVIDSON SB, 2008, P 2008 ACM SIGMOD IN, P1345, DOI DOI 10.1145/1376616.1376772. Decullier Evelyne, 2013, BMC Res Notes, V6, P238, DOI 10.1186/1756-0500-6-238. Ding T, 2014, NATURE, V509, P357, DOI 10.1038/nature13178. Donoho DL, 2010, BIOSTATISTICS, V11, P385, DOI 10.1093/biostatistics/kxq028. Dudley JT, 2010, NAT BIOTECHNOL, V28, P1181, DOI 10.1038/nbt1110-1181. Eglen SJ, 2016, J SFDS, V157, P33. Eglen SJ, 2014, GIGASCIENCE, V3, DOI 10.1186/2047-217X-3-3. Felter W, 2014, UPDATED PERFORMANCE. Feynman RP, 1995, 6 EASY PIECES ESSENT, P34. Fisher R., 1935, DESIGN EXPT. Garijo D, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080278. Gent I. P., 2013, RECOMPUTATION MANIFE. Giardine B, 2005, GENOME RES, V15, P1451, DOI 10.1101/gr.4086505. Gil Y, 2007, COMPUTER, V40, P24, DOI 10.1109/MC.2007.421. Goecks J, 2010, GENOME BIOL, V11, DOI 10.1186/gb-2010-11-8-r86. Goff SA, 2011, FRONT PLANT SCI, V2, DOI 10.3389/fpls.2011.00034. GOLDBERG D, 1991, COMPUT SURV, V23, P5, DOI 10.1145/103162.103163. Gronenschild EHBM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038234. Gross A., 2014, NAT GENET, V46, P1. Halsey LG, 2015, NAT METHODS, V12, P179, DOI 10.1038/nmeth.3288. Heisen B., 2013, 14 INT C ACC LARG EX. Hey AJG, 2009, 4 PARADIGM DATA INTE. HONES MJ, 1990, PSA P SER, P585. Hong NC, 2014, WE ARE THE 92. Hothorn T, 2011, BRIEF BIOINFORM, V12, P288, DOI 10.1093/bib/bbq084. Howe B, 2012, COMPUT SCI ENG, V14, P36, DOI 10.1109/MCSE.2012.62. Huber W, 2015, NAT METHODS, V12, P115, DOI [10.1038/NMETH.3252, 10.1038/nmeth.3252]. Hurley DG, 2015, BRIEF BIOINFORM, V16, P901, DOI 10.1093/bib/bbu043. Ioannidis JPA, 2009, NAT GENET, V41, P149, DOI 10.1038/ng.295. Johnson VE, 2013, P NATL ACAD SCI USA, V110, P19313, DOI 10.1073/pnas.1313476110. Knight S, 2011, SCONS SOFTWARE CONST. KNUTH DE, 1984, COMPUT J, V27, P97, DOI 10.1093/comjnl/27.2.97. Koster J, 2012, BIOINFORMATICS, V28, P2520, DOI 10.1093/bioinformatics/bts480. Krampis K, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-42. Lazarus R, 2012, BIOINFORMATICS, V28, P3139, DOI 10.1093/bioinformatics/bts573. LeVeque RJ, 2012, COMPUT SCI ENG, V14, P13. Loeliger J, 2012, VERSION CONTROL GIT, P456. Martin R. C., 2009, CLEAN CODE HDB AGILE. McCarthy DJ, 2014, GENOME MED, V6, DOI 10.1186/gm543. Meadow JF, 2014, MICROBIOME, V2, DOI 10.1186/2049-2618-2-7. Michael C. C., 2012, EVOLUTION TRANSLATIO. Millman KJ, 2014, DEV OPEN SOURCE SCI, P149. Morin A, 2012, SCIENCE, V336, P159, DOI 10.1126/science.1218263. Moskvin O.V., 2014, SYSTEMS BIOMEDICINE, V2, P31. Murphy JM, 2004, NATURE, V430, P768, DOI 10.1038/nature02771. Murray-Rust P., 2014, IMPLEMENTING REPROD, P113. Nekrutenko A, 2012, NAT REV GENET, V13, P667, DOI 10.1038/nrg3305. Neuman JA, 2013, BRIEF BIOINFORM, V14, P46, DOI 10.1093/bib/bbs013. Peng RD, COURSERA COURSE EXPL. Peng RD, 2011, SCIENCE, V334, P1226, DOI 10.1126/science.1213847. Perez F, 2007, COMPUT SCI ENG, V9, P21, DOI 10.1109/MCSE.2007.53. Piccolo SR, 2014, BUILDING PORTABLE AN. Piwowar HA, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000308. Popper Karl, 1959, LOGIC SCI DISCOVERY. R Core Team, 2014, R LANG ENV STAT COMP. Ram Y, 2015, THEOR POPUL BIOL, V99, P1, DOI 10.1016/j.tpb.2014.10.004. Ransohoff DF, 2005, NAT REV CANCER, V5, P142, DOI 10.1038/nrc1550. Ravel J, 2014, MICROBIOME, V2, DOI 10.1186/2049-2618-2-8. Reich M, 2006, NAT GENET, V38, P500, DOI 10.1038/ng0506-500. Reich M, 2012, P 103 ANN M AM ASS C, V72, P3966. Rex DE, 2003, NEUROIMAGE, V19, P1033, DOI 10.1016/S1053-8119(03)00185-X. Rosenberg DM, 2016, J NEUROPHYSIOL A APR. RStudio Team, RSTUDIO INT DEV R. Russell JF, 2013, NATURE, V496, P7, DOI 10.1038/496007a. Sacks J., 1989, STAT SCI, V4, P409, DOI [10.1214/ss/1177012413, DOI 10.1214/SS/1177012413]. Sadedin SP, 2012, BIOINFORMATICS, V28, P1525, DOI 10.1093/bioinformatics/bts167. Sandve GK, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003285. Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]. Schneider CA, 2012, NAT METHODS, V9, P671, DOI 10.1038/nmeth.2089. Schofield PN, 2009, NATURE, V461, P171, DOI 10.1038/461171a. Shen H, 2014, NATURE, V515, P151, DOI 10.1038/515151a. Shirts M, 2000, SCIENCE, V290, P1903, DOI 10.1126/science.290.5498.1903. Stodden V, 2014, WHAT SCI IDEA IS REA. Stodden V., 2014, J OPEN RES STW, V2, P8, DOI [10.5334/jors.ay, DOI 10.5334/JORS.AY, DOI 10.5334/jors.ay]. Stodden V, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067111. Tan E, 2006, GEOCHEM GEOPHY GEOSY, P7. Tange O, 2011, THE USENIX MAGAZINE, V36, P42, DOI [DOI 10.5281/ZEN0D0.16303, 10.5281/zenodo.16303]. Toronto Int Data Release Workshop, 2009, NATURE, V461, P168, DOI 10.1038/461168a. Toth G, 2005, J GEOPHYS RES-SPACE, V110, DOI 10.1029/2005JA011126. Vandewalle P, 2007, IEEE INT C AC SPEECH, V2007. Wilson G, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001745. Wilson Greg, 2014, F1000Res, V3, P62, DOI 10.12688/f1000research.3-62.v2. Wolstencroft K, 2013, NUCLEIC ACIDS RES, V41, pW557, DOI 10.1093/nar/gkt328. Xie Y, 2013, DYNAMIC DOCUMENTS R, P216.},
  da = {2021-06-23},
  doc-delivery-number = {DR1SR},
  funding-acknowledgement = {Brigham Young University},
  funding-text = {SRP acknowledges startup funds provided by Brigham Young University. We thank research-community members and reviewers who provided valuable feedback on this manuscript.},
  journal-iso = {GigaScience},
  keywords-plus = {MICROBIAL COMMUNITY; BIOINFORMATICS; GALAXY; CLOUD; FRAMEWORK; SOFTWARE; REPEATABILITY; PLATFORM; IMAGE},
  language = {English},
  number-of-cited-references = {115},
  oa = {DOAJ Gold, Green Published},
  research-areas = {Life Sciences \& Biomedicine - Other Topics; Science \& Technology - Other Topics},
  times-cited = {46},
  unique-id = {ISI:000379685700001},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {17},
  web-of-science-categories = {Biology; Multidisciplinary Sciences},
  keywords = {Computational reproducibility; Practice of science; Literate programming; Virtualization; Software containers; Software frameworks},
  file = {/Users/awwillc/Zotero/storage/ZGQZ9SGY/Piccolo and Frampton - 2016 - Tools and techniques for computational reproducibi.pdf}
}

@article{ISI:000399841400005,
  type = {Article},
  title = {Computational Reproducibility in Archaeological Research: {{Basic}} Principles and a Case Study of Their Implementation},
  author = {Marwick, Ben},
  year = {2017},
  month = jun,
  journal = {JOURNAL OF ARCHAEOLOGICAL METHOD AND THEORY},
  volume = {24},
  number = {2},
  pages = {424--450},
  publisher = {{SPRINGER}},
  address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
  issn = {1072-5369},
  doi = {10.1007/s10816-015-9272-9},
  abstract = {The use of computers and complex software is pervasive in archaeology, yet their role in the analytical pipeline is rarely exposed for other researchers to inspect or reuse. This limits the progress of archaeology because researchers cannot easily reproduce each other's work to verify or extend it. Four general principles of reproducible research that have emerged in other fields are presented. An archaeological case study is described that shows how each principle can be implemented using freely available software. The costs and benefits of implementing reproducible research are assessed. The primary benefit, of sharing data in particular, is increased impact via an increased number of citations. The primary cost is the additional time required to enhance reproducibility, although the exact amount is difficult to quantify.},
  affiliation = {Marwick, B (Corresponding Author), Univ Washington, Dept Anthropol, Seattle, WA 98195 USA. Marwick, B (Corresponding Author), Univ Wollongong, Ctr Archaeol Sci, Wollongong, NSW, Australia. Marwick, Ben, Univ Washington, Dept Anthropol, Seattle, WA 98195 USA. Marwick, Ben, Univ Wollongong, Ctr Archaeol Sci, Wollongong, NSW, Australia.},
  author-email = {bmarwick@uw.edu},
  cited-references = {Abari K., 2012, INT J COMPUTER SCI I, V9, P43. Arbuckle BS, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099845. Baggerly KA, 2009, ANN APPL STAT, V3, P1309, DOI 10.1214/09-AOAS291. Barnes N, 2010, NATURE, V467, P753, DOI 10.1038/467753a. Bassi S, 2007, PLOS COMPUT BIOL, V3, P2052, DOI 10.1371/journal.pcbi.0030199. Baumer B., 2014, TECHNOLOGY INNOVATIO, V8, P1. Baumer B, 2015, WILEY INTERDISCIP RE, V7, P167, DOI 10.1002/wics.1348. Beale N, 2012, WORLD ARCHAEOL, V44, P612, DOI 10.1080/00438243.2012.743252. Begley CG, 2015, CIRC RES, V116, P116, DOI 10.1161/CIRCRESAHA.114.303819. Bivand RS, 2008, USE R, P1. Bocinsky RK, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms6618. Bocinsky RK, 2014, J ANTHROPOL ARCHAEOL, V35, P164, DOI 10.1016/j.jaa.2014.05.003. Boettiger Carl, 2015, ACM SIGOPS Operating Systems Review, V49, P71. Boettiger C., 2015, J OPEN RES SOFTWARE, V3, pe8. Bonhomme V, 2014, J STAT SOFTW, V56, P1. Borck L, 2015, J ARCHAEOL METHOD TH, V22, P33, DOI 10.1007/s10816-014-9236-5. Borgman CL, 2012, J AM SOC INF SCI TEC, V63, P1059, DOI 10.1002/asi.22634. Boyer MA, 2003, INT STUDIES PERSPECT, V4, DOI DOI 10.1111/1528-3577.04105. Buckheit J. B., 1995, WAVELETS STAT, P55, DOI [10.1007/978-1-4612-2544-7\_5., DOI 10.1007/978-1-4612-2544-7\_5]. Buffalo V, 2015, BIOINFORMATICS DATA. Chambers JM, 2008, STAT COMPUT SER, P1. Clarkson C, 2015, J HUM EVOL, V83, P46, DOI 10.1016/j.jhevol.2015.03.014. Contreras DA, 2014, J ARCHAEOL SCI, V52, P591, DOI 10.1016/j.jas.2014.05.030. Crema ER, 2014, J ARCHAEOL SCI, V50, P160, DOI 10.1016/j.jas.2014.07.014. Dafoe A, 2014, PS-POLIT SCI POLIT, V47, P60, DOI 10.1017/S104909651300173X. Delescluse M, 2012, J PHYSIOL-PARIS, V106, P159, DOI 10.1016/j.jphysparis.2011.09.011. Donoho DL, 2009, COMPUT SCI ENG, V11, P8, DOI 10.1109/MCSE.2009.15. Dorch S, 2012, CITATION ADVANTAGE L. Drake BL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095580. Dudley JT, 2010, NAT BIOTECHNOL, V28, P1181, DOI 10.1038/nbt1110-1181. Dye TS, 2011, ARCHAEOL OCEAN, V46, P130, DOI 10.1002/j.1834-4453.2011.tb00107.x. Eglen SJ, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000482. Faris J, 2011, OMICS, V15, P213, DOI 10.1089/omi.2011.0008. Gandrud C., 2013, REPRODUCIBLE RES R R. Gandrud C., 2013, POLITICAL METHODOL, V20, P7. Gentleman R, 2007, J COMPUT GRAPH STAT, V16, P1, DOI 10.1198/106186007X178663. Glatard T, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00012. Guedes JD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130430. Haddock SHD, 2011, PRACTICAL COMPUTING. HATTON L, 1994, IEEE T SOFTWARE ENG, V20, P785, DOI 10.1109/32.328993. Healy Kieran, 2011, POLITICAL METHODOLOG, V18, P9. Henley Mark, 2008, Computer Law \& Security Report, V24, P77, DOI 10.1016/j.clsr.2007.11.003. Henneken E. A., 2011, ABS11113618 CORR. Herndon T, 2014, CAMB J ECON, V38, P257, DOI 10.1093/cje/bet075. Hoffa Christina, 2008, 2008 IEEE Fourth International Conference on eScience, P640, DOI 10.1109/eScience.2008.167. Howe B, 2012, COMPUT SCI ENG, V14, P36, DOI 10.1109/MCSE.2012.62. Ince DC, 2012, NATURE, V482, P485, DOI 10.1038/nature10836. Janssen MA, 2008, JASSS-J ARTIF SOC S, V11. Jones Z. M., 2013, POLITICAL METHODOLOG, V21, P6. Joppa LN, 2013, SCIENCE, V340, P814, DOI 10.1126/science.1231535. Kahle D, 2013, R J, V5, P144. Kansa E. C., 2011, COTSEN DIGITAL ARCHA. Kansa E, 2012, WORLD ARCHAEOL, V44, P498, DOI 10.1080/00438243.2012.737575. Keeling KB, 2007, COMPUT STAT DATA AN, V51, P3811, DOI 10.1016/j.csda.2006.02.013. KING G, 1995, PS, V28, P444, DOI 10.2307/420301. Kintigh K, 2006, AM ANTIQUITY, V71, P567, DOI 10.2307/40035365. Kintigh KW, 2014, P NATL ACAD SCI USA, V111, P879, DOI 10.1073/pnas.1324000111. KNUTH DE, 1984, COMPUT J, V27, P97, DOI 10.1093/comjnl/27.2.97. Laine C, 2007, ANN INTERN MED, V146, P450, DOI 10.7326/0003-4819-146-6-200703200-00154. Lang Serge, 1993, Ethics Behav, V3, P3, DOI 10.1207/s15327019eb0301\_1. Leisch F, 2011, PROCEDIA COMPUT SCI, V4, P618, DOI 10.1016/j.procs.2011.04.065. Leonard R. D., 2010, QUANTITATIVE ANAL AR. Loeliger Jon, 2012, VERSION CONTROL GIT. Lowe KM, 2014, ARCHAEOL OCEAN, V49, P148, DOI 10.1002/arco.5039. Mackay A, 2014, QUATERN INT, V350, P43, DOI 10.1016/j.quaint.2014.05.007. Mair P, 2015, P NATL ACAD SCI USA, V112, P14788, DOI 10.1073/pnas.1506047112. Markowetz F., 2015, GENOME BIOL, V16. Marwick B., 2015, CODE DATA REPOSITORY. Marwick B, 2013, J ANTHROPOL ARCHAEOL, V32, P553, DOI 10.1016/j.jaa.2013.08.004. McCullough BD, 2008, CAN J ECON, V41, P1406, DOI 10.1111/j.1540-5982.2008.00509.x. McCullough BD, 2007, ECON J WATCH, V4, P326. McCullough BD, 2006, J MONEY CREDIT BANK, V38, P1093, DOI 10.1353/mcb.2006.0061. McCullough BD, 2003, AM ECON REV, V93, P873, DOI 10.1257/000282803322157133. Miguel E, 2014, SCIENCE, V343, P30, DOI 10.1126/science.1245317. Miller G, 2006, SCIENCE, V313, P431, DOI 10.1126/science.313.5786.431. Morandat F, 2012, LECT NOTES COMPUT SC, V7313, P104, DOI 10.1007/978-3-642-31057-7\_6. Morin A, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002598. Narasimhan B, 2005, J STAT SOFTW, V13, P1. Noble WS, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000424. Nosek BA, 2015, SCIENCE, V348, P1422, DOI 10.1126/science.aab2374. Nowakowski P, 2011, PROCEDIA COMPUT SCI, V4, P608, DOI 10.1016/j.procs.2011.04.064. Peeples MA, 2012, J ARCHAEOL SCI, V39, P2818, DOI 10.1016/j.jas.2012.04.040. Peng RD, 2011, SCIENCE, V334, P1226, DOI 10.1126/science.1213847. Peng RD, 2009, BIOSTATISTICS, V10, P405, DOI 10.1093/biostatistics/kxp014. Perkel JM, 2015, NATURE, V518, P125, DOI 10.1038/518125a. Pienta A. M., 2010, ENDURING VALUE SOCIA. Piwowar HA, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000308. Piwowar HA, 2013, PEERJ, V1, DOI 10.7717/peerj.175. Plummer M., 2003, P 3 INT WORKSH DISTR, V3, P20, DOI DOI 10.1038/S41598-018-29599-W. Ram K, 2013, SOURCE CODE BIOL MED, V8, DOI 10.1186/1751-0473-8-7. REICH V, 2008, SERIALS LIBR, V54, P135, DOI DOI 10.1080/03615260801973968. Reshef DN, 2011, SCIENCE, V334, P1518, DOI 10.1126/science.1205438. Richards JD, 1997, ANTIQUITY, V71, P1057, DOI 10.1017/S0003598X00086014. Rieth C., 2013, SAA ARCHAEOLOGICAL R, P42. Sandve GK, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003285. Sarkar D, 2008, USE R, P1. Schulte E, 2012, J STAT SOFTW, V46, P1. Schwab M, 2000, COMPUT SCI ENG, V2, P61, DOI 10.1109/5992.881708. Scopatz A., 2015, EFFECTIVE COMPUTATIO. Sears J., 2011, AGU FALL M, V1, P1628. Sharpe D, 2013, PSYCHOL METHODS, V18, P572, DOI 10.1037/a0034177. Shennan SJ, 2015, EVOL HUM BEHAV, V36, P103, DOI 10.1016/j.evolhumbehav.2014.09.006. Stanisic Luka, 2015, ACM SIGOPS Operating Systems Review, V49, P61. Stodden V., 2014, J OPEN RES SOFTWARE, V2, pE21, DOI DOI 10.5334/J0RS.AY. Stodden V, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067111. Stodden V, 2009, COMPUT SCI ENG, V11, P35, DOI 10.1109/MCSE.2009.19. Teal T. K., 2015, INT J DIGIT CURATION, V10, P343, DOI [10.2218/ijdc.v10i1.351., DOI 10.2218/IJDC.V10I1.351, 10.2218/ijdc.v10i1.351]. Tenopir C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021101. Thompson P. A., 2012, CORE ISSUES PROFESSI, V1. Tippmann S, 2015, NATURE, V517, P109, DOI 10.1038/517109a. Vandewalle P, 2012, COMPUT SCI ENG, V14, P42, DOI 10.1109/MCSE.2012.63. Vihinen M, 2015, NATURE, V521, P261, DOI 10.1038/521261a. Wicherts JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0026828. Wickham H., 2015, R PACKAGES, V1st ed.. Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3\_1. Wickham Hadley, 2014, ADV R. Widemann B. T., 2013, TRENDS FUNCTIONAL PR, V7829, P182, DOI [10.1007/978-3-642-40447-4\_12, DOI 10.1007/978-3-642-40447-4\_12]. WILSON G., 2014, F1000RESEARCH, DOI 10.12688/f1000research.3-62.v1. Wilson G, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001745. Xie Y., 2013, DYNAMIC DOCUMENTS R.},
  da = {2021-06-23},
  doc-delivery-number = {ES8XY},
  eissn = {1573-7764},
  funding-acknowledgement = {ARCAustralian Research Council [DP110102864]; University of Washington eScience Institute},
  funding-text = {Thanks to Chris Clarkson, Mike Smith, Richard Fullagar, Lynley A. Wallis, Patrick Faulkner, Tiina Manne, Elspeth Hayes, Richard G. Roberts, Zenobia Jacobs, Xavier Carah, Kelsey M. Lowe, and Jacqueline Matthews for their cooperation with the JHE paper. Thanks to the Mirarr Senior Traditional Owners, and to our research partners, the Gundjeimhi Aboriginal Corporation, for granting permission to carry out the research that was published in the JHE paper, and led to this paper. Thanks to Kyle Bocinsky and Oliver Nakoinz for their helpful peer reviews and many constructive suggestions. This research was carried out as part of ARC Discovery Project DP110102864. This work was supported in part by the University of Washington eScience Institute, and especially benefited from the expertise of the Reproducibility and Open Science working group. An earlier version was presented at an International Neuroinformatics Coordinating Facility (INCF) meeting in December 2014 organised by Stephen Eglen, and benefited from discussion during that meeting. I am a contributor to the Software and Data Carpentry projects and the rOpenSci collective; beyond this, I declare that I have no conflict of interest.},
  journal-iso = {J. Archaeol. Method Theory},
  keywords-plus = {SCIENCE; COMMUNITY; COMMUNICATION; TRANSPARENCY; REPLICATION; FRAMEWORK; DESIGN; REUSE; SITE; CODE},
  language = {English},
  number-of-cited-references = {120},
  orcid-numbers = {Marwick, Ben/0000-0001-7879-4531},
  research-areas = {Anthropology; Archaeology},
  researcherid-numbers = {Marwick, Ben/H-1747-2013},
  times-cited = {73},
  unique-id = {ISI:000399841400005},
  usage-count-last-180-days = {3},
  usage-count-since-2013 = {12},
  web-of-science-categories = {Anthropology; Archaeology},
  keywords = {Reproducible research; Computer programming; Software engineering; Australian archaeology; Open science}
}

@article{ISI:000404704400023,
  type = {Article},
  title = {Scientific Workflows for Computational Reproducibility in the Life Sciences: {{Status}}, Challenges and Opportunities},
  author = {{Cohen-Boulakia}, Sarah and Belhajjame, Khalid and Collin, Olivier and Chopard, Jerome and Froidevaux, Christine and Gaignard, Alban and Hinsen, Konrad and Larmande, Pierre and Le Brass, Yvan and Lemoine, Frederic and Mareuil, Fabien and Menager, Herve and Pradal, Christophe and Blanchet, Christophe},
  year = {2017},
  month = oct,
  journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
  volume = {75},
  pages = {284--298},
  publisher = {{ELSEVIER SCIENCE BV}},
  address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
  issn = {0167-739X},
  doi = {10.1016/j.future.2017.01.012},
  abstract = {With the development of new experimental technologies, biologists are faced with an avalanche of data to be computationally analyzed for scientific advancements and discoveries to emerge. Faced with the complexity of analysis pipelines, the large number of computational tools, and the enormous amount of data to manage, there is compelling evidence that many if not most scientific discoveries will not stand the test of time: increasing the reproducibility of computed results is of paramount importance. The objective we set out in this paper is to place scientific workflows in the context of reproducibility. To do so, we define several kinds of reproducibility that can be reached when scientific workflows are used to perform experiments. We characterize and define the criteria that need to be catered for by reproducibility-friendly scientific workflow systems, and use such criteria to place several representative and widely used workflow systems and companion tools within such a framework. We also discuss the remaining challenges posed by reproducible scientific workflows in the life sciences. Our study was guided by three use cases from the life science domain involving in silico experiments. (C) 2017 Elsevier B.V. All rights reserved.},
  affiliation = {Cohen-Boulakia, S (Corresponding Author), Univ Paris Saclay, Univ Paris Sud, CNRS UMR 8623, Lab Rech Informat, Orsay, France. Cohen-Boulakia, Sarah; Froidevaux, Christine, Univ Paris Saclay, Univ Paris Sud, CNRS UMR 8623, Lab Rech Informat, Orsay, France. Cohen-Boulakia, Sarah; Pradal, Christophe, Inria, VirtualPlants, Montpellier, France. Cohen-Boulakia, Sarah; Larmande, Pierre, Inria, Zenith, Montpellier, France. Belhajjame, Khalid, Univ Paris 09, PSL Res Univ, CNRS, Ctr Lamsade,UMR7243, F-75016 Paris, France. Collin, Olivier, IRISA, Rennes, France. Chopard, Jerome, INRA, MISTEA, UMR729, F-34060 Montpellier, France. Gaignard, Alban, CHU Nantes, Nantes Acad Hosp, Nantes, France. Hinsen, Konrad, CNRS UPR4301, Ctr Biophys Mol, Orleans, France. Larmande, Pierre, IRD, DIADE, F-34394 Montpellier, France. Le Brass, Yvan, EnginesOn INRIA, Rennes, France. Lemoine, Frederic, USR 3756 IP CNRS, Inst Pasteur, Ctr Bioinformat Biostat \& Biol Integrat, Unite Bioinformat Evolut, Paris, France. Mareuil, Fabien; Menager, Herve, USR 3756 IP CNRS, Inst Pasteur, Ctr Bioinformat Biostat \& Biol Integrat, Hub Bioinformat \& Biostat, Paris, France. Mareuil, Fabien; Menager, Herve, Direct Syst Informat, Inst Pasteur, Ctr Informat Biol, Paris, France. Pradal, Christophe, UMR AGAP, CIRAD, Montpellier, France. Blanchet, Christophe, CNRS, UMS 3601, Ave Terrasse, F-91190 Gif Sur Yvette, France. Blanchet, Christophe, Inst Francais Bioinformat, IFB Core, Ave Terrasse, F-91190 Gif Sur Yvette, France.},
  author-email = {cohen@lri.fr},
  cited-references = {Abouelhoda M, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-77. Alper Pinar, 2013, P JOINT EDBT ICDT 20, P313, DOI [10.1145/2457317.2457370, DOI 10.1145/2457317.2457370]. Alsheikh-Ali AA, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024357. Amstutz P., 2016, COMMON WORK IN PRESS. Begley CG, 2015, CIRC RES, V116, P116, DOI 10.1161/CIRCRESAHA.114.303819. Begley CG, 2012, NATURE, V483, P531, DOI 10.1038/483531a. Belhajjame K, 2015, J WEB SEMANT, V32, P16, DOI 10.1016/j.websem.2015.01.003. Bergmann R, 2014, INFORM SYST, V40, P115, DOI 10.1016/j.is.2012.07.005. BHAGAT J, 2010, NUCLEIC ACIDS RES. Biton O. S., 2007, P 33 INT C VER LARG, P1366. Blankenberg D, 2014, GENOME BIOL, V15, DOI 10.1186/gb4161. Boettiger Carl, 2015, ACM SIGOPS Operating Systems Review, V49, P71. Brown TB, 2014, CURR OPIN PLANT BIOL, V18, P73, DOI 10.1016/j.pbi.2014.02.002. Cerezo N., 2011, P 6 WORKSH WORKFL SU, P1, DOI [10.1145/2110497.2110499, DOI 10.1145/2110497.2110499]. Chen J., 2014, P 26 INT C SCI STAT, P46. Chirigati FS, 2013, TAPP. Cohen-Boulakia S, 2011, SIGMOD REC, V40, P6, DOI 10.1145/2034863.2034865. Conesa A., 2016, GENOME BIOL. Costa F, 2013, P JOINT EDBT ICDT 20, P282. De Roure D, 2009, FUTURE GENER COMP SY, V25, P561, DOI 10.1016/j.future.2008.06.010. Drummond C., 2009, REPLICABILITY UNPUB. Errington TM, 2014, ELIFE, V3, DOI 10.7554/eLife.04333. Freedman LP, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002165. Freire J., 2016, TECHNICAL REPORT. Freire J. P., 2012, P 2012 ACM SIGMOD IN, P593, DOI DOI 10.4230/DAGREP.6.1.108. Freire J, 2006, LECT NOTES COMPUT SC, V4145, P10. Furbank RT, 2011, TRENDS PLANT SCI, V16, P635, DOI 10.1016/j.tplants.2011.09.005. Gaignard A, 2014, J WEB SEMANT, V29, P19, DOI 10.1016/j.websem.2014.07.001. Garijo D, 2014, FUTURE GENER COMP SY, V36, P338, DOI 10.1016/j.future.2013.09.018. Garijo D, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080278. Giardine B, 2005, GENOME RES, V15, P1451, DOI 10.1101/gr.4086505. Gibson A, 2009, FUTURE GENER COMP SY, V25, P453, DOI 10.1016/j.future.2008.09.009. Goble C., 2013, COMMUNICATION. Goecks J, 2010, GENOME BIOL, V11, DOI 10.1186/gb-2010-11-8-r86. Gonzalez-Beltran A., 2014, BIORXIV. Gonzalez-Beltran A, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-S14-S4. Goodman SN, 2016, SCI TRANSL MED, V8, DOI 10.1126/scitranslmed.aaf5027. Guo PJ, 2012, COMPUT SCI ENG, V14, P32, DOI 10.1109/MCSE.2012.36. Harmassi M, 2015, LECT NOTES COMPUT SC, V9398, P76, DOI 10.1007/978-3-319-27932-9\_7. Hettne K.M., 2012, SWAT4LS. Hirschman L., 2012, TEXT MINING BIOCURAT, V2012. Ison J, 2016, NUCLEIC ACIDS RES, V44, pD38, DOI 10.1093/nar/gkv1116. Juve G, 2013, FUTURE GENER COMP SY, V29, P682, DOI 10.1016/j.future.2012.08.015. Koenig Dierk, 2007, GROOVY IN ACTION, V1. Koster J, 2012, BIOINFORMATICS, V28, P2520, DOI 10.1093/bioinformatics/bts480. Korkhov V., 2012, STUD HLTH TECHNOL IN, V175. Kurs J.P., 2016, BIORXIV. Leipzig J, 2017, BRIEF BIOINFORM, V18, P530, DOI 10.1093/bib/bbw020. Ludascher B, 2003, SSDBM 2002: 15TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, P251. Ludascher B., 2003, PROVIDING DECL UNPUB. Ma YL, 2015, INFORM SCIENCES, V314, P1, DOI 10.1016/j.ins.2015.03.055. Mardis ER, 2011, NATURE, V470, P198, DOI 10.1038/nature09796. Mates Phillip, 2011, Scientific and Statistical Database Management. Proceedings 23rd International Conference, SSDBM 2011, P555, DOI 10.1007/978-3-642-22351-8\_38. McPhillips T., 2015, ARXIV150202403. Meyerson M, 2010, NAT REV GENET, V11, P685, DOI 10.1038/nrg2841. Missier P, 2008, LECT NOTES COMPUT SC, V5272, P17, DOI 10.1007/978-3-540-89965-5\_4. Murta L, 2015, LECT NOTES COMPUT SC, V8628, P71, DOI 10.1007/978-3-319-16462-5\_6. Nekrutenko A, 2012, NAT REV GENET, V13, P667, DOI 10.1038/nrg3305. Oinn T., 2002, J CONCURR COMPUT PRA. Peng RD, 2009, BIOSTATISTICS, V10, P405, DOI 10.1093/biostatistics/kxp014. Perez F, 2007, COMPUT SCI ENG, V9, P21, DOI 10.1109/MCSE.2007.53. Plankensteiner K, 2013, J GRID COMPUT, V11, P429, DOI 10.1007/s10723-013-9261-8. Plankensteiner P., 2011, P 6 WORKSH WORKFL SU, P97. Pradal C., 2016, FUTURE GENER COMPUT. Pradal C, 2015, P 27 INT C SCI STAT, P11. Pradal C, 2008, FUNCT PLANT BIOL, V35, P751, DOI 10.1071/FP08084. Racine JS, 2012, J APPL ECONOMET, V27, P167, DOI 10.1002/jae.1278. Ragan-Kelley M, 2014, AGU FALL M, V1, P7. Richter SH, 2010, NAT METHODS, V7, P167, DOI 10.1038/nmeth0310-167. Santori G, 2016, NATURE, V535, P355, DOI 10.1038/535355b. Schurr U., 2015, EPPN PLANT PHEN S BA, P1. Smith MA, 2013, CLIN CANCER RES, V19, P2828, DOI 10.1158/1078-0432.CCR-13-0043. Soiland-Reyes S., 2014, SCUFL2 WFDESC UNPUB. Starlinger J, 2016, FUTURE GENER COMP SY, V56, P584, DOI 10.1016/j.future.2015.06.012. Starlinger J, 2014, PROC VLDB ENDOW, V7, P1143, DOI 10.14778/2732977.2732988. Stodden V., 2014, IMPLEMENTING REPROD. Stodden V, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067111. Tommaso P.D., 2014, NOVEL TOOL HIG UNPUB. Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18. Wilson G., 2013, F1000RESEARCH, V3, P62. Wolstencroft K, 2013, NUCLEIC ACIDS RES, V41, pW557, DOI 10.1093/nar/gkt328. Yaffe MB, 2015, SCI SIGNAL, V8, DOI 10.1126/scisignal.aaa5764. Zhao J, 2012, P IEEE INT C E-SCI, DOI 10.1109/eScience.2012.6404482. Zheng CL, 2015, GENOME MED, V7, DOI 10.1186/s13073-015-0202-y.},
  da = {2021-06-23},
  doc-delivery-number = {EZ4TC},
  eissn = {1872-7115},
  funding-acknowledgement = {GDR CNRS MaDICS; programme CPER Region Bretagne ``CeSGO''; programme Region Pays de la Loire ``Connect Talent'' (SyMeTRIC); call ``Infrastructures in Biology and Health'' of the French ``Investments for the Future'' [ANR-11-INBS-0012, ANR-11-INBS-0013]},
  funding-text = {The authors acknowledge the support of GDR CNRS MaDICS, programme CPER Region Bretagne ``CeSGO'', and programme Region Pays de la Loire ``Connect Talent'' (SyMeTRIC). We acknowledge funding by the call ``Infrastructures in Biology and Health'' in the framework of the French ``Investments for the Future'' (ANR-11-INBS-0012 and ANR-11-INBS-0013). This work was conducted in part at the IBC (Institute of Computational Biology) in Montpellier, France.},
  journal-iso = {Futur. Gener. Comp. Syst.},
  keywords-plus = {SOFTWARE; GALAXY; RETRIEVAL; PLATFORM; SEARCH},
  language = {English},
  number-of-cited-references = {84},
  oa = {Green Accepted},
  orcid-numbers = {Menager, Herve/0000-0002-7552-1009 Mareuil, Fabien/0000-0002-3832-9157 Gaignard, Alban/0000-0002-3597-8557 Larmande, Pierre/0000-0002-2923-9790 COHEN-BOULAKIA, Sarah/0000-0002-7439-1441 Le Bras, Yvan/0000-0002-8504-068X Pradal, Christophe/0000-0002-2555-761X Collin, Olivier/0000-0002-8959-8402 Hinsen, Konrad/0000-0003-0330-9428},
  research-areas = {Computer Science},
  researcherid-numbers = {Menager, Herve/I-2258-2019 Mareuil, Fabien/AAO-2844-2020 Hinsen, Konrad/X-1363-2019 Gaignard, Alban/D-1333-2018 Larmande, Pierre/F-2144-2016 Le Bras, Yvan/B-4017-2010},
  times-cited = {40},
  unique-id = {ISI:000404704400023},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {31},
  web-of-science-categories = {Computer Science, Theory \& Methods},
  keywords = {Reproducibility; Scientific workflows; Provenance; Packaging environments}
}

@article{ISI:000411546100013,
  type = {Article},
  title = {Computational Reproducibility of ``{{Goal}} Relevance and Goal Conduciveness Appraisals Lead to Differential Autonomic Reactivity in Emotional Responding to Performance Feedback'' ({{Kreibig}}, {{Gendolla}}, \& {{Scherer}}, 2012): {{A}} Guide and New Evidence},
  author = {Kreibig, Sylvia D.},
  year = {2017},
  month = sep,
  journal = {INTERNATIONAL JOURNAL OF PSYCHOPHYSIOLOGY},
  volume = {119},
  number = {SI},
  pages = {93--107},
  publisher = {{ELSEVIER SCIENCE BV}},
  address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
  issn = {0167-8760},
  doi = {10.1016/j.ijpsycho.2017.06.001},
  abstract = {The emerging field of the psychophysiology of motivation bears many new findings, but little replication. Using my own data (Kreibig, Gendolla, \& Scherer, 2012), I test the reproducibility of this specific study, provide the necessary materials to make the study reproducible, and instantiate proper reproducibility practices that other researchers can use as a road map toward the same goal. In addition, based on re-analyses of the original data, I report new evidence for the motivational effects of emotional responding to performance feedback. Specifically, greater appraisal of goal relevance amplifies the emotional response to events appraised as conducive (i.e., effort mobilization), but not to those appraised as obstructive to a person's goals (i.e., effort withdrawal). I conclude by providing a ten-step road map of best practices to facilitate computational reproducibility for future studies.},
  affiliation = {Kreibig, SD (Corresponding Author), Stanford Univ, Dept Psychol, Stanford, CA 94305 USA. Kreibig, Sylvia D., Stanford Univ, Dept Psychol, Stanford, CA 94305 USA.},
  author-email = {skreibig@stanford.edu},
  cited-references = {American Psychological Association, 2017, LINKS DAT SETS REP. Annis S, 2001, J APPL BIOBEHAV RES, V6, P82, DOI 10.1111/j.1751-9861.2001.tb00108.x. Armel KC, 2003, P ROY SOC B-BIOL SCI, V270, P1499, DOI 10.1098/rspb.2003.2364. Armstrong RA, 2014, OPHTHAL PHYSL OPT, V34, P502, DOI 10.1111/opo.12131. Baggerly K.K., 2016, STAT CHALLENGES ASSE. Bakeman R, 2005, BEHAV RES METHODS, V37, P379, DOI 10.3758/BF03192707. Baldwin SA, 2017, INT J PSYCHOPHYSIOL, V111, P5, DOI 10.1016/j.ijpsycho.2016.04.006. Berntson GG, 2008, PSYCHOPHYSIOLOGY, V45, P643, DOI 10.1111/j.1469-8986.2008.00652.x. Betella A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148037. Blakesley RE, 2009, NEUROPSYCHOLOGY, V23, P255, DOI 10.1037/a0012850. Boekel W, 2017, PSYCHOPHYSIOLOGY, V54, P24, DOI 10.1111/psyp.12769. Boettiger Carl, 2015, ACM SIGOPS Operating Systems Review, V49, P71. Bollen K., 2015, SOCIAL BEHAV EC SCI. Bonferroni C., 1936, PUBBLICAZIONI R I SU, V8, P3. Bonferroni C.E.C.E., 1935, TIPOGRAFIA SENATOPP, P13. Boucsein W., 1992, ELECTRODERMAL ACTIVI. Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0. Bradford DE, 2015, PSYCHOPHYSIOLOGY, V52, P1669, DOI 10.1111/psyp.12545. BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9. BREHM JW, 1989, ANNU REV PSYCHOL, V40, P109, DOI 10.1146/annurev.ps.40.020189.000545. Burgess AP, 1997, INT J PSYCHOPHYSIOL, V26, P113, DOI 10.1016/S0167-8760(97)00759-9. Cecotti H, 2017, INT J PSYCHOPHYSIOL, V111, P156, DOI 10.1016/j.ijpsycho.2016.07.500. Chirigati F.F., 2013, 5USENIX WORKSH THEOR. Claerbout J.J., 1992, P SOC EXPL GEOPH SEA. Cohen J., 1988, STAT POWER ANAL BEHA. Collins H.M., 1992, CHANGING ORDER REPLI. Crepinsek M, 2014, APPL SOFT COMPUT, V19, P161, DOI 10.1016/j.asoc.2014.02.009. Cumming G, 2006, PSYCHOL METHODS, V11, P217, DOI 10.1037/1082-989X.11.3.217. Cumming G, 2008, PERSPECT PSYCHOL SCI, V3, P286, DOI 10.1111/j.1745-6924.2008.00079.x. Development Core Team R.R, 2007, R LANG ENV STAT COMP. Donoho DL, 2010, BIOSTATISTICS, V11, P385, DOI 10.1093/biostatistics/kxq028. Donoho DL, 2009, COMPUT SCI ENG, V11, P8, DOI 10.1109/MCSE.2009.15. EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552. Elkins-Brown N, 2016, PSYCHOPHYSIOLOGY, V53, P159, DOI 10.1111/psyp.12556. Gallopoulos E., 1994, IEEE Computational Science and Engineering, V1, P11, DOI 10.1109/99.326669. Garijo D, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080278. Gendolla GHE, 2001, PSYCHOPHYSIOLOGY, V38, P548, DOI 10.1017/S0048577201000622. Gendolla GHE, 2010, REV GEN PSYCHOL, V14, P212, DOI 10.1037/a0019742. Gentleman R, 2005, STAT APPL GENET MOL, V4, DOI 10.2202/1544-6115.1034. Groppe DM, 2017, PSYCHOPHYSIOLOGY, V54, P139, DOI 10.1111/psyp.12616. Hefner KR, 2016, PSYCHOPHYSIOLOGY, V53, P1193, DOI 10.1111/psyp.12660. Herndon T, 2014, CAMB J ECON, V38, P257, DOI 10.1093/cje/bet075. Hewes DE, 2003, HUM COMMUN RES, V29, P448, DOI 10.1093/hcr/29.3.448. Hsu J.C., 1996, MULTIPLE COMP THEORY. Hullett CR, 2007, COMMUN METHODS MEAS, V1, P275, DOI 10.1080/19312450701642308. Ioannidis JPA, 2011, SCIENCE, V334, P1230, DOI 10.1126/science.1211811. Ito TA, 1998, J PERS SOC PSYCHOL, V75, P887, DOI 10.1037/0022-3514.75.4.887. Kanwal S, 2015, COMP MED SY, P220, DOI 10.1109/CBMS.2015.28. Kappenman ES, 2017, PSYCHOPHYSIOLOGY, V54, P3, DOI 10.1111/psyp.12787. Kaye JT, 2016, PSYCHOPHYSIOLOGY, V53, P1241, DOI 10.1111/psyp.12663. Kidwell MC, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002456. Kreibig SD, 2015, PSYCHOPHYSIOLOGY, V52, P873, DOI 10.1111/psyp.12425. Kreibig SD, 2012, BIOL PSYCHOL, V91, P365, DOI 10.1016/j.biopsycho.2012.08.007. Kron A, 2015, EMOTION, V15, P35, DOI 10.1037/a0038474. Lake Jessica I, 2016, Timing Time Percept, V4, P63. Lal SKL, 2005, INT J PSYCHOPHYSIOL, V55, P137, DOI 10.1016/j.ijpsycho.2004.07.001. Larsen JT, 2017, EMOTION, V17, P323, DOI 10.1037/emo0000231. Larsen JT, 2003, PSYCHOPHYSIOLOGY, V40, P776, DOI 10.1111/1469-8986.00078. Larson MJ, 2017, INT J PSYCHOPHYSIOL, V111, P1, DOI 10.1016/j.ijpsycho.2016.12.001. Leek JT, 2015, P NATL ACAD SCI USA, V112, P1645, DOI 10.1073/pnas.1421412111. Marwick B, 2017, J ARCHAEOL METHOD TH, V24, P424, DOI 10.1007/s10816-015-9272-9. Matsunaga M, 2007, COMMUN METHODS MEAS, V1, P243, DOI 10.1080/19312450701641409. McKubre M.C.M.C., 2008, 14 INT C COLD FUS IN. Narici L, 1997, INT J PSYCHOPHYSIOL, V26, P137, DOI 10.1016/S0167-8760(97)00761-7. Nummenmaa L, 2004, EMOTION, V4, P207, DOI 10.1037/1528-3542.4.2.207. O'Keefe DJ, 2007, COMMUN METHODS MEAS, V1, P267, DOI 10.1080/19312450701641383. O'Keefe DJ, 2003, HUM COMMUN RES, V29, P431, DOI 10.1093/hcr/29.3.431. O'Keefe DJ, 2003, HUM COMMUN RES, V29, P464, DOI 10.1111/j.1468-2958.2003.tb00849.x. Peng RD, 2006, AM J EPIDEMIOL, V163, P783, DOI 10.1093/aje/kwj093. Peng RD, 2011, SCIENCE, V334, P1226, DOI 10.1126/science.1213847. Peng RD, 2009, BIOSTATISTICS, V10, P405, DOI 10.1093/biostatistics/kxp014. Perrino T, 2013, PERSPECT PSYCHOL SCI, V8, P433, DOI 10.1177/1745691613491579. ROSNOW RL, 1995, PSYCHOL SCI, V6, P3, DOI 10.1111/j.1467-9280.1995.tb00297.x. ROSNOW RL, 1989, PSYCHOL BULL, V105, P143, DOI 10.1037/0033-2909.105.1.143. Sandusky R.J.R.J., 2007, P AM SOC INFORM SCI, V44, P1, DOI DOI 10.1002/meet.1450440390. Sankoh AJ, 1997, STAT MED, V16, P2529, DOI 10.1002/(SICI)1097-0258(19971130)16:22\textexclamdown 2529::AID-SIM692\textquestiondown 3.0.CO;2-J. Scherer KlausR., 2001, APPRAISAL PROCESSES, DOI DOI 10.1016/J.PHYSBEH.2006.11.008. Schimmack U, 2001, COGNITION EMOTION, V15, P81, DOI 10.1080/0269993004200123. Schmidt S, 2009, REV GEN PSYCHOL, V13, P90, DOI 10.1037/a0015108. Schwalbe M., 2016, STAT CHALL ASS FOST. Selle NK, 2016, PSYCHOPHYSIOLOGY, V53, P579, DOI 10.1111/psyp.12583. SHAFFER JP, 1995, ANNU REV PSYCHOL, V46, P561, DOI 10.1146/annurev.ps.46.020195.003021. Siller A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01553. Silvestrini N, 2013, J PERS SOC PSYCHOL, V104, P803, DOI 10.1037/a0031995. Silvia PJ, 2014, SELF IDENTITY, V13, P231, DOI 10.1080/15298868.2013.796086. Sloan B.M.B.M., 2013, AM LAB C. Small SL, 2009, INT J PSYCHOPHYSIOL, V73, P62, DOI 10.1016/j.ijpsycho.2009.01.010. Spottiswoode SJP, 2003, J SCI EXPLORATION, V7, P617. Stodden V.V., 2015, THIS IDEA MUST DIE S. STRAUBE ER, 1979, J NERV MENT DIS, V167, P601, DOI 10.1097/00005053-197910000-00003. Suchard M.M., 2016, STAT CHALLENGES ASSE, P55. Sutton BP, 2009, INT J PSYCHOPHYSIOL, V73, P33, DOI 10.1016/j.ijpsycho.2008.12.020. Tabachnick B. G., 2013, USING MULTIVARIATE S. Tibshirani R.J.R.J., 2002, STAT APPL GENET MOL, V1, P1000. Tutzauer F, 2003, HUM COMMUN RES, V29, P455. van der Zwaag MD, 2011, MUSIC SCI, V15, P250, DOI 10.1177/1029864911403364. Vandewalle P, 2009, IEEE SIGNAL PROC MAG, V26, P37, DOI 10.1109/MSP.2009.932122. VENABLES P, 1978, PSYCHOPHYSIOLOGY, V15, P302, DOI 10.1111/j.1469-8986.1978.tb01383.x. Venables P. H., 1980, TECHNIQUES PSYCHOPHY, P3. Venables W. N., 2002, MODEM APPL STAT S. WASSERMAN S, 1989, PSYCHOPHYSIOLOGY, V26, P208, DOI 10.1111/j.1469-8986.1989.tb03159.x. Weber R, 2007, COMMUN METHODS MEAS, V1, P281, DOI 10.1080/19312450701641391. Wright R.A., 1996, PSYCHOL ACTION LINKI, P424.},
  da = {2021-06-23},
  doc-delivery-number = {FH9QF},
  eissn = {1872-7697},
  funding-acknowledgement = {NIDCR NIH HHSUnited States Department of Health \& Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Dental \& Craniofacial Research (NIDCR) [R56 DE025321] Funding Source: Medline; NATIONAL INSTITUTE OF DENTAL \& CRANIOFACIAL RESEARCHUnited States Department of Health \& Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Dental \& Craniofacial Research (NIDCR) [R56DE025321] Funding Source: NIH RePORTER},
  journal-iso = {Int. J. Psychophysiol.},
  keywords-plus = {ELECTROMYOGRAPHIC ACTIVITY; EFFORT MOBILIZATION; FAMILYWISE-ALPHA; REPLICATION; BRAIN; PSYCHOPHYSIOLOGY; ADJUSTMENT; ERROR; SELF; RELIABILITY},
  language = {English},
  number-of-cited-references = {103},
  research-areas = {Psychology; Neurosciences \& Neurology; Physiology},
  times-cited = {0},
  unique-id = {ISI:000411546100013},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {8},
  web-of-science-categories = {Psychology, Biological; Neurosciences; Physiology; Psychology; Psychology, Experimental},
  keywords = {Computational reproducibility; Replication; Psychophysiology; Motivation; Emotion; Appraisal}
}

@article{ISI:000418663700012,
  type = {Review},
  title = {The Future of Scientific Workflows},
  author = {Deelman, Ewa and Peterka, Tom and Altintas, Ilkay and Carothers, Christopher D. and {van Dam}, Kerstin Kleese and Moreland, Kenneth and Parashar, Manish and Ramakrishnan, Lavanya and Taufer, Michela and Vetter, Jeffrey},
  year = {2018},
  month = jan,
  journal = {INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS},
  volume = {32},
  number = {1, SI},
  pages = {159--175},
  publisher = {{SAGE PUBLICATIONS LTD}},
  address = {{1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND}},
  issn = {1094-3420},
  doi = {10.1177/1094342017704893},
  abstract = {Today's computational, experimental, and observational sciences rely on computations that involve many related tasks. The success of a scientific mission often hinges on the computer automation of these workflows. In April 2015, the US Department of Energy (DOE) invited a diverse group of domain and computer scientists from national laboratories supported by the Office of Science, the National Nuclear Security Administration, from industry, and from academia to review the workflow requirements of DOE's science and national security missions, to assess the current state of the art in science workflows, to understand the impact of emerging extreme-scale computing systems on those workflows, and to develop requirements for automated workflow management in future and existing environments. This article is a summary of the opinions of over 50 leading researchers attending this workshop. We highlight use cases, computing systems, workflow needs and conclude by summarizing the remaining challenges this community sees that inhibit large-scale scientific workflows from becoming a mainstream tool for extreme-scale science.},
  affiliation = {Deelman, E (Corresponding Author), Univ Southern Calif, Inst Informat Sci, 4676 AdmiraltyWay,Suite 1001, Marina Del Rey, CA 90292 USA. Deelman, Ewa, Univ Southern Calif, Inst Informat Sci, 4676 AdmiraltyWay,Suite 1001, Marina Del Rey, CA 90292 USA. Peterka, Tom, Argonne Natl Lab, Math \& Comp Sci Div, 9700 S Cass Ave, Argonne, IL 60439 USA. Altintas, Ilkay, Univ Calif San Diego, San Diego Supercomputing Ctr, San Diego, CA USA. Carothers, Christopher D., Rensselaer Polytech Inst, Dept Comp Sci, New York, NY USA. van Dam, Kerstin Kleese, Brookhaven Natl Lab, CSI, New York, NY USA. Moreland, Kenneth, Sandia Natl Labs, Livermore, CA 94550 USA. Parashar, Manish, Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ USA. Ramakrishnan, Lavanya, Lawrence Berkeley Natl Lab, Berkeley, CA USA. Taufer, Michela, Univ Delaware, Dept Comp Sci, Newark, DE USA. Vetter, Jeffrey, Oak Ridge Natl Lab, Oak Ridge, TN USA.},
  author-email = {deelman@isi.edu},
  cited-references = {ABBASI H, 2009, 18TH ACM INTERNATION, P39. Aktas MF, 2014, 2014 FOURTH INTERNATIONAL WORKSHOP ON NETWORK-AWARE DATA MANAGEMENT (NDM), P28, DOI 10.1109/NDM.2014.9. Altintas I, 2004, 16TH INT C SCI STAT. [Anonymous], 2015, WORKSHOP FUTURE SCI. Arteaga A, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.127. Bailey DH, 2005, COMPUT SCI ENG, V7, P54, DOI 10.1109/MCSE.2005.52. BALAJI P, 2013, 10TH IEEE INTERNATIO, P407, DOI DOI 10.1109/HPCC.AND.EUC.2013.65. Balderrama JR, 2014, 2014 9TH WORKSHOP ON WORKFLOWS IN SUPPORT OF LARGE-SCALE SCIENCE (WORKS), P50, DOI 10.1109/WORKS.2014.14. Barga Roger, 2008, 2008 IEEE Fourth International Conference on eScience, P317, DOI 10.1109/eScience.2008.126. Bavoil L, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P135, DOI 10.1109/visual.2005.1532788. BDEC Committee, 2016, BDEC PATHW CONV REP. Benedict MN, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003882. Bennett JC, 2012, P INT C HIGH PERF CO, P491. Bergmann R, 2014, INFORM SYST, V40, P115, DOI 10.1016/j.is.2012.07.005. BHAT VB, 2008, THESIS. Biddiscombe J, 2007, IEEE T VIS COMPUT GR, V13, P1376, DOI 10.1109/TVCG.2007.70600. Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X. Bui P, 2010, P 19 ACM INT S HIGH, P636, DOI DOI 10.1145/1851476.1851570. Burtscher Martin, 2010, P 2010 ACM IEEE INT, P1, DOI [10.1109/SC.2010.41, DOI 10.1109/SC.2010.41]. Cappello F, 2009, INT J HIGH PERFORM C, V23, P212, DOI 10.1177/1094342009106189. Cattell R., 2011, ACM SIGMOD RECORD, V39, P12, DOI DOI 10.1145/1978915.1978919. Chapp D, 2015, IEEE CLUST C CHIC IL. Chiang W.-F., 2013, WORKSH DET CORR PAR. Churches D, 2006, CONCURR COMP-PRACT E, V18, P1021, DOI 10.1002/cpe.992. Clarke JA, 2007, PROCEEDINGS OF THE HPCMP USERS GROUP CONFERENCE 2007, P322. Considine DM, 1999, NOSTRANDS SCI ENCY. CUEVASVICENTTIN. V, 2012, HIGH PERFORMANCE COM, P119. Dayal Jai, 2013, 2013 IEEE International Symposium on Parallel and Distributed Processing, Workshops and PhD Forum (IPDPSW), P2015, DOI 10.1109/IPDPSW.2013.198. Dayal J, 2014, IEEE ACM INT SYMP, P246, DOI 10.1109/CCGrid.2014.104. de Oliveira D, 2012, J GRID COMPUT, V10, P521, DOI 10.1007/s10723-012-9227-2. Dean J., 2004, P 6 C S OP SYST DES, V6, P10, DOI DOI 10.HTTP://DL.ACM.0RG/CITATI0N.CFM?. Deelman E., 2005, Scientific Programming, V13, P219. Deelman E, 2004, GRID C SPAIN 13 14 F. Deelman E, 2015, FUTURE GENER COMP SY, V46, P17, DOI 10.1016/j.future.2014.10.008. Demmel J, 2015, IEEE T COMPUT, V64, P2060, DOI 10.1109/TC.2014.2345391. Docan C., 2011, Proceedings of the 25th IEEE International Parallel \& Distributed Processing Symposium (IPDPS 2011), P758, DOI 10.1109/IPDPS.2011.120. Docan C., 2010, HPDC, P25, DOI DOI 10.1145/1851476.1851481. Dorier M., 2015, P 1 WORKSH SIT INFR, P19. Dreher M, 2016, IEEE INT C CL COMP, P279, DOI 10.1109/CLUSTER.2016.30. Eaton B., 2011, NETCDF CLIMATE FOREC. Ekanayake Jaliya, 2008, 2008 IEEE Fourth International Conference on eScience, P277, DOI 10.1109/eScience.2008.59. Ewa Deelman, 2016, DOE NGNS CS SCI WORK. Fox G., 2014, HIGH PERFORMANCE HIG. Gamell M, 2014, INT CONF HIGH PERFOR, P895, DOI 10.1109/SC.2014.78. Garijo D, 2012, OPEN PUBLICATION REU. Giardine B, 2005, GENOME RES, V15, P1451, DOI 10.1101/gr.4086505. Goecks J, 2010, GENOME BIOL, V11, DOI 10.1186/gb-2010-11-8-r86. Graves R, 2011, PURE APPL GEOPHYS, V168, P367, DOI 10.1007/s00024-010-0161-6. Gustafson J., 2015, END ERROR UNUM COMPU. Habib S, 2016, NEW ASTRON, V42, P49, DOI 10.1016/j.newast.2015.06.003. Jacob JC, 2010, COMPUTING RES REPOSI. Jha S, 2014, IEEE INT CONGR BIG, P645, DOI 10.1109/BigData.Congress.2014.137. Juve G, 2013, FUTURE GENER COMP SY, V29, P682, DOI 10.1016/j.future.2012.08.015. KAHAN W, 1965, COMMUN ACM, V8, P40, DOI 10.1145/363707.363723. Khan F, 2013, ICALEPCS. Kleese van Dam K, 2015, PNNLSA120941. Koziol Q., 2014, HIGH PERFORMANCE PAR. LANL NERSC and SNL, 2016, SAND20162371O NERSC. Lim C, 2011, FUTURE GENER COMP SY, V27, P781, DOI 10.1016/j.future.2010.10.013. Lofstead J., 2008, P 6 INT WORKSH CHALL, P15, DOI [10.1145/1383529.1383533, DOI 10.1145/1383529.1383533]. Logan J, 2012, LECT NOTES COMPUT SC, V7484, P77, DOI 10.1007/978-3-642-32820-6\_10. Maechling P, 2006, WORKFLOWS E SCI, P143. Maheshwari K, 2013, 3 WORKSH SUST SOFTW. Malewicz Grzegorz, 2010, P ACM INT C MAN DAT, P135. Mathog DR, 2003, BIOINFORMATICS, V19, P1865, DOI 10.1093/bioinformatics/btg250. Melnik S, 2010, PROC VLDB ENDOW, V3, P330. Meyer L, 2013, TECHNICAL REPORT. Moreau L, 2011, FUTURE GENER COMP SY, V27, P743, DOI 10.1016/j.future.2010.07.005. Moustakas DT, 2006, J COMPUT AID MOL DES, V20, P601, DOI 10.1007/s10822-006-9060-4. Muniswamy-Reddy K. K., 2009, P 2009 C USENIX ANN, P10. Oinn T, 2006, CONCURR COMP-PRACT E, V18, P1067, DOI 10.1002/cpe.993. Parker S., 1995, SUPERCOMPUTING, P52, DOI DOI 10.1109/SUPERC.1995.66. Qui J, 2014, BUILD ROB BIG DAT EC. Ramakrishnan L, 2014, P IEEE INT C E-SCI, P290, DOI 10.1109/eScience.2014.56. Revol N, 2014, CHALL 21 CENT EXP MA. Samak T, 2011, P 6 WORKSH WORKFL SU, P107. Scheidegger C. E., 2008, SIGMOD, P1251. Shasharina S, 2010, 1 INT PART ACC C IPA. Silva CT, 2007, COMPUT SCI ENG, V9, P82, DOI 10.1109/MCSE.2007.106. Sorenson H, 1985, KALMAN FILTER THEORY, VVol. 38. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Stonebraker Michael, 2011, Scientific and Statistical Database Management. Proceedings 23rd International Conference, SSDBM 2011, P1, DOI 10.1007/978-3-642-22351-8\_1. Talukder AKMKA, 2009, CONCURR COMP-PRACT E, V21, P1742, DOI 10.1002/cpe.1417. Taufer M., 2010, 2010 IEEE INT S PAR, P1. TCHOUA R, 2010, IEEE 9TH INTERNATION, P27, DOI DOI 10.1109/ESCIENCE.2013.24. Teranishi K, 2014, P 21 EUR MPI US GROU, P5151. Thakur R., 2015, PARALLEL I O BENCHMA. Thall A, 2006, ACM SIGGRAPH 2006 RE. Top Ten Exascale Research Challenges, 2014, DOE ASCAC SUBC REP. Truong HL, 2007, FUTURE GENER COMP SY, V23, P760, DOI 10.1016/j.future.2007.01.003. UPSON C, 1989, IEEE COMPUT GRAPH, V9, P30, DOI 10.1109/38.31462. Weerawarana S., 2005, WEB SERVICES PLATFOR. Wilde M, 2011, PARALLEL COMPUT, V37, P633, DOI 10.1016/j.parco.2011.05.005. Wilde M, 2009, COMPUTER, V42, P50, DOI 10.1109/MC.2009.365. WILKE J, 2014, 44TH ANNUAL IEEEIFIP, P756, DOI DOI 10.1109/DSN.2014.105. Wolstencroft K, 2013, NUCLEIC ACIDS RES, V41, pW557, DOI 10.1093/nar/gkt328. Yelick K, 2012, SYNCHR RED COMM RED. Zhang Z, 2014, P IEEE INT C E-SCI, P111, DOI 10.1109/eScience.2014.9. Zhao Y, 2007, IEEE C SERV SALT LAK. Zheng F., 2011, P 6 WORKSH PAR DAT S, P37. Zheng F., 2010, PAR DISTR PROC IPDPS, P1, DOI DOI 10.1109/IPDPS.2010.5470454.},
  da = {2021-06-24},
  doc-delivery-number = {FQ9DX},
  eissn = {1741-2846},
  funding-acknowledgement = {U.S. Department of Energy Office of ScienceUnited States Department of Energy (DOE) [DE-AC02-06CH11357]; U.S. Department of Energy's National Nuclear Security AdministrationNational Nuclear Security Administration [DE-AC04-94AL85000]; US Department of EnergyUnited States Department of Energy (DOE) [DESC0012636]},
  funding-text = {The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: Argonne National Laboratory is managed by UChicago Argonne, LLC, for the U.S. Department of Energy Office of Science under contract DE-AC02-06CH11357. Sandia National Laboratories is a multi-program laboratory managed and operated by Sandia Corporation, a wholly owned subsidiary of Lockheed Martin Corporation, for the U.S. Department of Energy's National Nuclear Security Administration under contract DE-AC04-94AL85000. This work was funded in part by the US Department of Energy under Contract \#DESC0012636, ``Panorama -Predictive Modeling and Diagnostic Monitoring of Extreme Science Workflows''.},
  journal-iso = {Int. J. High Perform. Comput. Appl.},
  keywords-plus = {SYSTEM; ENVIRONMENT; TAVERNA; WEB},
  language = {English},
  number-of-cited-references = {101},
  orcid-numbers = {Taufer, Michela/0000-0002-0031-6377 Vetter, Jeffrey/0000-0002-2449-6720},
  research-areas = {Computer Science},
  times-cited = {39},
  unique-id = {ISI:000418663700012},
  usage-count-last-180-days = {2},
  usage-count-since-2013 = {15},
  web-of-science-categories = {Computer Science, Hardware \& Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods},
  keywords = {Scientific workflows; extreme-scale computing; distributed computing; in situ computing; workflow models},
  file = {/Users/awwillc/Zotero/storage/W9PDCD98/Deelman et al. - 2018 - The future of scientific workflows.pdf}
}

@article{ISI:000427245400036,
  type = {Article},
  title = {An Empirical Analysis of Journal Policy Effectiveness for Computational Reproducibility},
  author = {Stodden, Victoria and Seiler, Jennifer and Ma, Zhaokun},
  year = {2018},
  month = mar,
  journal = {PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA},
  volume = {115},
  number = {11},
  pages = {2584--2589},
  publisher = {{NATL ACAD SCIENCES}},
  address = {{2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA}},
  issn = {0027-8424},
  doi = {10.1073/pnas.1708290115},
  abstract = {A key component of scientific communication is sufficient information for other researchers in the field to reproduce published findings. For computational and data-enabled research, this has often been interpreted to mean making available the raw data from which results were generated, the computer code that generated the findings, and any additional information needed such as workflows and input parameters. Many journals are revising author guidelines to include data and code availability. This work evaluates the effectiveness of journal policy that requires the data and code necessary for reproducibility be made available postpublication by the authors upon request. We assess the effectiveness of such a policy by (i) requesting data and code from authors and (ii) attempting replication of the published findings. We chose a random sample of 204 scientific papers published in the journal Science after the implementation of their policy in February 2011. We found that we were able to obtain artifacts from 44\% of our sample and were able to reproduce the findings for 26\%. We find this policy-author remission of data and code postpublication upon request-an improvement over no policy, but currently insufficient for reproducibility.},
  affiliation = {Stodden, V (Corresponding Author), Univ Illinois, Sch Informat Sci, Champaign, IL 61820 USA. Stodden, Victoria, Univ Illinois, Sch Informat Sci, Champaign, IL 61820 USA. Seiler, Jennifer; Ma, Zhaokun, Columbia Univ, Dept Stat, New York, NY 10027 USA.},
  author-email = {victoria@stodden.net},
  cited-references = {American Association for the Advancement of Science, 2011, SCI J ED POL. Brinckman A, 2019, FUTURE GENER COMP SY, V94, P854, DOI 10.1016/j.future.2017.12.029. Carata L, 2014, ACM QUEUE, V12. Chang A.C., 2015, FINANCE EC DISCUSS S, P1. Coughlin SS, 2017, AM J EPIDEMIOL, V186, P393, DOI 10.1093/aje/kwx065. Donoho DL, 2009, COMPUT SCI ENG, V11, P8, DOI 10.1109/MCSE.2009.15. Dwork C, 2014, PRIVACY, BIG DATA, AND THE PUBLIC GOOD: FRAMEWORKS FOR ENGAGEMENT, P296. Fuentes M, 2016, AMSTAT NEWS. Gentleman R, 2007, J COMPUT GRAPH STAT, V16, P1, DOI 10.1198/106186007X178663. Gilbert KJ, 2012, MOL ECOL, V21, P4925, DOI 10.1111/j.1365-294X.2012.05754.x. Hanson B, 2011, SCIENCE, V331, P649, DOI 10.1126/science.1203354. Ioannidis JPA, 2009, NAT GENET, V41, P149, DOI 10.1038/ng.295. KING G, 1995, PS, V28, P444, DOI 10.2307/420301. National Academies of Sciences Engineering and Medicine., 2017, FOST INT RES. Nosek BA, 2015, SCIENCE, V348, P1422, DOI 10.1126/science.aab2374. Peng RD, 2011, SCIENCE, V334, P1226, DOI 10.1126/science.1213847. Renear A. H., 2010, P AM SOC INFORM SCI, P1, DOI [DOI 10.1002/MEET.14504701240, 10.1002/meet.14504701240]. Sarathy R, 2012, HANDB STAT, V28, P513, DOI 10.1016/B978-0-44-4518750.00019-1. Stodden V., 2013, SIAM NEWS. Stodden V, 2013, NOTICES AMS. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Stodden V, 2014, PRIVACY, BIG DATA, AND THE PUBLIC GOOD: FRAMEWORKS FOR ENGAGEMENT, P112. Stodden V, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067111. Stodden V, 2009, COMPUT SCI ENG, V11, P35, DOI 10.1109/MCSE.2009.19. Wolf LE, 2015, J LAW MED ETHICS, V43, P594, DOI 10.1111/jlme.12302.},
  da = {2021-06-23},
  doc-delivery-number = {FZ0GH},
  funding-acknowledgement = {Alfred P. Sloan FoundationAlfred P. Sloan Foundation [PG004545]; NSFNational Science Foundation (NSF) [1153384]},
  funding-text = {We thank anonymous reviewers for constructive comments and criticism that improved the manuscript. This research was supported by Alfred P. Sloan Foundation Award PG004545 ``Facilitating Transparency in Scientific Publishing'' and NSF Award 1153384 ``EAGER: Policy Design for Reproducibility and Data Sharing in Computational Science.'' See www.nsf.gov/awardsearch/showAward?AWD\_ID=1153384. Since 2016, V.S. has been a member of the Transparency and Openness Promotion (TOP) Guidelines Coordinating Committee.},
  journal-iso = {Proc. Natl. Acad. Sci. U. S. A.},
  language = {English},
  number-of-cited-references = {25},
  oa = {Green Published, Bronze},
  orcid-numbers = {Seiler, Jennifer/0000-0003-2855-3945},
  research-areas = {Science \& Technology - Other Topics},
  times-cited = {78},
  unique-id = {ISI:000427245400036},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {14},
  web-of-science-categories = {Multidisciplinary Sciences},
  keywords = {reproducible research; data access; code access; reproducibility policy; open science}
}

@article{ISI:000430867600004,
  type = {Article},
  title = {Excuse Me, Do You Have a Moment to Talk about Version Control?},
  author = {Bryan, Jennifer},
  year = {2018},
  journal = {AMERICAN STATISTICIAN},
  volume = {72},
  number = {1, SI},
  pages = {20--27},
  publisher = {{AMER STATISTICAL ASSOC}},
  address = {{732 N WASHINGTON ST, ALEXANDRIA, VA 22314-1943 USA}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1399928},
  abstract = {Data analysis, statistical research, and teaching statistics have at least one thing in common: these activities all produce many files! There are data files, source code, figures, tables, prepared reports, and much more. Most of these files evolve over the course of a project and often need to be shared with others, for reading or edits, as a project unfolds. Without explicit and structured management, project organization can easily descend into chaos, taking time away from the primary work and reducing the quality of the final product. This unhappy result can be avoided by repurposing tools and workflows from the software development world, namely, distributed version control. This article describes the use of the version control system Git and the hosting site GitHub for statistical and data scientific workflows. Special attention is given to projects that use the statistical language R and, optionally, RMarkdown documents. Supplementary materials include an annotated set of links to step-by-step tutorials, real world examples, and other useful learning resources. Supplementary materials for this article are available online.},
  affiliation = {Bryan, J (Corresponding Author), Univ British Columbia, RStudio, Vancouver, BC V6T 1Z4, Canada. Bryan, J (Corresponding Author), Univ British Columbia, Dept Stat, Vancouver, BC V6T 1Z4, Canada. Bryan, Jennifer, Univ British Columbia, RStudio, Vancouver, BC V6T 1Z4, Canada. Bryan, Jennifer, Univ British Columbia, Dept Stat, Vancouver, BC V6T 1Z4, Canada.},
  author-email = {jenny@rstudio.com},
  cited-references = {Allaire J., 2017, RMARKDOWN DYNAMIC DO. ANDERSON EDGAR, 1936, ANN MISSOURI BOT GARD, V23, P457, DOI 10.2307/2394164. Bartlett A., 2016, COMMUNICATION. Cetinkaya-Rundel M., 2017, PEERJ PREPRINTS, V5, DOI 10. 7287/peerj. preprints. 3181v1. Donoho D., 2015, 50 YEARS DATA SCI VE. Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x. Perez-Riverol Y, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004947. R Core Team, 2017, R LANG ENV STAT COMP. Ram K, 2013, SOURCE CODE BIOL MED, V8, DOI 10.1186/1751-0473-8-7. Wilson G., 2016, ABS160900037 CORR. Xie Y., 2016, BOOKDOWN AUTHORING B. Xie Y., 2015, DYNAMIC DOCUMENTS R. Xie Y, 2017, BOOKDOWN AUTHORING B. Xie Y., 2017, KNITR GEN PURPOSE PA.},
  da = {2021-06-24},
  doc-delivery-number = {GD9XZ},
  eissn = {1537-2731},
  journal-iso = {Am. Stat.},
  language = {English},
  number-of-cited-references = {14},
  orcid-numbers = {Bryan, Jennifer/0000-0002-6983-2759},
  research-areas = {Mathematics},
  times-cited = {8},
  unique-id = {ISI:000430867600004},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {13},
  web-of-science-categories = {Statistics \& Probability},
  keywords = {Data science; Git; GitHub; R language; R Markdown; Reproducibility; Workflow}
}

@article{ISI:000436877800001,
  type = {Editorial Material},
  title = {Practical Computational Reproducibility in the Life Sciences},
  author = {Gruening, Bjoern and Chilton, John and Koester, Johannes and Dale, Ryan and Soranzo, Nicola and {van den Beek}, Marius and Goecks, Jeremy and Backofen, Rolf and Nekrutenko, Anton and Taylor, James},
  year = {2018},
  month = jun,
  journal = {CELL SYSTEMS},
  volume = {6},
  number = {6},
  pages = {631--635},
  publisher = {{CELL PRESS}},
  address = {{50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA}},
  issn = {2405-4712},
  doi = {10.1016/j.cels.2018.03.014},
  abstract = {Many areas of research suffer from poor reproducibility, particularly in computationally intensive domains where results rely on a series of complex methodological decisions that are not well captured by traditional publication approaches. Various guidelines have emerged for achieving reproducibility, but implementation of these practices remains difficult due to the challenge of assembling software tools plus associated libraries, connecting tools together into pipelines, and specifying parameters. Here, we discuss a suite of cutting-edge technologies that make computational reproducibility not just possible, but practical in both time and effort. This suite combines three well-tested components-a system for building highly portable packages of bioinformatics software, containerization and virtualization technologies for isolating reusable execution environments for these packages, and workflow systems that automatically orchestrate the composition of these packages for entire pipelines-to achieve an unprecedented level of computational reproducibility. We also provide a practical implementation and five recommendations to help set a typical researcher on the path to performing data analyses reproducibly.},
  affiliation = {Backofen, R (Corresponding Author), Albert Ludwigs Univ, Freiburg, Germany. Nekrutenko, A (Corresponding Author), Penn State Univ, University Pk, PA 16802 USA. Taylor, J (Corresponding Author), Johns Hopkins Univ, Baltimore, MD 21218 USA. Gruening, Bjoern; Backofen, Rolf, Albert Ludwigs Univ, Freiburg, Germany. Chilton, John; Nekrutenko, Anton, Penn State Univ, University Pk, PA 16802 USA. Koester, Johannes, Univ Duisburg Essen, Essen, Germany. Dale, Ryan, NIDDK, Bethesda, MD 20892 USA. Soranzo, Nicola, Earlham Inst, Norwich, Norfolk, England. van den Beek, Marius, Inst Curie, Paris, France. Goecks, Jeremy, Oregon Hlth \& Sci Univ, Portland, OR 97201 USA. Taylor, James, Johns Hopkins Univ, Baltimore, MD 21218 USA.},
  author-email = {backofen@informatik.uni-freiburg.de anton@nekrut.org james@taylorlab.org},
  cited-references = {Afgan E, 2016, NUCLEIC ACIDS RES, V44, pW3, DOI 10.1093/nar/gkw343. Afgan E, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-S12-S4. Baker M, 2016, NATURE, V533, P452, DOI 10.1038/533452a. Baumer B, 2014, ARXIV14021894. Beaulieu-Jones BK, 2017, NAT BIOTECHNOL, V35, P342, DOI 10.1038/nbt.3780. Begley CG, 2015, NATURE, V525, P25, DOI 10.1038/525025a. Begley CG, 2013, NATURE, V497, P433, DOI 10.1038/497433a. Bolger AM, 2014, BIOINFORMATICS, V30, P2114, DOI 10.1093/bioinformatics/btu170. Cook J., 2017, DOCKER DATA SCI, P103. Gruning B, 2017, BIORXIV, DOI [10.1101/207092, DOI 10.1101/207092]. Kim D, 2015, NAT METHODS, V12, P357, DOI [10.1038/nmeth.3317, 10.1038/NMETH.3317]. Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87. Koster J, 2012, BIOINFORMATICS, V28, P2520, DOI 10.1093/bioinformatics/bts480. Kurtzer GM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177459. Leek JT, 2015, SCIENCE, V347, P1314, DOI 10.1126/science.aaa6146. Leprevost FD, 2017, BIOINFORMATICS, V33, P2580, DOI 10.1093/bioinformatics/btx192. McNutt M, 2014, SCIENCE, V343, P231, DOI 10.1126/science.1250475. Moller S, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-S12-S5. Nekrutenko A, 2012, NAT REV GENET, V13, P667, DOI 10.1038/nrg3305. O'Connor Brian D, 2017, F1000Res, V6, P52, DOI 10.12688/f1000research.10137.1. Pertea M, 2015, NAT BIOTECHNOL, V33, P290, DOI 10.1038/nbt.3122. Reich M, 2006, NAT GENET, V38, P500, DOI 10.1038/ng0506-500. Scheidegger C. E., 2008, SIGMOD, P1251. Younge A. J., 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P9, DOI 10.1109/CLOUD.2011.29.},
  da = {2021-06-23},
  doc-delivery-number = {GL1PT},
  eissn = {2405-4720},
  funding-acknowledgement = {NIHUnited States Department of Health \& Human ServicesNational Institutes of Health (NIH) - USA [U41 HG006620, R01 AI134384-01]; NSFNational Science Foundation (NSF) [1661497]; Intramural Program of the National Institute of Diabetes and Digestive and Kidney Diseases, National Institutes of HealthUnited States Department of Health \& Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Diabetes \& Digestive \& Kidney Diseases (NIDDK); BBSRC Core Capability GrantUK Research \& Innovation (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC) [BB/CCG1720/1]; German Federal Ministry of Education and Research (BMBF)Federal Ministry of Education \& Research (BMBF) [031A538A, 031L0101C]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH \& HUMAN DEVELOPMENTUnited States Department of Health \& Human ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child Health \& Human Development (NICHD) [ZICHD008986] Funding Source: NIH RePORTER; NATIONAL HUMAN GENOME RESEARCH INSTITUTEUnited States Department of Health \& Human ServicesNational Institutes of Health (NIH) - USANIH National Human Genome Research Institute (NHGRI) [U41HG006620] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF ALLERGY AND INFECTIOUS DISEASESUnited States Department of Health \& Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Allergy \& Infectious Diseases (NIAID) [R01AI134384] Funding Source: NIH RePORTER},
  funding-text = {The authors are grateful to the Bioconda, BioContainers, and Galaxy communities, as without these resources, this work would not be possible. Nate Coraor provided critical advice on the project and edited the manuscript. This project was supported in part by NIH grants U41 HG006620 and R01 AI134384-01, as well as NSF grant 1661497 to J.T., A.N., and J.G. R. D. was supported by the Intramural Program of the National Institute of Diabetes and Digestive and Kidney Diseases, National Institutes of Health. N.S. was supported by the BBSRC Core Capability Grant BB/CCG1720/1 to the Earlham Institute. Additional funding was provided by German Federal Ministry of Education and Research (BMBF grants 031A538A \& 031L0101C de. NBI-RBC \& de. NBI-epi) to R.B. and B.G.},
  journal-iso = {Cell Syst.},
  language = {English},
  number-of-cited-references = {24},
  oa = {Bronze, Green Accepted},
  orcid-numbers = {Taylor, James/0000-0001-5079-840X Chilton, John/0000-0002-6794-0756 Soranzo, Nicola/0000-0003-3627-5340},
  research-areas = {Biochemistry \& Molecular Biology; Cell Biology},
  researcherid-numbers = {Taylor, James/F-1026-2011 Backofen, Rolf/AAC-1569-2021},
  times-cited = {26},
  unique-id = {ISI:000436877800001},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {4},
  web-of-science-categories = {Biochemistry \& Molecular Biology; Cell Biology},
  file = {/Users/awwillc/Zotero/storage/GW68T8RW/Gruening et al. - 2018 - Practical computational reproducibility in the lif.pdf}
}

@article{ISI:000447873800001,
  type = {Article},
  title = {Teaching Computational Reproducibility for Neuroimaging},
  author = {Millman, K. Jarrod and Brett, Matthew and Bamowski, Ross and Poline, Jean-Baptiste},
  year = {2018},
  month = oct,
  journal = {FRONTIERS IN NEUROSCIENCE},
  volume = {12},
  publisher = {{FRONTIERS MEDIA SA}},
  address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
  doi = {10.3389/fnins.2018.00727},
  abstract = {We describe a project-based introduction to reproducible and collaborative neuroimaging analysis. Traditional teaching on neuroimaging usually consists of a series of lectures that emphasize the big picture rather than the foundations on which the techniques are based. The lectures are often paired with practical workshops in which students run imaging analyses using the graphical interface of specific neuroimaging software packages. Our experience suggests that this combination leaves the student with a superficial understanding of the underlying ideas, and an informal, inefficient, and inaccurate approach to analysis. To address these problems, we based our course around a substantial open-ended group project. This allowed us to teach: (a) computational tools to ensure computationally reproducible work, such as the Unix command line, structured code, version control, automated testing, and code review and (b) a clear understanding of the statistical techniques used for a basic analysis of a single run in an MR scanner. The emphasis we put on the group project showed the importance of standard computational tools for accuracy, efficiency, and collaboration. The projects were broadly successful in engaging students in working reproducibly on real scientific questions. We propose that a course on this model should be the foundation for future programs in neuroimaging. We believe it will also serve as a model for teaching efficient and reproducible research in other fields of computational science.},
  affiliation = {Millman, KJ (Corresponding Author), Univ Calif Berkeley, Div Biostat, Berkeley, CA 94720 USA. Millman, KJ (Corresponding Author), Univ Calif Berkeley, Berkeley Inst Data Sci, Berkeley, CA 94720 USA. Millman, K. Jarrod, Univ Calif Berkeley, Div Biostat, Berkeley, CA 94720 USA. Millman, K. Jarrod, Univ Calif Berkeley, Berkeley Inst Data Sci, Berkeley, CA 94720 USA. Brett, Matthew, Univ Birmingham, Coll Life \& Environm Sci, Birmingham, W Midlands, England. Bamowski, Ross, Lawrence Berkeley Natl Lab, Appl Nucl Phys Program, Berkeley, CA USA. Poline, Jean-Baptiste, McGill Univ, Neurol \& Neurosurg, Montreal, PQ, Canada.},
  article-number = {727},
  author-email = {millman@berkeley.edu},
  cited-references = {Boring Anne, 2016, STUDENT EVALUATIONS. Buckheit J. B., 1995, WAVELETS STAT, P55, DOI [10.1007/978-1-4612-2544-7\_5., DOI 10.1007/978-1-4612-2544-7\_5]. Condliffe B., 2017, WORKING PAPER. Hanke M, 2014, SCI DATA, V1, DOI 10.1038/sdata.2014.3. Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736. Huppenkothen D., 2017, ARXIV171100028ASTROP. Kirschner PA, 2006, EDUC PSYCHOL-US, V41, P75, DOI 10.1207/s15326985ep4102\_1. Kitzes J., 2017, PRACTICE REPROD RES. Knoll M, 2012, TEACH COLL REC, V114, P1. Krautmann AC, 1999, ECON EDUC REV, V18, P59, DOI 10.1016/S0272-7757(98)00004-1. Mayer RE, 2004, AM PSYCHOL, V59, P14, DOI 10.1037/0003-066X.59.1.14. Millman K. J., 2014, IMPLEMENTING REPROD, P149. Millman KJ, 2007, COMPUT SCI ENG, V9, P52, DOI 10.1109/MCSE.2007.46. Millman KJ, 2011, COMPUT SCI ENG, V13, P9, DOI 10.1109/MCSE.2011.36. Perez F, 2011, COMPUT SCI ENG, V13, P13, DOI 10.1109/MCSE.2010.119. Poldrack RA, 2017, NEUROIMAGE, V144, P259, DOI 10.1016/j.neuroimage.2015.05.073. Poldrack RA, 2013, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00012. Preeyanon L., 2014, REPROD BIOINFORMATIC, P185. Repovs G, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00137. Thomas J. W., 2000, REV RES PROJECT BASE. Tom SM, 2007, SCIENCE, V315, P515, DOI 10.1126/science.1134239. Uttl B, 2017, STUD EDUC EVAL, V54, P22, DOI 10.1016/j.stueduc.2016.08.007. Uttl B, 2017, PEERJ, V5, DOI 10.7717/peerj.3299. Wilson G, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001745. Wilson Greg, 2014, F1000Res, V3, P62, DOI 10.12688/f1000research.3-62.v2. Worthington A., 2002, ASSESS EVAL HIGH EDU, V27, P49, DOI [10.1080/02602930120105054, DOI 10.1080/02602930120105054].},
  da = {2021-06-23},
  doc-delivery-number = {GX6LV},
  eissn = {1662-453X},
  funding-acknowledgement = {Gordon and Betty Moore FoundationGordon and Betty Moore Foundation [GBMF3834]; Alfred P. Sloan FoundationAlfred P. Sloan Foundation [2013-10-27]; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERINGUnited States Department of Health \& Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging \& Bioengineering (NIBIB) [P41EB019936] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF MENTAL HEALTHUnited States Department of Health \& Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH) [R01MH083320] Funding Source: NIH RePORTER},
  funding-text = {KM was funded in part by the Gordon and Betty Moore Foundation through Grant GBMF3834 and by the Alfred P. Sloan Foundation through Grant 2013-10-27 to the University of California, Berkeley.},
  journal-iso = {Front. Neurosci.},
  keywords-plus = {PYTHON},
  language = {English},
  number-of-cited-references = {26},
  oa = {DOAJ Gold, Green Published},
  orcid-numbers = {Millman, Kenneth/0000-0002-5263-5070},
  research-areas = {Neurosciences \& Neurology},
  times-cited = {7},
  unique-id = {ISI:000447873800001},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {1},
  web-of-science-categories = {Neurosciences},
  keywords = {neuroimaging; FMRI; computational reproducibility; scientific computing; statistics; education; Python language; data science},
  file = {/Users/awwillc/Zotero/storage/JTCP5EM3/Millman et al. - 2018 - Teaching computational reproducibility for neuroim.pdf}
}

@article{ISI:000450550600009,
  type = {Article},
  title = {Computational Reproducibility in Geoscientific Papers: {{Insights}} from a Series of Studies with Geoscientists and a Reproduction Study},
  author = {Konkol, Markus and Kray, Christian and Pfeiffer, Max},
  year = {2019},
  month = feb,
  journal = {INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE},
  volume = {33},
  number = {2},
  pages = {408--429},
  publisher = {{TAYLOR \& FRANCIS LTD}},
  address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND}},
  issn = {1365-8816},
  doi = {10.1080/13658816.2018.1508687},
  abstract = {Reproducibility is a cornerstone of science and thus for geographic research as well. However, studies in other disciplines such as biology have shown that published work is rarely reproducible. To assess the state of reproducibility, specifically computational reproducibility (i.e. rerunning the analysis of a paper using the original code), in geographic research, we asked geoscientists about this topic using three methods: a survey (n = 146), interviews (n = 9), and a focus group (n = 5). We asked participants about their understanding of open reproducible research (ORR), how much it is practiced, and what obstacles hinder ORR. We found that participants had different understandings of ORR and that there are several obstacles for authors and readers (e.g. effort, lack of openness). Then, in order to complement the subjective feedback from the participants, we tried to reproduce the results of papers that use spatial statistics to address problems in the geosciences. We selected 41 open access papers from Copernicus and Journal of Statistical Software and executed the R code. In doing so, we identified several technical issues and specific issues with the reproduced figures depicting the results. Based on these findings, we propose guidelines for authors to overcome the issues around reproducibility in the computational geosciences.},
  affiliation = {Konkol, M (Corresponding Author), Univ Munster, Inst Geoinformat, Munster, Germany. Konkol, Markus; Kray, Christian; Pfeiffer, Max, Univ Munster, Inst Geoinformat, Munster, Germany.},
  author-email = {m.konkol@uni-muenster.de},
  cited-references = {Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716. Allaire J., 2016, RMARKDOWN DYNAMIC DO, V1, P9010. Bailey D.H., 2016, REPRODUCIBILITY PRIN. Baker M, 2016, NATURE, V533, P452, DOI 10.1038/533452a. Barnes N, 2010, NATURE, V467, P753, DOI 10.1038/467753a. Benestad RE, 2016, THEOR APPL CLIMATOL, V126, P699, DOI 10.1007/s00704-015-1597-5. Boettiger C., 2017, ARXIV171003675. Bollen Kenneth, 2015, REP SUBC REPL SCI AD, P3. Brunsdon C, 2016, PROG HUM GEOG, V40, P687, DOI 10.1177/0309132515599625. Claerbou J.F., 1992, 1992 SEG ANN M SOC E. Collberg C, 2016, COMMUN ACM, V59, P62, DOI 10.1145/2812803. Costello MJ, 2009, BIOSCIENCE, V59, P418, DOI 10.1525/bio.2009.59.5.9. Darch PT, 2017, LIBR INFORM SCI RES, V39, P295, DOI 10.1016/j.lisr.2017.11.008. Donoho DL, 2009, COMPUT SCI ENG, V11, P8, DOI 10.1109/MCSE.2009.15. Easterbrook SM, 2014, NAT GEOSCI, V7, P779, DOI 10.1038/ngeo2283. Fehr J, 2016, AIMS MATH, V1, P261, DOI 10.3934/Math.2016.3.261. Gentleman R, 2007, J COMPUT GRAPH STAT, V16, P1, DOI 10.1198/106186007X178663. Gertler P, 2018, NATURE, V555, P580. Gewin V, 2016, NATURE, V529, P117, DOI 10.1038/nj7584-117a. Gil Y, 2016, EARTH SPACE SCI, V3, P388, DOI 10.1002/2015EA000136. Giraud T, 2017, LECT NOTES GEOINF CA, P173, DOI 10.1007/978-3-319-57336-6\_13. Glaser B., 1967, J BRIT SOCIOLOGICAL, V12, P27, DOI DOI 10.4324/9780203793206-1. GOODCHILD MF, 1992, INT J GEOGR INF SYST, V6, P31, DOI 10.1080/02693799208901893. Goodman SN, 2016, SCI TRANSL MED, V8, DOI 10.1126/scitranslmed.aaf5027. Heiberger RM, 2014, J STAT SOFTW, V57. Hillebrand H, 2013, ECOL LETT, V16, P1419, DOI 10.1111/ele.12190. Ioannidis JPA, 2009, NAT GENET, V41, P149, DOI 10.1038/ng.295. Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87. KNUTH DE, 1984, COMPUT J, V27, P97, DOI 10.1093/comjnl/27.2.97. Lazar J., 2017, RES METHODS HUMAN CO. Leek JT, 2017, ANNU REV STAT APPL, V4, P109, DOI 10.1146/annurev-statistics-060116-054104. Leek JT, 2015, P NATL ACAD SCI USA, V112, P1645, DOI 10.1073/pnas.1421412111. Lovelace R., 2016, GEOCOMPUTATION R. Markowetz F, 2015, GENOME BIOL, V16, DOI 10.1186/s13059-015-0850-7. Marlon JR, 2016, BIOGEOSCIENCES, V13, P3225, DOI 10.5194/bg-13-3225-2016. McCullough BD, 2008, CAN J ECON, V41, P1406, DOI 10.1111/j.1540-5982.2008.00509.x. Nature Geosciences, 2018, NATURE GEOSCIENCES. Nosek BA, 2015, SCIENCE, V348, P1422, DOI 10.1126/science.aab2374. Nust Daniel, 2017, D-Lib Magazine, V23, DOI 10.1045/january2017-nuest. Ostermann FO, 2017, T GIS, V21, P224, DOI 10.1111/tgis.12195. Peng RD, 2011, SCIENCE, V334, P1226, DOI 10.1126/science.1213847. Piwowar HA, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000308. R Core Team, 2018, R LANG ENV STAT COMP. Reichman OJ, 2011, SCIENCE, V331, P703, DOI 10.1126/science.1197962. RStudio Team, 2015, RSTUDIO INT DEV R. Sandve GK, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003285. Skaggs TH, 2015, VADOSE ZONE J, V14, DOI 10.2136/vzj2015.06.0088. Steiniger S, 2009, ECOL INFORM, V4, P183, DOI 10.1016/j.ecoinf.2009.07.004. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Stodden Victoria, 2010, 477310 MIT SLOAN. Vandewalle P, 2012, COMPUT SCI ENG, V14, P42, DOI 10.1109/MCSE.2012.63. Vandewalle P, 2009, IEEE SIGNAL PROC MAG, V26, P37, DOI 10.1109/MSP.2009.932122. Vines TH, 2014, CURR BIOL, V24, P94, DOI 10.1016/j.cub.2013.11.014. Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18.},
  da = {2021-06-23},
  doc-delivery-number = {HA8OV},
  eissn = {1362-3087},
  funding-acknowledgement = {German Research Foundation (DFG)German Research Foundation (DFG) [KR 3930/3-1]},
  funding-text = {This work was supported by the German Research Foundation (DFG) [grant number KR 3930/3-1].},
  journal-iso = {Int. J. Geogr. Inf. Sci.},
  keywords-plus = {CODE; REPEATABILITY; SOFTWARE},
  language = {English},
  number-of-cited-references = {54},
  oa = {Other Gold},
  orcid-numbers = {Konkol, Markus/0000-0001-6651-0976 Kray, Christian/0000-0002-4199-8976},
  research-areas = {Computer Science; Geography; Physical Geography; Information Science \& Library Science},
  times-cited = {11},
  unique-id = {ISI:000450550600009},
  usage-count-last-180-days = {1},
  usage-count-since-2013 = {16},
  web-of-science-categories = {Computer Science, Information Systems; Geography; Geography, Physical; Information Science \& Library Science},
  keywords = {Open reproducible research; computational research; spatial statistics},
  file = {/Users/awwillc/Zotero/storage/6CYX7J73/Konkol et al. - 2019 - Computational reproducibility in geoscientific pap.pdf}
}

@inproceedings{ISI:000452538600142,
  type = {Proceedings Paper},
  title = {{{ReproZip}}: {{Computational}} Reproducibility with Ease},
  booktitle = {{{SIGMOD}}'16: {{PROCEEDINGS OF THE}} 2016 {{INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA}}},
  author = {Chirigati, Fernando and Rampin, Remi and Shasha, Dennis and Freire, Juliana},
  year = {2016},
  pages = {2085--2088},
  publisher = {{ASSOC COMPUTING MACHINERY}},
  address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
  doi = {10/ggxs3d},
  abstract = {We present ReproZip, the recommended packaging tool for the SIGMOD Reproducibility Review. ReproZip was designed to simplify the process of making an existing computational experiment reproducible across platforms, even when the experiment was put together without reproducibility in mind. The tool creates a self-contained package for an experiment by automatically tracking and identifying all its required dependencies. The researcher can share the package with others, who can then use ReproZip to unpack the experiment, reproduce the findings on their favorite operating system, as well as modify the original experiment for reuse in new research, all with little effort. The demo will consist of examples of non-trivial experiments, showing how these can be packed in a Linux machine and reproduced on different machines and operating systems. Demo visitors will also be able to pack and reproduce their own experiments.},
  affiliation = {Chirigati, F (Corresponding Author), NYU, New York, NY 10003 USA. Chirigati, Fernando; Rampin, Remi; Shasha, Dennis; Freire, Juliana, NYU, New York, NY 10003 USA.},
  author-email = {fchirigati@nyu.edu remi.rampin@nyu.edu shasha@cs.nyu.edu juliana.freire@nyu.edu},
  book-group-author = {ACM SIGMOD},
  da = {2021-01-10},
  doc-delivery-number = {BL5RI},
  funding-acknowledgement = {NSFNational Science Foundation (NSF) [CNS-1229185, CI-EN-1405927]; Moore-Sloan Data Science Environment at NYU},
  funding-text = {This work was supported in part by NSF awards CNS-1229185 and CI-EN-1405927, and by the Moore-Sloan Data Science Environment at NYU.},
  isbn = {978-1-4503-3531-7},
  language = {English},
  number-of-cited-references = {18},
  oa = {Bronze},
  orcid-numbers = {Freire, Juliana/0000-0003-3915-7075 Rampin, Remi/0000-0002-0524-2282},
  organization = {{ACM SIGMOD; Assoc Comp Machinery; Microsoft; Oracle; Tableau; Alibaba com; AT \& T; Facebook; Google; IBM Res; Infosys; Platfora; Recruit; Salesforce; SAP; Snowflake; Amazon Web Serv; Cloudera; Esgyn; HP; Intel; LinkedIn; LogicBlox; Memsql; Splice Machine; Visa Res; Natl Sci Fdn}},
  research-areas = {Computer Science},
  researcherid-numbers = {Freire, Juliana/AAQ-4484-2020},
  times-cited = {21},
  unique-id = {ISI:000452538600142},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {0},
  web-of-science-categories = {Computer Science, Information Systems},
  keywords = {Computational Reproducibility; Provenance; ReproZip}
}

@inproceedings{ISI:000452538600142,
  type = {Proceedings Paper},
  title = {{{ReproZip}}: {{Computational}} Reproducibility with Ease},
  booktitle = {{{SIGMOD}}'16: {{PROCEEDINGS OF THE}} 2016 {{INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA}}},
  author = {Chirigati, Fernando and Rampin, Remi and Shasha, Dennis and Freire, Juliana},
  year = {2016},
  pages = {2085--2088},
  publisher = {{ASSOC COMPUTING MACHINERY}},
  address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
  doi = {10.1145/2882903.2899401},
  abstract = {We present ReproZip, the recommended packaging tool for the SIGMOD Reproducibility Review. ReproZip was designed to simplify the process of making an existing computational experiment reproducible across platforms, even when the experiment was put together without reproducibility in mind. The tool creates a self-contained package for an experiment by automatically tracking and identifying all its required dependencies. The researcher can share the package with others, who can then use ReproZip to unpack the experiment, reproduce the findings on their favorite operating system, as well as modify the original experiment for reuse in new research, all with little effort. The demo will consist of examples of non-trivial experiments, showing how these can be packed in a Linux machine and reproduced on different machines and operating systems. Demo visitors will also be able to pack and reproduce their own experiments.},
  affiliation = {Chirigati, F (Corresponding Author), NYU, New York, NY 10003 USA. Chirigati, Fernando; Rampin, Remi; Shasha, Dennis; Freire, Juliana, NYU, New York, NY 10003 USA.},
  author-email = {fchirigati@nyu.edu remi.rampin@nyu.edu shasha@cs.nyu.edu juliana.freire@nyu.edu},
  book-group-author = {ACM SIGMOD},
  cited-references = {Begley CG, 2012, NATURE, V483, P531, DOI 10.1038/483531a. Bonnet P, 2011, SIGMOD REC, V40, P45, DOI 10.1145/2034863.2034873. Chirigati F, 2013, P 2013 ACM SIGMOD IN, P977, DOI [10.1145/2463676.2465269, DOI 10.1145/2463676.2465269]. Collberg C., 2015, TR1404 U AR. Davidson S. B., 2008, P 2008ACMSIGMODINTER, P1345, DOI DOI 10.1145/1376616.1376772. Davison AP, 2012, COMPUT SCI ENG, V14, P48, DOI 10.1109/MCSE.2012.41. Devecsery D., 2014, 11 USENIX S OP SYST, P525. Donoho DL, 2009, COMPUT SCI ENG, V11, P8, DOI 10.1109/MCSE.2009.15. Freire J., 2011, ARCHITECTURE OPEN SO. Guo P.J., 2012, TAPP, P7. Guo PJ, 2012, COMPUT SCI ENG, V14, P32, DOI 10.1109/MCSE.2012.36. Janin Y., 2014, TRUST 14, P1. Murta L, 2015, LECT NOTES COMPUT SC, V8628, P71, DOI 10.1007/978-3-319-16462-5\_6. Nuzzo R, 2015, NATURE, V526, P182, DOI 10.1038/526182a. Pham Q., 2013, TAPP. Ruiz C., 2014, TESTBEDS RES INFRAST, V137, P33. Tenopir C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021101. Vandewalle P, 2009, IEEE SIGNAL PROC MAG, V26, P37, DOI 10.1109/MSP.2009.932122.},
  da = {2021-06-23},
  doc-delivery-number = {BL5RI},
  funding-acknowledgement = {NSFNational Science Foundation (NSF) [CNS-1229185, CI-EN-1405927]; Moore-Sloan Data Science Environment at NYU},
  funding-text = {This work was supported in part by NSF awards CNS-1229185 and CI-EN-1405927, and by the Moore-Sloan Data Science Environment at NYU.},
  isbn = {978-1-4503-3531-7},
  language = {English},
  number-of-cited-references = {18},
  oa = {Bronze},
  orcid-numbers = {Freire, Juliana/0000-0003-3915-7075 Rampin, Remi/0000-0002-0524-2282},
  organization = {{ACM SIGMOD; Assoc Comp Machinery; Microsoft; Oracle; Tableau; Alibaba com; AT \& T; Facebook; Google; IBM Res; Infosys; Platfora; Recruit; Salesforce; SAP; Snowflake; Amazon Web Serv; Cloudera; Esgyn; HP; Intel; LinkedIn; LogicBlox; Memsql; Splice Machine; Visa Res; Natl Sci Fdn}},
  research-areas = {Computer Science},
  researcherid-numbers = {Freire, Juliana/AAQ-4484-2020},
  times-cited = {29},
  unique-id = {ISI:000452538600142},
  usage-count-last-180-days = {1},
  usage-count-since-2013 = {1},
  web-of-science-categories = {Computer Science, Information Systems},
  keywords = {Computational Reproducibility; Provenance; ReproZip},
  file = {/Users/awwillc/Zotero/storage/8Q4YJPS5/Chirigati et al. - 2016 - ReproZip Computational reproducibility with ease.pdf}
}

@article{ISI:000454682100001,
  type = {Article},
  title = {Towards Computational Reproducibility: Researcher Perspectives on the Use and Sharing of Software},
  author = {AlNoamany, Yasmin and Borghi, John A.},
  year = {2018},
  month = sep,
  journal = {PEERJ COMPUTER SCIENCE},
  publisher = {{PEERJ INC}},
  address = {{341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND}},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.163},
  abstract = {Research software, which includes both source code and executables used as part of the research process, presents a significant challenge for efforts aimed at ensuring reproducibility. In order to inform such efforts, we conducted a survey to better understand the characteristics of research software as well as how it is created, used, and shared by researchers. Based on the responses of 215 participants, representing a range of research disciplines, we found that researchers create, use, and share software in a wide variety of forms for a wide variety of purposes, including data collection, data analysis, data visualization, data cleaning and organization, and automation. More participants indicated that they use open source software than commercial software. While a relatively small number of programming languages (e.g., Python, R, JavaScript, C++, MATLAB) are used by a large number, there is a long tail of languages used by relatively few. Between-group comparisons revealed that significantly more participants from computer science write source code and create executables than participants from other disciplines. Differences between researchers from computer science and other disciplines related to the knowledge of best practices of software creation and sharing were not statistically significant. While many participants indicated that they draw a distinction between the sharing and preservation of software, related practices and perceptions were often not aligned with those of the broader scholarly communications community.},
  affiliation = {AlNoamany, Y (Corresponding Author), Univ Calif Berkeley, Berkeley, CA 94720 USA. AlNoamany, Yasmin, Univ Calif Berkeley, Berkeley, CA 94720 USA. Borghi, John A., Calif Digital Lib, Oakland, CA USA.},
  article-number = {e163},
  author-email = {yasminal@berkeley.edu},
  cited-references = {AlNoamany Y, 2018, DATA RE PERSPECTIVES, DOI [10.6078/D1HM2W, DOI 10.6078/D1HM2W]. AlNoamany Y, 2018, ZENODO, DOI [10.5281/zenodo.1195605, DOI 10.5281/ZENODO.1195605]. Barnes N, 2010, NATURE, V467, P753, DOI 10.1038/467753a. Boettiger Carl, 2015, ACM SIGOPS Operating Systems Review, V49, P71. Borgman CL, 2012, COMPUT SUPP COOP W J, V21, P485, DOI 10.1007/s10606-012-9169-z. Chassanoff A, 2018, OSF PREPRINTS, DOI [10.31219/osf.io/fb5s8, DOI 10.31219/OSF.IO/FB5S8]. Chirigati F., 2013, P 5 USENIX C THEOR P, P1. Cochrane E, 2018, J DIGITAL MEDIA MANA, V6, P255. Crouch S, 2013, COMPUT SCI ENG, V15, P74, DOI 10.1109/MCSE.2013.133. Eglen SJ, 2017, NAT NEUROSCI, V20, P770, DOI 10.1038/nn.4550. Fecher B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118053. Goble C, 2014, IEEE INTERNET COMPUT, V18, P4, DOI 10.1109/MIC.2014.88. Goodman SN, 2016, SCI TRANSL MED, V8, DOI 10.1126/scitranslmed.aaf5027. Hafer L, 2009, COMMUN ACM, V52, P126, DOI 10.1145/1610252.1610285. Hannay JE, 2009, 2009 ICSE WORKSHOP ON SOFTWARE ENGINEERING FOR COMPUTATIONAL SCIENCE AND ENGINEERING, P1, DOI 10.1109/SECSE.2009.5069155. Herbsleb J.D., 2011, P ACM 2011 C COMP SU, DOI [10.1145/1958824.1958904, DOI 10.1145/1958824.1958904]. Hey T, 2009, 4 PARADIGM DATA INTE. Hong NC, 2011, DIGITAL PRESERVATION. Hong NC, 2014, DEALING SOFTWARE RES, DOI [10.6084/m9.figshare.1150299, DOI 10.6084/M9.FIGSHARE.1150299]. Howison J, 2013, P 2013 C COMP SUPP C, P459, DOI DOI 10.1145/2441776.2441828. Howison J, 2015, TECHNICAL REPORT. Howison J, 2016, J ASSOC INF SCI TECH, V67, P2137, DOI 10.1002/asi.23538. Hucka M, 2018, J SYST SOFTWARE, V141, P171, DOI 10.1016/j.jss.2018.03.047. Ince DC, 2012, NATURE, V482, P485, DOI 10.1038/nature10836. Jimenez Rafael C, 2017, F1000Res, V6, DOI 10.12688/f1000research.11407.1. Joppa LN, 2013, SCIENCE, V340, P814, DOI 10.1126/science.1231535. Katz DS, 2013, J OPEN RES SOFTWARE, V6, P10, DOI [10.5334/jors.184, DOI 10.5334/JORS.184]. Kim Y, 2016, J ASSOC INF SCI TECH, V67, P776, DOI 10.1002/asi.23424. Kissel R, 2011, 7298 NIST IR, V7298. Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87. Kratz JE, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117619. Marwick B, 2017, J ARCHAEOL METHOD TH, V24, P424, DOI 10.1007/s10816-015-9272-9. McCarthy DJ, 2014, GENOME MED, V6, DOI 10.1186/gm543. Meyerson J, 2017, D LIB MAGAZINE, V23, DOI [10.1045/MAY2017.meyerson, DOI 10.1045/MAY2017.MEYERSON]. Monteith JY, 2014, P 2014 EUR C SOFTW A, DOI 10.1145/2642803.2642812. Morin A, 2012, SCIENCE, V336, P159, DOI 10.1126/science.1218263. Morin A, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002598. Munafo MR, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-016-0021. National Institutes of Health (NIH), 2016, STRAT NIH DAT MAN SH. Nosek BA, 2015, SCIENCE, V348, P1422, DOI 10.1126/science.aab2374. Nosek BA, 2012, PERSPECT PSYCHOL SCI, V7, P615, DOI 10.1177/1745691612459058. Pan XL, 2016, SCIENTOMETRICS, V109, P1593, DOI 10.1007/s11192-016-2138-4. Perez F, 2007, COMPUT SCI ENG, V9, P21, DOI 10.1109/MCSE.2007.53. Piccolo SR, 2016, GIGASCIENCE, V5, DOI 10.1186/s13742-016-0135-4. Prabhu P, 2011, STATE PRACTICE REPOR, P19, DOI [10.1145/2063348.2063374, DOI 10.1145/2063348.2063374]. Prlic A, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002802. Ram K, 2017, SI2 S2I2 CONCEPTUALI. Rios Fernando, 2016, D-Lib Magazine, V22, DOI 10.1045/july2016-rios. Rios F, 2017, OPEN SCI FRAMEWORK, DOI [10.17605/OSF.IO/D4KEF, DOI 10.17605/OSF.IO/D4KEF]. Sadowski C, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P191, DOI 10.1145/2786805.2786855. Sandve GK, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003285. Sayre F, 2018, COLL RES LIBR, V79, P2, DOI 10.5860/crl.79.1.2. Smith AM, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.86. StackOverflow, 2017, DEV SURV RES 2017. Steeves V, 2017, COLLABORATIVE LIB, V9, P80. Stodden V., 2014, IMPLEMENTING REPROD. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Stodden V, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067111. Stodden V, 2009, COMPUT SCI ENG, V11, P35, DOI 10.1109/MCSE.2009.19. Teal T. K., 2015, INT J DIGIT CURATION, V10, P343, DOI [10.2218/ijdc.v10i1.351., DOI 10.2218/IJDC.V10I1.351, 10.2218/ijdc.v10i1.351]. Tenopir C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021101. Thain D, 2015, P 12 INT C DIG PRES, DOI [10.7274/R0CZ353M, DOI 10.7274/R0CZ353M]. Vandewalle P, 2012, COMPUT SCI ENG, V14, P42, DOI 10.1109/MCSE.2012.63. Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18. Wilson G., 2017, PLOS COMPUT BIOL, V13, P1, DOI [10.1371/journal.pcbi.1005510, DOI 10.1371/J0URNAL.PCBI.1005510]. Wilson G, 2006, COMPUT SCI ENG, V8, P66, DOI 10.1109/MCSE.2006.122.},
  da = {2021-06-23},
  doc-delivery-number = {HG1AR},
  funding-acknowledgement = {Alfred P. Sloan FoundationAlfred P. Sloan Foundation [G-2015-14112, G-2014-13746]; National Science Foundation NSF (ACI)National Science Foundation (NSF) [1349002]; Berkeley Research Impact Initiative (BRII) - UC Berkeley Library},
  funding-text = {This work is supported in part by Alfred P. Sloan Foundation (\#G-2015-14112 and \#G-2014-13746) and the National Science Foundation NSF (ACI \#1349002). This publication was made possible in part by support from the Berkeley Research Impact Initiative (BRII) sponsored by the UC Berkeley Library. There was no additional external funding received for this study. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.},
  journal-iso = {PeerJ Comput. Sci.},
  keywords-plus = {COMPUTER CODE; SCIENTISTS; SCIENCE; IMPACT},
  language = {English},
  number-of-cited-references = {66},
  oa = {DOAJ Gold, Green Published},
  research-areas = {Computer Science},
  times-cited = {9},
  unique-id = {ISI:000454682100001},
  usage-count-last-180-days = {2},
  usage-count-since-2013 = {3},
  web-of-science-categories = {Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory \& Methods},
  keywords = {Software sustainability; Reproducibility; Research software; Code; Finding software; Sharing software},
  file = {/Users/awwillc/Zotero/storage/4E7UZK2C/AlNoamany and Borghi - 2018 - Towards computational reproducibility researcher .pdf}
}

@article{ISI:000459536000022,
  type = {Editorial Material},
  title = {Computational Reproducibility the Elephant in the Room},
  author = {Hatton, Les and {van Genuchten}, Michiel},
  year = {2019},
  month = mar,
  journal = {IEEE SOFTWARE},
  volume = {36},
  number = {2},
  pages = {137+},
  publisher = {{IEEE COMPUTER SOC}},
  address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
  issn = {0740-7459},
  doi = {10.1109/ms.2018.2883805},
  affiliation = {Hatton, L (Corresponding Author), Kingston Univ, Forens Software Engn, London, England. Hatton, Les, Kingston Univ, Forens Software Engn, London, England. van Genuchten, Michiel, VitalHlth Software, Management Team, Minneapolis, MN USA.},
  author-email = {esh@oakcomp.co.uk genuchten@ieee.org},
  cited-references = {Claerbout J. F., 1994, NATL RES COUNC M HIG. Freedman LP, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002165. Hatton L, 2016, FULL COMPUTATIONAL R. Hatton L, 2017, J SOFTW-EVOL PROC, V29, DOI 10.1002/smr.1847. Huston L., 2014, NEW ENGLAND J MED DE. Ioannidis JPA, 2014, PLOS MED, V11, DOI 10.1371/journal.pmed.1001747. Kuhn Thomas, 1962, STRUCTURE SCI REVOLU, DOI [10.1086/ahr/68.3.700, DOI 10.1086/AHR/68.3.700]. Mossinger J, 2010, IEEE SOFTWARE, V27, P92, DOI 10.1109/MS.2010.55. Myers G. J., 1979, ART SOFTWARE TESTING. Nagy J, 2016, IEEE SOFTWARE, V33, P101, DOI 10.1109/MS.2016.91. Perkel J, 2018, TOOLKIT DATA TRANSPA. Popper Karl, 1959, LOGIC SCI DISCOVERY. Rousseau D, 2012, IEEE SOFTWARE, V29, P11, DOI 10.1109/MS.2012.123. van Genuchten M, 2011, IEEE SOFTWARE, V28, P24, DOI 10.1109/MS.2011.107. Wester R, 2015, IEEE SOFTWARE, V32, P37, DOI 10.1109/MS.2015.53. Zwart SP, 2016, IEEE SOFTWARE, V33, P25, DOI 10.1109/MS.2016.113.},
  da = {2021-06-23},
  doc-delivery-number = {HM5SR},
  eissn = {1937-4194},
  journal-iso = {IEEE Softw.},
  keywords-plus = {SOFTWARE},
  language = {English},
  number-of-cited-references = {16},
  oa = {Bronze, Green Accepted},
  orcid-numbers = {Hatton, Les/0000-0003-2226-3453},
  research-areas = {Computer Science},
  times-cited = {1},
  unique-id = {ISI:000459536000022},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {3},
  web-of-science-categories = {Computer Science, Software Engineering},
  file = {/Users/awwillc/Zotero/storage/ME7BGK3L/Hatton and van Genuchten - 2019 - Computational reproducibility the elephant in the .pdf}
}

@inproceedings{ISI:000468499301002,
  type = {Proceedings Paper},
  title = {Predicting Computational Reproducibility of Data Analysis Pipelines in Large Population Studies Using Collaborative Filtering},
  booktitle = {2018 {{IEEE INTERNATIONAL CONFERENCE ON BIG DATA}} ({{BIG DATA}})},
  author = {Barghi, Soudabeh and Scaria, Lalet and Salari, Ali and Glatard, Tristan},
  editor = {{Abe, N and Liu, H and Pu, C and Hu, X and Ahmed, N and Qiao, M and Song, Y and Kossmann, D and Liu, B and Lee, K and Tang, J and He, J and Saltz, J}},
  year = {2018},
  series = {{{IEEE}} International Conference on Big Data},
  pages = {943--950},
  publisher = {{IEEE}},
  address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
  issn = {2639-1589},
  abstract = {Evaluating the computational reproducibility of data analysis pipelines has become a critical issue. It is, however, a cumbersome process for analyses that involve data from large populations of subjects, due to their computational and storage requirements. We present a method to predict the computational reproducibility of data analysis pipelines in large population studies. We formulate the problem as a collaborative filtering process, with constraints on the construction of the training set. We propose 6 different strategies to build the training set, which we evaluate on 2 datasets, a synthetic one modeling a population with a growing number of subject types, and a real one obtained with neuroinformatics pipelines. Results show that one sampling method, ``Random File Numbers (Uniform)'' is able to predict computational reproducibility with a good accuracy. We also analyze the relevance of including file and subject biases in the collaborative filtering model. We conclude that the proposed method is able to speed-up reproducibility evaluations substantially, with a reduced accuracy loss.},
  affiliation = {Barghi, S (Corresponding Author), Concordia Univ, Dept Comp Sci \& Software Engn, Montreal, PQ, Canada. Barghi, Soudabeh; Scaria, Lalet; Salari, Ali; Glatard, Tristan, Concordia Univ, Dept Comp Sci \& Software Engn, Montreal, PQ, Canada.},
  cited-references = {Baker M, 2016, NATURE, V533, P452, DOI 10.1038/533452a. Bowring A., 2018, BIORXIV. Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43. Feng DW, 2013, FUTURE GENER COMP SY, V29, P2272, DOI 10.1016/j.future.2013.06.001. Glasser MF, 2013, NEUROIMAGE, V80, P105, DOI 10.1016/j.neuroimage.2013.04.127. Glatard T, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00012. Gronenschild EHBM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038234. Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263. Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1. Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344. Peng RD, 2011, SCIENCE, V334, P1226, DOI 10.1126/science.1213847. Van Essen DC, 2013, NEUROIMAGE, V80, P62, DOI 10.1016/j.neuroimage.2013.05.041.},
  da = {2021-06-23},
  doc-delivery-number = {BM7WO},
  isbn = {978-1-5386-5035-6},
  language = {English},
  number-of-cited-references = {12},
  organization = {{IEEE; IEEE Comp Soc; Expedia Grp; Baidu; Squirrel AI Learning; Ankura; Springer}},
  research-areas = {Computer Science},
  times-cited = {0},
  unique-id = {ISI:000468499301002},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {0},
  web-of-science-categories = {Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory \& Methods}
}

@article{ISI:000473184100005,
  type = {Article},
  title = {Lifecycle Support for Scientific Investigations: {{Integrating}} Data, Computing, and Workflows},
  author = {Catlin, Ann Christine and HewaNadungodage, Chandima and Bejarano, Andres},
  year = {2019},
  month = jul,
  journal = {COMPUTING IN SCIENCE \& ENGINEERING},
  volume = {21},
  number = {4},
  pages = {49--61},
  publisher = {{IEEE COMPUTER SOC}},
  address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
  issn = {1521-9615},
  doi = {10.1109/mcse.2019.2901433},
  abstract = {Scientific workflows have emerged as a model for representing the complex processes carried out by scientists throughout their investigations, encompassing research activities corresponding to data collection, data flow, computation, output analysis, and all the ways these are used together to produce results. Existing infrastructures support elements of the workflow, such as data repositories or computing services, but these are not integrated as interactive environments that provide full investigation lifecycle support. The digital environment for enabling data-driven sciences (DEEDS) project brought together domain scientists and computer scientists to create a platformthat provides interactive end-to-end support for diverse scientific workflows. Key among requirements were preservation, provenance, coupling of data and computing, results traceability, collaborative sharing, exploration, and publication of the full products of research work. This paper highlights use cases that contributed to DEEDS development and concludes with lessons learned from a process that joined experiences and perspectives from diverse science domains.},
  affiliation = {Catlin, AC (Corresponding Author), Purdue Univ, Rosen Ctr Adv Comp, W Lafayette, IN 47907 USA. Catlin, Ann Christine; HewaNadungodage, Chandima; Bejarano, Andres, Purdue Univ, Rosen Ctr Adv Comp, W Lafayette, IN 47907 USA. Bejarano, Andres, Purdue Univ, Comp Sci, W Lafayette, IN 47907 USA.},
  author-email = {acc@purdue.edu chewanad@purdue.edu abejara@purdue.edu},
  cited-references = {[Anonymous], 2006, NSF WORKSH CHALL SCI. Boyko A., 2009, NDIIPP CONTENT TRANS. Catlin A. C., 2018, P SCI GAT SEP. Catlin AC, 2018, COMPUT SCI ENG, V20, P49, DOI 10.1109/MCSE.2017.3301213. Deelman E, 2018, INT J HIGH PERFORM C, V32, P159, DOI 10.1177/1094342017704893. Frisch M.J., 2016, GAUSSIAN 16 REVISION. Hoehn RD, 2018, FRONT PHYS-LAUSANNE, V6, DOI 10.3389/fphy.2018.00025. King G, 2007, SOCIOL METHOD RES, V36, P173, DOI 10.1177/0049124107306660. Leipzig J, 2017, BRIEF BIOINFORM, V18, P530, DOI 10.1093/bib/bbw020. McLennan M, 2015, CONCURR COMP-PRACT E, V27, P328, DOI 10.1002/cpe.3257. McLennan M, 2010, COMPUT SCI ENG, V12, P48, DOI 10.1109/MCSE.2010.41. Singh M., 1996, P NSF WORKSH WORKFL, P28. Sun XS, 2019, PROG PHOTOVOLTAICS, V27, P55, DOI 10.1002/pip.3043. Weibel A., 1998, 2413 RFC IETF. Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18.},
  da = {2021-06-24},
  doc-delivery-number = {IF6IJ},
  eissn = {1558-366X},
  funding-acknowledgement = {NSF CIF21 DIBBs award [1724728]},
  funding-text = {DEEDS is funded by NSF CIF21 DIBBs award \#1724728. We thank NSF program director A. Walton; co-PIs A. Alam, J. Francisco, M. Sepulveda, and C. Weaver; science domain Postdoctoral Researchers and Graduate students led by T. Patel, R. Asadpour, X. Sun, M. Iacchetta, R. Flynn, R. Hoehn, J. Hodges, and J. Monical; and members of R\&D with major contributions: S. Clark, G. Wickramaarachchi, S. Fernando, and P. Desigavinayagam.},
  journal-iso = {Comput. Sci. Eng.},
  keywords-plus = {HUBZERO; SCIENCE},
  language = {English},
  number-of-cited-references = {15},
  research-areas = {Computer Science},
  times-cited = {4},
  unique-id = {ISI:000473184100005},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {6},
  web-of-science-categories = {Computer Science, Interdisciplinary Applications}
}

@inproceedings{ISI:000476945900003,
  type = {Proceedings Paper},
  title = {Enabling the Verification of Computational Results an Empirical Evaluation of Computational Reproducibility},
  booktitle = {{{PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON PRACTICAL REPRODUCIBLE EVALUATION OF COMPUTER SYSTEMS}} ({{P}}-{{RECS}}'18)},
  author = {Stodden, Victoria and Krafczyk, Matthew S. and Bhaskar, Adhithya},
  year = {2018},
  publisher = {{ASSOC COMPUTING MACHINERY}},
  address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
  doi = {10.1145/3214239.3214242},
  abstract = {The ability to independently regenerate published computational claims is widely recognized as a key component of scientific reproducibility. In this article we take a narrow interpretation of this goal, and attempt to regenerate published claims from author-supplied information, including data, code, inputs, and other provided specifications, on a different computational system than that used by the original authors. We are motivated by Claerbout and Donoho's exhortation of the importance of providing complete information for reproducibility of the published claim. We chose the Elsevier journal, the Journal of Computational Physics, which has stated author guidelines that encourage the availability of computational digital artifacts that support scholarly findings. In an IRB approved study at the University of Illinois at Urbana-Champaign (IRB \#17329) we gathered artifacts from a sample of authors who published in this journal in 2016 and 2017. We then used the ICERM criteria generated at the 2012 ICERM workshop ``Reproducibility in Computational and Experimental Mathematics'' to evaluate the sufficiency of the information provided in the publications and the ease with which the digital artifacts afforded computational reproducibility. We find that, for the articles for which we obtained computational artifacts, we could not easily regenerate the findings for 67\% of them, and we were unable to easily regenerate all the findings for any of the articles. We then evaluated the artifacts we did obtain (55 of 306 articles) and find that the main barriers to computational reproducibility are inadequate documentation of code, data, and workflow information (70.9\%), missing code function and setting information, and missing licensing information (75\%). We recommend improvements based on these findings, including the deposit of supporting digital artifacts for reproducibility as a condition of publication, and verification of computational findings via re-execution of the code when possible.},
  affiliation = {Stodden, V (Corresponding Author), Univ Illinois, Champaign, IL 61820 USA. Stodden, Victoria; Krafczyk, Matthew S.; Bhaskar, Adhithya, Univ Illinois, Champaign, IL 61820 USA.},
  author-email = {vcs@stodden.net mkrafcz2@illinois.edu bhaskar7@illinois.edu},
  book-group-author = {Assoc Comp Machinery},
  cited-references = {Bailey David H, 2013, NOTICES AMS. Barba Lorena A., 2018, ABS180203311 CORR. Berman F, 2018, COMMUN ACM, V61, P67, DOI 10.1145/3188721. BUCKHEIT JB, 1995, TECHNICAL REPORT. Claerbout J., 1994, TECHNICAL REPORT. Collberg C, 2016, COMMUN ACM, V59, P62, DOI 10.1145/2812803. Donoho DL, 2009, COMPUT SCI ENG, V11, P8, DOI 10.1109/MCSE.2009.15. Gentleman R, 2007, J COMPUT GRAPH STAT, V16, P1, DOI 10.1198/106186007X178663. Ioannidis JPA, 2009, NAT GENET, V41, P149, DOI 10.1038/ng.295. KING G, 1995, PS, V28, P444, DOI 10.2307/420301. Nosek BA, 2015, SCIENCE, V348, P1422, DOI 10.1126/science.aab2374. Schwab M, 2000, COMPUT SCI ENG, V2, P61, DOI 10.1109/5992.881708. Stodden V., 2013, SIAM NEWS. Stodden V, 2018, P NATL ACAD SCI USA, V115, P2584, DOI 10.1073/pnas.1708290115. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Stodden V, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067111. Stodden V, 2009, COMPUT SCI ENG, V11, P35, DOI 10.1109/MCSE.2009.19.},
  da = {2021-06-23},
  doc-delivery-number = {BN2MM},
  funding-acknowledgement = {NSFNational Science Foundation (NSF) [ACI-1659702]; NCSA SPIN program},
  funding-text = {The authors would like to thank David Wong, Yantong Zhang, and Alex Dickinson for outstanding research assistance. We also acknowledge support from NSF Award ACI-1659702 and the NCSA SPIN program.},
  isbn = {978-1-4503-5861-3},
  keywords-plus = {REPEATABILITY},
  language = {English},
  number-of-cited-references = {17},
  oa = {Bronze},
  research-areas = {Computer Science; Engineering},
  times-cited = {1},
  unique-id = {ISI:000476945900003},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {0},
  web-of-science-categories = {Computer Science, Theory \& Methods; Engineering, Electrical \& Electronic},
  keywords = {reproducible research; data access; code access; workflows; provenance; reproducibility policy},
  file = {/Users/awwillc/Zotero/storage/7K6SZV8Z/Stodden et al. - 2018 - Enabling the verification of computational results.pdf}
}

@article{ISI:000484527300002,
  type = {Article},
  title = {Computational Reproducibility of Scientific Workflows at Extreme Scales},
  author = {Pouchard, Line and Baldwin, Sterling and Elsethagen, Todd and Jha, Shantenu and Raju, Bibi and Stephan, Eric and Tang, Li and Van Dam, Kerstin Kleese},
  year = {2019},
  month = sep,
  journal = {INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS},
  volume = {33},
  number = {5, SI},
  pages = {763--776},
  publisher = {{SAGE PUBLICATIONS LTD}},
  address = {{1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND}},
  issn = {1094-3420},
  doi = {10.1177/1094342019839124},
  abstract = {We propose an approach for improved reproducibility that includes capturing and relating provenance characteristics and performance metrics. We discuss two use cases: scientific reproducibility of results in the Energy Exascale Earth System Model (E3SM-previously ACME) and performance reproducibility in molecular dynamics workflows on HPC platforms. To capture and persist the provenance and performance data of these workflows, we have designed and developed the Chimbuko and ProvEn frameworks. Chimbuko captures provenance and enables detailed single workflow performance analysis. ProvEn is a hybrid, queryable system for storing and analyzing the provenance and performance metrics of multiple runs in workflow performance analysis campaigns. Workflow provenance and performance data output from Chimbuko can be visualized in a dynamic, multilevel visualization providing overview and zoom-in capabilities for areas of interest. Provenance and related performance data ingested into ProvEn is queryable and can be used to reproduce runs. Our provenance-based approach highlights challenges in extracting information and gaps in the information collected. It is agnostic to the type of provenance data it captures so that both the reproducibility of scientific results and that of performance can be explored with our tools.},
  affiliation = {Pouchard, L (Corresponding Author), Brookhaven Natl Lab, POB 5000, Upton, NY 11973 USA. Pouchard, Line; Jha, Shantenu, Brookhaven Natl Lab, Ctr Data Driven Discovery, Computat Sci Initiat, Upton, NY 11973 USA. Van Dam, Kerstin Kleese, Brookhaven Natl Lab, Computat Sci Initiat, Upton, NY 11973 USA. Baldwin, Sterling, Lawrence Livermore Natl Lab, Livermore, CA USA. Elsethagen, Todd; Raju, Bibi; Stephan, Eric, Pacific Northwest Natl Lab, Richland, WA 99352 USA. Tang, Li, Los Alamos Natl Lab, Los Alamos, NM USA.},
  author-email = {pouchard@bnl.gov},
  cited-references = {Agrawal K, 2014, 2014 1ST INTERNATIONAL WORKSHOP ON HPC USER SUPPORT TOOLS (HUST), P32, DOI 10.1109/HUST.2014.6. Bechhofer S., 2010, NATURE PRECEDINGS, DOI [10.1038/npre.2010.4626.1, DOI 10.1038/NPRE.2010.4626.1]. Boettiger Carl, 2015, ACM SIGOPS Operating Systems Review, V49, P71. Carpen-Amarie A, 2014, LECT NOTES COMPUT SC, V8805, P499, DOI 10.1007/978-3-319-14325-5\_43. Chirigati F, 2013, P 2013 ACM SIGMOD IN, P977, DOI [10.1145/2463676.2465269, DOI 10.1145/2463676.2465269]. Cinquini L, 2014, FUTURE GENER COMP SY, V36, P400, DOI 10.1016/j.future.2013.07.002. Collange S, 2015, PARALLEL COMPUT, V49, P83, DOI 10.1016/j.parco.2015.09.001. Davison A. P., 2014, IMPLEMENTING REPROD, P57, DOI DOI 10.1201/B16868. Davison AP, 2012, COMPUT SCI ENG, V14, P48, DOI 10.1109/MCSE.2012.41. Demmel J, 2013, P S COMP ARITHM, P235, DOI 10.1109/ARITH.2013.43. Drummond C, 2009, WORKSH EV METH MACH. Elsethagen T., 2016, 2016 NEW YORK SCI DA, P1, DOI DOI 10.1109/NYSDS.2016.7747819. Gamblin T, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807623. Gil Y, 2016, EARTH SPACE SCI, V3, P388, DOI 10.1002/2015EA000136. Goble C, 2013, KNOWLEDGE DISCOVERY, V348, P3, DOI DOI 10.1007/978-3-642-37186-8\_1. Gramoli V, 2016, EUR C PAR PROC, P596, DOI [10.1007/978-3-319-58943-5\_48, DOI 10.1007/978-3-319-58943-5\_48]. Heroux M, 2018, SAND201811186. Huang H, 2014, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2641574. Huang RZ, 2016, PROCEEDINGS OF XSEDE16: DIVERSITY, BIG DATA, AND SCIENCE AT SCALE, DOI 10.1145/2949550.2949560. Huck KA, 2006, LECT NOTES COMPUT SC, V4192, P313. Hunold S, 2013, ARXIV13083648. James D, 2014, ARXIV14125557. Jeffrey S.Vetter, 2018, DOE ASCR WORKSH EXTR, V12, DOI [10.2172/1473756, DOI 10.2172/1473756]. Johansen H, 2014, DOE ASCR WORKSH, P13. Johns M, 2015, GETTING STARTED HAZE. Kleese van Dam K, 2015, 8 WORKSH MAN TASK CO, DOI [10.13140/RG.2.1.3311.9127, DOI 10.13140/RG.2.1.3311.9127]. Koch D, 2016, AGU FALL M. Langford J, 2017, 34 INT C MACH LEARN. Liu Q, 2014, CONCURR COMP-PRACT E, V26, P1453, DOI 10.1002/cpe.3125. Merzky A, 2016, 151208194V2 ARXIV. Moreau L., 2013, SYNTHESIS LECT SEMAN, V3, P1, DOI DOI 10.2200/S00528ED1V01Y201308WBE007. Nussbaum L, 2017, PROCEEDINGS OF THE 2017 REPRODUCIBILITY WORKSHOP (REPRODUCIBILITY `17), P24, DOI 10.1145/3097766.3097773. Nussbaum L, 2017, IEEE SYM PARA DISTR, P1571, DOI 10.1109/IPDPSW.2017.101. Peng RD, 2011, SCIENCE, V334, P1226, DOI 10.1126/science.1213847. Pilgrim P, 2015, DIGITAL JAVA EE 7 WE. PLIMPTON S, 1995, J COMPUT PHYS, V117, P1, DOI 10.1006/jcph.1995.1039. Pouchard L, 2018, IEEE P NEW YORK SCI, DOI [10.1109/NYSDS.2018.8538951, DOI 10.1109/NYSDS.2018.8538951]. Pouchard L, 2017, 2017 NEW YORK SCIENTIFIC DATA SUMMIT (NYSDS). Sandve GK, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003285. Singh A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P2115, DOI 10.1109/BigData.2016.7840839. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Taylor BN, 1994, GUIDELINES EVALUATIN, DOI [10.1002/10.6028/NIST.tn.1297, DOI 10.1002/10.6028/NIST.TN.1297]. Turilli M., 2016, ARXIV160903484. Valiev M, 2010, COMPUT PHYS COMMUN, V181, P1477, DOI 10.1016/j.cpc.2010.04.018. Vitek J, 2012, ACM SIGPLAN NOTICES, V47, P30, DOI 10.1145/2442776.2442781. Xie C, 2018, VISIGRAPP 2018: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS / INTERNATIONAL CONFERENCE ON INFORMATION VISUALIZATION THEORY AND APPLICATIONS (IVAPP), VOL 3, P330, DOI 10.5220/0006646803330340. Yoo SJ, 2016, PROC INT CONF DATA, P637, DOI 10.1109/ICDE.2016.7498277. Zhang J, 2016, PROC INT CONF PARAL, P268, DOI 10.1109/ICPP.2016.38. Zheng CF, 2016, IEEE INT POWER ELEC, P37, DOI 10.1109/IPEMC.2016.7512258.},
  da = {2021-06-24},
  doc-delivery-number = {IV8PK},
  eissn = {1741-2846},
  journal-iso = {Int. J. High Perform. Comput. Appl.},
  keywords-plus = {NUMERICAL REPRODUCIBILITY},
  language = {English},
  number-of-cited-references = {49},
  orcid-numbers = {baldwin, sterling/0000-0003-1103-150X Tang, Li/0000-0002-7636-0876 Pouchard, Line/0000-0002-2120-6521},
  research-areas = {Computer Science},
  times-cited = {3},
  unique-id = {ISI:000484527300002},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {6},
  web-of-science-categories = {Computer Science, Hardware \& Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods},
  keywords = {Computational reproducibility; scientific workflows; provenance; performance analysis; ProvEn; Chimbuko}
}

@article{ISI:000484527300002,
  type = {Article},
  title = {Computational Reproducibility of Scientific Workflows at Extreme Scales},
  author = {Pouchard, Line and Baldwin, Sterling and Elsethagen, Todd and Jha, Shantenu and Raju, Bibi and Stephan, Eric and Tang, Li and Van Dam, Kerstin Kleese},
  year = {2019},
  month = sep,
  journal = {INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS},
  volume = {33},
  number = {5, SI},
  pages = {763--776},
  publisher = {{SAGE PUBLICATIONS LTD}},
  address = {{1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND}},
  issn = {1094-3420},
  doi = {10.1177/1094342019839124},
  abstract = {We propose an approach for improved reproducibility that includes capturing and relating provenance characteristics and performance metrics. We discuss two use cases: scientific reproducibility of results in the Energy Exascale Earth System Model (E3SM-previously ACME) and performance reproducibility in molecular dynamics workflows on HPC platforms. To capture and persist the provenance and performance data of these workflows, we have designed and developed the Chimbuko and ProvEn frameworks. Chimbuko captures provenance and enables detailed single workflow performance analysis. ProvEn is a hybrid, queryable system for storing and analyzing the provenance and performance metrics of multiple runs in workflow performance analysis campaigns. Workflow provenance and performance data output from Chimbuko can be visualized in a dynamic, multilevel visualization providing overview and zoom-in capabilities for areas of interest. Provenance and related performance data ingested into ProvEn is queryable and can be used to reproduce runs. Our provenance-based approach highlights challenges in extracting information and gaps in the information collected. It is agnostic to the type of provenance data it captures so that both the reproducibility of scientific results and that of performance can be explored with our tools.},
  affiliation = {Pouchard, L (Corresponding Author), Brookhaven Natl Lab, POB 5000, Upton, NY 11973 USA. Pouchard, Line; Jha, Shantenu, Brookhaven Natl Lab, Ctr Data Driven Discovery, Computat Sci Initiat, Upton, NY 11973 USA. Van Dam, Kerstin Kleese, Brookhaven Natl Lab, Computat Sci Initiat, Upton, NY 11973 USA. Baldwin, Sterling, Lawrence Livermore Natl Lab, Livermore, CA USA. Elsethagen, Todd; Raju, Bibi; Stephan, Eric, Pacific Northwest Natl Lab, Richland, WA 99352 USA. Tang, Li, Los Alamos Natl Lab, Los Alamos, NM USA.},
  author-email = {pouchard@bnl.gov},
  cited-references = {Agrawal K, 2014, 2014 1ST INTERNATIONAL WORKSHOP ON HPC USER SUPPORT TOOLS (HUST), P32, DOI 10.1109/HUST.2014.6. Bechhofer S., 2010, NATURE PRECEDINGS, DOI [10.1038/npre.2010.4626.1, DOI 10.1038/NPRE.2010.4626.1]. Boettiger Carl, 2015, ACM SIGOPS Operating Systems Review, V49, P71. Carpen-Amarie A, 2014, LECT NOTES COMPUT SC, V8805, P499, DOI 10.1007/978-3-319-14325-5\_43. Chirigati F, 2013, P 2013 ACM SIGMOD IN, P977, DOI [10.1145/2463676.2465269, DOI 10.1145/2463676.2465269]. Cinquini L, 2014, FUTURE GENER COMP SY, V36, P400, DOI 10.1016/j.future.2013.07.002. Collange S, 2015, PARALLEL COMPUT, V49, P83, DOI 10.1016/j.parco.2015.09.001. Davison A. P., 2014, IMPLEMENTING REPROD, P57, DOI DOI 10.1201/B16868. Davison AP, 2012, COMPUT SCI ENG, V14, P48, DOI 10.1109/MCSE.2012.41. Demmel J, 2013, P S COMP ARITHM, P235, DOI 10.1109/ARITH.2013.43. Drummond C, 2009, WORKSH EV METH MACH. Elsethagen T., 2016, 2016 NEW YORK SCI DA, P1, DOI DOI 10.1109/NYSDS.2016.7747819. Gamblin T, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807623. Gil Y, 2016, EARTH SPACE SCI, V3, P388, DOI 10.1002/2015EA000136. Goble C, 2013, KNOWLEDGE DISCOVERY, V348, P3, DOI DOI 10.1007/978-3-642-37186-8\_1. Gramoli V, 2016, EUR C PAR PROC, P596, DOI [10.1007/978-3-319-58943-5\_48, DOI 10.1007/978-3-319-58943-5\_48]. Heroux M, 2018, SAND201811186. Huang H, 2014, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2641574. Huang RZ, 2016, PROCEEDINGS OF XSEDE16: DIVERSITY, BIG DATA, AND SCIENCE AT SCALE, DOI 10.1145/2949550.2949560. Huck KA, 2006, LECT NOTES COMPUT SC, V4192, P313. Hunold S, 2013, ARXIV13083648. James D, 2014, ARXIV14125557. Jeffrey S.Vetter, 2018, DOE ASCR WORKSH EXTR, V12, DOI [10.2172/1473756, DOI 10.2172/1473756]. Johansen H, 2014, DOE ASCR WORKSH, P13. Johns M, 2015, GETTING STARTED HAZE. Kleese van Dam K, 2015, 8 WORKSH MAN TASK CO, DOI [10.13140/RG.2.1.3311.9127, DOI 10.13140/RG.2.1.3311.9127]. Koch D, 2016, AGU FALL M. Langford J, 2017, 34 INT C MACH LEARN. Liu Q, 2014, CONCURR COMP-PRACT E, V26, P1453, DOI 10.1002/cpe.3125. Merzky A, 2016, 151208194V2 ARXIV. Moreau L., 2013, SYNTHESIS LECT SEMAN, V3, P1, DOI DOI 10.2200/S00528ED1V01Y201308WBE007. Nussbaum L, 2017, PROCEEDINGS OF THE 2017 REPRODUCIBILITY WORKSHOP (REPRODUCIBILITY `17), P24, DOI 10.1145/3097766.3097773. Nussbaum L, 2017, IEEE SYM PARA DISTR, P1571, DOI 10.1109/IPDPSW.2017.101. Peng RD, 2011, SCIENCE, V334, P1226, DOI 10.1126/science.1213847. Pilgrim P, 2015, DIGITAL JAVA EE 7 WE. PLIMPTON S, 1995, J COMPUT PHYS, V117, P1, DOI 10.1006/jcph.1995.1039. Pouchard L, 2018, IEEE P NEW YORK SCI, DOI [10.1109/NYSDS.2018.8538951, DOI 10.1109/NYSDS.2018.8538951]. Pouchard L, 2017, 2017 NEW YORK SCIENTIFIC DATA SUMMIT (NYSDS). Sandve GK, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003285. Singh A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P2115, DOI 10.1109/BigData.2016.7840839. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Taylor BN, 1994, GUIDELINES EVALUATIN, DOI [10.1002/10.6028/NIST.tn.1297, DOI 10.1002/10.6028/NIST.TN.1297]. Turilli M., 2016, ARXIV160903484. Valiev M, 2010, COMPUT PHYS COMMUN, V181, P1477, DOI 10.1016/j.cpc.2010.04.018. Vitek J, 2012, ACM SIGPLAN NOTICES, V47, P30, DOI 10.1145/2442776.2442781. Xie C, 2018, VISIGRAPP 2018: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS / INTERNATIONAL CONFERENCE ON INFORMATION VISUALIZATION THEORY AND APPLICATIONS (IVAPP), VOL 3, P330, DOI 10.5220/0006646803330340. Yoo SJ, 2016, PROC INT CONF DATA, P637, DOI 10.1109/ICDE.2016.7498277. Zhang J, 2016, PROC INT CONF PARAL, P268, DOI 10.1109/ICPP.2016.38. Zheng CF, 2016, IEEE INT POWER ELEC, P37, DOI 10.1109/IPEMC.2016.7512258.},
  da = {2021-06-23},
  doc-delivery-number = {IV8PK},
  eissn = {1741-2846},
  journal-iso = {Int. J. High Perform. Comput. Appl.},
  keywords-plus = {NUMERICAL REPRODUCIBILITY},
  language = {English},
  number-of-cited-references = {49},
  orcid-numbers = {baldwin, sterling/0000-0003-1103-150X Tang, Li/0000-0002-7636-0876 Pouchard, Line/0000-0002-2120-6521},
  research-areas = {Computer Science},
  times-cited = {3},
  unique-id = {ISI:000484527300002},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {6},
  web-of-science-categories = {Computer Science, Hardware \& Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods},
  keywords = {Computational reproducibility; scientific workflows; provenance; performance analysis; ProvEn; Chimbuko}
}

@article{ISI:000487060400007,
  type = {Article; Proceedings Paper},
  title = {The Role of Machine Learning in Scientific Workflows},
  author = {Deelman, Ewa and Mandal, Anirban and Jiang, Ming and Sakellariou, Rizos},
  year = {2019},
  month = nov,
  journal = {INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS},
  volume = {33},
  number = {6, SI},
  pages = {1128--1139},
  publisher = {{SAGE PUBLICATIONS LTD}},
  address = {{1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND}},
  issn = {1094-3420},
  doi = {10.1177/1094342019852127},
  abstract = {Machine learning (ML) is being applied in a number of everyday contexts from image recognition, to natural language processing, to autonomous vehicles, to product recommendation. In the science realm, ML is being used for medical diagnosis, new materials development, smart agriculture, DNA classification, and many others. In this article, we describe the opportunities of using ML in the area of scientific workflow management. Scientific workflows are key to today's computational science, enabling the definition and execution of complex applications in heterogeneous and often distributed environments. We describe the challenges of composing and executing scientific workflows and identify opportunities for applying ML techniques to meet these challenges by enhancing the current workflow management system capabilities. We foresee that as the ML field progresses, the automation provided by workflow management systems will greatly increase and result in significant improvements in scientific productivity.},
  affiliation = {Deelman, E (Corresponding Author), Univ Southern Calif, Informat Sci Inst, Marina Del Rey, CA 90292 USA. Deelman, Ewa, Univ Southern Calif, Informat Sci Inst, Marina Del Rey, CA 90292 USA. Mandal, Anirban, Renaissance Comp Inst, Chapel Hill, NC USA. Jiang, Ming, Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94550 USA. Sakellariou, Rizos, Univ Manchester, Comp Sci, Manchester, Lancs, England.},
  author-email = {deelman@isi.edu},
  cited-references = {Abramson D, 2008, SC 08. Albrecht M, 2012, 1 WORKSH SCAL WORKFL. Altintas I, 2004, 16TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, PROCEEDINGS, P423. Amer M, 2012, P 3 RAP MIN COMM M C, P1, DOI [10.5455/ijavms.141, DOI 10.5455/IJAVMS.141]. Bala A, 2015, EXPERT SYST APPL, V42, P980, DOI 10.1016/j.eswa.2014.09.014. Bhaduri K., 2011, 2011 IEEE International Conference on Data Mining Workshops, P137, DOI 10.1109/ICDMW.2011.62. BINDONG, 2016, INT C HIGH PERFORM, P152, DOI DOI 10.1109/HIPC.2016.32. BLYTHE J, 2003, ICAPS 2003. Breiman L., 2017, CLASSIFICATION REGRE. Buneci ES, 2008, HIGH PERF COMP NETW, P1. Byun E-K, 2008, 4 IEEE INT C E SCI E. Carothers CD, 2002, J PARALLEL DISTR COM, V62, P1648, DOI 10.1016/S0743-7315(02)00004-7. Chandola V, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541882. Chase J, 2009, 2009 IEEE CONGRESS ON SERVICES (SERVICES-1 2009), VOLS 1 AND 2, P275, DOI 10.1109/SERVICES-I.2009.70. David De R, 2009, MICR E SCI WORKSH PI. Dean DJ, 2012, P 9 INT C AUT COMP. Deelman E, 2006, CONCURR COMP-PRACT E, V18, P1187, DOI 10.1002/cpe.1001. Deelman E, 2018, INT J HIGH PERFORM C, V32, P159, DOI 10.1177/1094342017704893. Deelman E, 2017, INT J HIGH PERFORM C, V31, P4, DOI 10.1177/1094342015594515. Deelman E, 2015, FUTURE GENER COMP SY, V46, P17, DOI 10.1016/j.future.2014.10.008. DeRoure D, 2007, IEEE INT C E SCI GRI. Du Y, 2015, INT S HIGH PERF COMP, P223, DOI 10.1109/HPCA.2015.7056035. Duan RB, 2005, LECT NOTES COMPUT SC, V3726, P704. Duda R.O., 2012, PATTERN CLASSIFICATI. Durillo J. J., 2012, 2012 IEEE 4th International Conference on Cloud Computing Technology and Science (CloudCom). Proceedings, P185, DOI 10.1109/CloudCom.2012.6427573. Elomaa T, 2002, P 6 EUR C PKDD 2002. Fahringer T, 2005, P 6 IEEE ACM INT WOR. Fu S., 2011, GLOB TEL C GLOBECOM, P1, DOI DOI 10.1109/GLOCOM.2011.6134532. GIL Y, 2004, IEEE INTELLIGENT SYS. Gil Y., 2007, P 19 NAT C INN APPL, V2, P1767. Gil Y, 2011, IEEE INTELL SYST, V26, P62, DOI 10.1109/MIS.2010.9. Goderis A, 2007, 2 INT WORKSH WORKFL. Goecks J, 2010, GENOME BIOL, V11, DOI 10.1186/gb-2010-11-8-r86. Goldstein M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152173. Gunter D, 2011, P 7 INT C NETW SERV, P1. HATHAWAY RJ, 1986, PATTERN RECOGN, V19, P477, DOI 10.1016/0031-3203(86)90047-6. He ZY, 2003, PATTERN RECOGN LETT, V24, P1641, DOI 10.1016/S0167-8655(03)00003-5. Huang D, 2019, IEEE T PARALL DISTR, V30, P615, DOI 10.1109/TPDS.2018.2867879. Ibidunmoye O., 2015, COMPUT SURV CSUR, V48, P4. Jain N, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503263. Jinka P., 2015, ANOMALY DETECTION MO. Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202. Jones AC, 2007, WORKFLOWS E SCI SCI, P80. Kiran M, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2785, DOI 10.1109/BigData.2015.7364082. Kohonen T, 2001, SELF ORG MAPS, V3rd. Kotliar M, 2018, CWL AIRFLOW LIGHTWEI, V2018, DOI [10.1101/249243, DOI 10.1101/249243]. Kourtellis N., 2019, LEARNING DATA STREAM, P177. Krol D., 2016, EUR WORKSH, P108. Lee YC, 2015, KNOWL-BASED SYST, V80, P153, DOI 10.1016/j.knosys.2015.02.012. Li P, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-334. Liu J, 2015, J GRID COMPUT, V13, P457, DOI 10.1007/s10723-015-9329-8. Liu J, 2012, INT C INTEL HUM MACH, P34, DOI 10.1109/IHMSC.2012.104. Lorena AC, 2011, EXPERT SYST APPL, V38, P5268, DOI 10.1016/j.eswa.2010.10.031. Ma KL, 2009, IEEE COMPUT GRAPH, V29, P14, DOI 10.1109/MCG.2009.120. MacQueen J.B., 1967, P 5 BERKELEY S ONMAT, VVolume 1, P281, DOI DOI 10.1007/S11665-016-2173-6. Malawski M, 2015, FUTURE GENER COMP SY, V48, P1, DOI 10.1016/j.future.2015.01.004. Malawski Maciej, 2015, SCI PROGRAM, V2015, P5. Mandal A, 2016, IEEE SYM PARA DISTR, P1370, DOI 10.1109/IPDPSW.2016.202. Matsunaga A, 2010, P 2010 10 IEEE ACM I, P495, DOI DOI 10.1109/CCGRID.2010.98. Meng F, 2014, LECT NOTES ELECTR EN, V296, P133, DOI 10.1007/978-3-642-54236-7\_15. Missier P, 2010, LECT NOTES COMPUT SC, V6187, P471, DOI 10.1007/978-3-642-13818-8\_33. Muniswamy-Reddy K., 2010, FAST, P15. Muniswamy-Reddy K. K., 2009, P 2009 C USENIX ANN, P10. Nemirovsky D, 2017, INT SYM COMP ARCHIT, P121, DOI 10.1109/SBAC-PAD.2017.23. Pal NR, 1996, NEURAL NETWORKS, V9, P787, DOI 10.1016/0893-6080(95)00094-1. Pietri I, 2014, 3 INT WORKSH POW AW. Pietri I, 2019, FUTURE GENER COMP SY, V94, P479, DOI 10.1016/j.future.2018.12.004. Pietri I, 2014, 2014 9TH WORKSHOP ON WORKFLOWS IN SUPPORT OF LARGE-SCALE SCIENCE (WORKS), P11, DOI 10.1109/WORKS.2014.12. Plankensteiner K, 2009, GRID SERVICES EVOLUT, P1. Poehlman WL, 2016, BIOINFORM BIOL INSIG, V10, P133, DOI 10.4137/BBI.S38193. Prathamesh G, 2016, IEEE 2016 INT C HIGH. Ramakrishnan A, 2007, 7 IEEE INT S CLUST C. Samak T., 2011, Proceedings of the 2011 IEEE 13th International Conference on High Performance Computing and Communication (HPCC 2011). 2011 IEEE International Workshop on Future Trends of Distributed Computing Systems (FTDCS 2011). Workshops of the 2011 International Conference on Ubiquitous Intelligence and Computing (UIC 2011). Workshops of the 2011 International Conference on Autonomic and Trusted Computing (ATC 2011), P373, DOI 10.1109/HPCC.2011.55. Samak T, 2011, P 6 WORKSH WORKFL SU, P107. Samak T, 2013, P IEEE INT C E-SCI, P45, DOI 10.1109/eScience.2013.49. Simmhan YL, 2005, SIGMOD REC, V34, P31, DOI 10.1145/1084805.1084812. Simmhan YL, 2006, LECT NOTES COMPUT SC, V4145, P222. Singh G, 2007, SCI PROGRAMMING-NETH, V15, P249, DOI 10.1155/2007/701609. Spafford KL, 2012, INT CONF HIGH PERFOR. Spark A, 2014, SPARK STREAMING PROG. Steuer R, 2002, BIOINFORMATICS, V18, pS231, DOI 10.1093/bioinformatics/18.suppl\_2.S231. Subedi P, 2018, P INT C HIGH PERF CO. Taylor I., 2007, WORKFLOWS E SCI, P320, DOI [DOI 10.1007/978-1-84628-757-2\_20, 10.1007/978-1-84628-757-2]. Tovar B, 2018, IEEE T PARALL DISTR, V29, P240, DOI 10.1109/TPDS.2017.2762310. Usman SA, 2015, ARXIV150802357ASTROP. Wang T, 2014, J SYST SOFTWARE, V89, P19, DOI 10.1016/j.jss.2013.03.060. Wang T, 2015, IEEE INT C CL COMP, P194, DOI 10.1109/CLUSTER.2015.38. Weiss N.A., 2012, INTRO STAT, V9th ed.. Weitzel D, 2017, P PRACT EXP ADV RES, P24. Wolstencroft K, 2013, NUCLEIC ACIDS RES, V41, pW557, DOI 10.1093/nar/gkt328. Zhang O. Q., 2011, Proceedings of the 2011 IEEE 3rd International Conference on Cloud Computing Technology and Science (CloudCom 2011), P446, DOI 10.1109/CloudCom.2011.66.},
  da = {2021-06-24},
  doc-delivery-number = {IZ4NL},
  eissn = {1741-2846},
  journal-iso = {Int. J. High Perform. Comput. Appl.},
  keywords-plus = {PERFORMANCE; DESIGN; SYSTEM; WEB},
  language = {English},
  number-of-cited-references = {91},
  oa = {Bronze},
  orcid-numbers = {Mandal, Anirban/0000-0001-5145-8618 Sakellariou, Rizos/0000-0002-6104-6649 Deelman, Ewa/0000-0001-5106-503X},
  research-areas = {Computer Science},
  researcherid-numbers = {Mandal, Anirban/AAE-3739-2020},
  times-cited = {3},
  unique-id = {ISI:000487060400007},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {18},
  web-of-science-categories = {Computer Science, Hardware \& Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods},
  keywords = {Scientific workflows; machine learning; workflow systems; anomaly detection; workflow composition},
  file = {/Users/awwillc/Zotero/storage/UWI48ITY/Deelman et al. - 2019 - The role of machine learning in scientific workflo.pdf}
}

@article{ISI:000523744600001,
  type = {Article},
  title = {Reproducible {{Software Environment}}: A Tool Enabling Computational Reproducibility in Geospace Sciences and Facilitating Collaboration},
  author = {Bhatt, Asti and Valentic, Todd and Reimer, Ashton and Lamarche, Leslie and Reyes, Pablo and Cosgrove, Russell},
  year = {2020},
  month = apr,
  journal = {JOURNAL OF SPACE WEATHER AND SPACE CLIMATE},
  volume = {10},
  publisher = {{EDP SCIENCES S A}},
  address = {{17, AVE DU HOGGAR, PA COURTABOEUF, BP 112, F-91944 LES ULIS CEDEX A, FRANCE}},
  issn = {2115-7251},
  doi = {10.1051/swsc/2020011},
  abstract = {The Reproducible Software Environment (Resen) is an open-source software tool enabling computationally reproducible scientific results in the geospace science community. Resen was developed as part of a larger project called the Integrated Geoscience Observatory (InGeO), which aims to help geospace researchers bring together diverse datasets from disparate instruments and data repositories, with software tools contributed by instrument providers and community members. The main goals of InGeO are to remove barriers in accessing, processing, and visualizing geospatially resolved data from multiple sources using methodologies and tools that are reproducible. The architecture of Resen combines two mainstream open source software tools, Docker and JupyterHub, to produce a software environment that not only facilitates computationally reproducible research results, but also facilitates effective collaboration among researchers. In this technical paper, we discuss some challenges for performing reproducible science and a potential solution via Resen, which is demonstrated using a case study of a geospace event. Finally we discuss how the usage of mainstream, open-source technologies seems to provide a sustainable path towards enabling reproducible science compared to proprietary and closed-source software.},
  affiliation = {Bhatt, A (Corresponding Author), SRI Int, Ctr Geospace Studies, 333 Ravenswood Ave, Menlo Pk, CA 94025 USA. Bhatt, Asti; Valentic, Todd; Reimer, Ashton; Lamarche, Leslie; Reyes, Pablo; Cosgrove, Russell, SRI Int, Ctr Geospace Studies, 333 Ravenswood Ave, Menlo Pk, CA 94025 USA.},
  article-number = {12},
  author-email = {asti.bhatt@sri.com},
  cited-references = {Baker M, 2016, NATURE, V533, P452, DOI 10.1038/533452a. EOSDIS N, 2018, NASA EARTH SCI DAT S. Integrated Geoscience Observatory Team, 2019, RES VERS 2019 1 ORC2. Integrated Geoscience Observatory Team, 2019, RES COR VERS 2019 1. Lyons LR, 2019, J GEOPHYS RES-SPACE, V124, P700, DOI 10.1029/2018JA025980. Makela J., 2015, DATA CEDAR MADRIGAL. Matsuo T, 2020, RECENT PROGR INVERSE, P219, DOI [10.1007/978-3-030-26732-2, DOI 10.1007/978-3-030-26732-2]. McGranaghan RM, 2017, J GEOPHYS RES-SPACE, V122, P12586, DOI 10.1002/2017JA024835. Met Office, 2010, CART CART PYTH LIBR. Morley S.K., 2011, P 9 PYTH SCI C SCIPY. National Academies of Sciences Engineering and Medicine, 2018, OP SOURC SOFTW POL O, DOI [10.17226/25217, DOI 10.17226/25217]. Neupane JB, 2019, ORG LETT, V21, P8449, DOI 10.1021/acs.orglett.9b03216. Project Jupyter, 2019, JUP LAB VERS 0 35 5. Rideout W., 2017, MADRIGALWEB VERSION. Shiokawa K, 2002, J GEOPHYS RES-SPACE, V107, DOI 10.1029/2001JA000245. Song Q, 2012, ANN GEOPHYS-GERMANY, V30, P683, DOI 10.5194/angeo-30-683-2012. Stall S., 2018, EOS, V99, DOI [10.1029/2018EO109301, DOI 10.1029/2018EO109301]. Stoneback R, 2019, PYSAT PYSAT V2 1 VER, DOI 10.5281/zenodo.3546270. Stoneback RA, 2018, J GEOPHYS RES-SPACE, V123, P5271, DOI 10.1029/2018JA025297. Super Dual Auroral Radar Network Software Team, 2018, DAT VIS TOOLK PYTH V. Teytelman L, 2018, NATURE, V560, P411, DOI 10.1038/d41586-018-06008-w.},
  da = {2021-06-23},
  doc-delivery-number = {LA1WG},
  funding-acknowledgement = {US National Science FoundationNational Science Foundation (NSF) [ICER-1541057, CSSI1835573]},
  funding-text = {This work was supported by the US National Science Foundation grants ICER-1541057 and CSSI1835573 to SRI International. The software and data used for the case study (Fig. 4) have been published on Zenodo, DOI: https://doi.org/10.5281/zenodo.3564835.The editor thanks two anonymous reviewers for their assistance in evaluating this paper.},
  journal-iso = {J. Space Weather Space Clim.},
  keywords-plus = {MAGNETIC STORM},
  language = {English},
  number-of-cited-references = {21},
  oa = {DOAJ Gold, Green Published},
  orcid-numbers = {Reimer, Ashton/0000-0002-4621-3453 Lamarche, Leslie/0000-0001-7098-0524 Valentic, Todd/0000-0002-1940-3040 Reyes, Pablo/0000-0002-8433-5072},
  research-areas = {Astronomy \& Astrophysics; Geochemistry \& Geophysics; Meteorology \& Atmospheric Sciences},
  times-cited = {0},
  unique-id = {ISI:000523744600001},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {2},
  web-of-science-categories = {Astronomy \& Astrophysics; Geochemistry \& Geophysics; Meteorology \& Atmospheric Sciences},
  keywords = {Geospace science; open source software; data collaboration; computational reproducibility},
  file = {/Users/awwillc/Zotero/storage/8CPTLBFU/Bhatt et al. - 2020 - Reproducible Software Environment a tool enabling.pdf}
}

@article{ISI:000537465000018,
  type = {Article},
  title = {Computational Reproducibility in the Wildlife Society's Flagship Journals},
  author = {Archmiller, Althea A. and Johnson, Andrew D. and Nolan, Jane and Edwards, Margaret and Elliott, Lisa H. and Ferguson, Jake M. and Iannarilli, Fabiola and Velez, Juliana and Vitense, Kelsey and Johnson, Douglas H. and Fieberg, John},
  year = {2020},
  month = jul,
  journal = {JOURNAL OF WILDLIFE MANAGEMENT},
  volume = {84},
  number = {5},
  pages = {1012--1017},
  publisher = {{WILEY}},
  address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
  issn = {0022-541X},
  doi = {10/gg66q7},
  abstract = {Scientific progress depends upon the accumulation of empirical knowledge via reproducible methodology. Although reproducibility is a main tenet of the scientific method, recent studies have highlighted widespread failures in adherence to this ideal. The goal of this study was to gauge the level of computational reproducibility, or the ability to obtain the same results using the same data and analytic methods as in the original publication, in the field of wildlife science. We randomly selected 80 papers published in the Journal of Wildlife Management and Wildlife Society Bulletin between 1 June 2016 and 1 June 2018. Of those that were suitable for reproducibility review (n = 74), we attempted to obtain study data from online repositories or directly from authors. Forty-two authors did not respond to our requests, and we were further unable to obtain data from authors of 13 other studies. Of the 19 studies for which we were able to obtain data and complete our analysis, we judged that 13 were mostly or fully reproducible. We conclude that the studies with publicly available data or data shared upon request were largely reproducible, but we remain concerned about the difficulty in obtaining data from recently published papers. We recommend increased data-sharing, data organization and documentation, communication, and training to advance computational reproducibility in the wildlife sciences. (c) 2020 The Authors. The Journal of Wildlife Management published by Wiley Periodicals, Inc. on behalf of The Wildlife Society.},
  affiliation = {Archmiller, AA (Corresponding Author), Concordia Coll, Biol Dept, 901 8th St S, Moorhead, MN 56562 USA. Archmiller, Althea A.; Johnson, Andrew D., Concordia Coll, Biol Dept, 901 8th St S, Moorhead, MN 56562 USA. Nolan, Jane, Concordia Coll, 901 8th St S, Moorhead, MN 56562 USA. Edwards, Margaret; Elliott, Lisa H.; Iannarilli, Fabiola; Velez, Juliana; Vitense, Kelsey; Johnson, Douglas H.; Fieberg, John, Univ Minnesota, Dept Fisheries Wildlife \& Conservat Biol, 2003 Upper Buford Circle,Suite 135, St Paul, MN 55108 USA. Ferguson, Jake M., Univ Hawaii Manoa, Dept Biol, 2538 McCarthy Mall, Honolulu, HI 96822 USA.},
  author-email = {althea.archmiller@gmail.com},
  da = {2021-01-10},
  doc-delivery-number = {LU0PD},
  eissn = {1937-2817},
  journal-iso = {J. Wildl. Manage.},
  keywords-plus = {ECOINFORMATICS},
  language = {English},
  number-of-cited-references = {32},
  oa = {Other Gold},
  orcid-numbers = {Velez, Juliana/0000-0003-0412-2761 Iannarilli, Fabiola/0000-0002-7018-3557 Nolan, Jane/0000-0001-7023-5217 Archer, Althea/0000-0003-1927-0783},
  research-areas = {Environmental Sciences \& Ecology; Zoology},
  researcherid-numbers = {Archer, Althea/AAV-9801-2020},
  times-cited = {1},
  unique-id = {ISI:000537465000018},
  usage-count-last-180-days = {2},
  usage-count-since-2013 = {3},
  web-of-science-categories = {Ecology; Zoology},
  keywords = {data sharing; meta-analysis; open science; reproducibility; research methods; statistical methods},
  file = {/Users/awwillc/Zotero/storage/2HYBZ9WY/Archmiller et al. - 2020 - Computational reproducibility in the wildlife soci.pdf}
}

@article{ISI:000537465000018,
  type = {Article},
  title = {Computational Reproducibility in the Wildlife Society's Flagship Journals},
  author = {Archmiller, Althea A. and Johnson, Andrew D. and Nolan, Jane and Edwards, Margaret and Elliott, Lisa H. and Ferguson, Jake M. and Iannarilli, Fabiola and Velez, Juliana and Vitense, Kelsey and Johnson, Douglas H. and Fieberg, John},
  year = {2020},
  month = jul,
  journal = {JOURNAL OF WILDLIFE MANAGEMENT},
  volume = {84},
  number = {5},
  pages = {1012--1017},
  publisher = {{WILEY}},
  address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
  issn = {0022-541X},
  doi = {10.1002/jwmg.21855},
  abstract = {Scientific progress depends upon the accumulation of empirical knowledge via reproducible methodology. Although reproducibility is a main tenet of the scientific method, recent studies have highlighted widespread failures in adherence to this ideal. The goal of this study was to gauge the level of computational reproducibility, or the ability to obtain the same results using the same data and analytic methods as in the original publication, in the field of wildlife science. We randomly selected 80 papers published in the Journal of Wildlife Management and Wildlife Society Bulletin between 1 June 2016 and 1 June 2018. Of those that were suitable for reproducibility review (n = 74), we attempted to obtain study data from online repositories or directly from authors. Forty-two authors did not respond to our requests, and we were further unable to obtain data from authors of 13 other studies. Of the 19 studies for which we were able to obtain data and complete our analysis, we judged that 13 were mostly or fully reproducible. We conclude that the studies with publicly available data or data shared upon request were largely reproducible, but we remain concerned about the difficulty in obtaining data from recently published papers. We recommend increased data-sharing, data organization and documentation, communication, and training to advance computational reproducibility in the wildlife sciences. (c) 2020 The Authors. The Journal of Wildlife Management published by Wiley Periodicals, Inc. on behalf of The Wildlife Society.},
  affiliation = {Archmiller, AA (Corresponding Author), Concordia Coll, Biol Dept, 901 8th St S, Moorhead, MN 56562 USA. Archmiller, Althea A.; Johnson, Andrew D., Concordia Coll, Biol Dept, 901 8th St S, Moorhead, MN 56562 USA. Nolan, Jane, Concordia Coll, 901 8th St S, Moorhead, MN 56562 USA. Edwards, Margaret; Elliott, Lisa H.; Iannarilli, Fabiola; Velez, Juliana; Vitense, Kelsey; Johnson, Douglas H.; Fieberg, John, Univ Minnesota, Dept Fisheries Wildlife \& Conservat Biol, 2003 Upper Buford Circle,Suite 135, St Paul, MN 55108 USA. Ferguson, Jake M., Univ Hawaii Manoa, Dept Biol, 2538 McCarthy Mall, Honolulu, HI 96822 USA.},
  author-email = {althea.archmiller@gmail.com},
  cited-references = {Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716. Agresti A, 1998, AM STAT, V52, P119, DOI 10.2307/2685469. Alsheikh-Ali AA, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024357. Alter G, 2018, AM PSYCHOL, V73, P146, DOI 10.1037/amp0000258. Baker M, 2016, NATURE, V533, P452, DOI 10.1038/533452a. Begley CG, 2012, NATURE, V483, P531, DOI 10.1038/483531a. British Ecological Society, 2017, GUID REPR COD EC EV. Camerer CF, 2016, SCIENCE, V351, P1433, DOI 10.1126/science.aaf0918. Carey MA, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005871. Cassey P, 2006, BIOSCIENCE, V56, P958, DOI 10.1641/0006-3568(2006)56[958:RARIE]2.0.CO;2. Dengler J, 2011, J VEG SCI, V22, P577, DOI 10.1111/j.1654-1103.2011.01313.x. Gilbert KJ, 2012, MOL ECOL, V21, P4925, DOI 10.1111/j.1365-294X.2012.05754.x. Johnson DH, 2002, J WILDLIFE MANAGE, V66, P919, DOI 10.2307/3802926. Krausman PR, 2018, J WILDLIFE MANAGE, V82, P1091, DOI 10.1002/jwmg.21496. Krausman PR, 2017, J WILDLIFE MANAGE, V81, P4, DOI 10.1002/jwmg.21177. Kroll A. J., 2014, WILDLIFE SOC A UNPUB. Lewis KP, 2018, WILDLIFE SOC B, V42, P172, DOI 10.1002/wsb.847. Lin J, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001975. Merrill E, 2015, J WILDLIFE MANAGE, V79, P1, DOI 10.1002/jwmg.819. Merrill E, 2014, J WILDLIFE MANAGE, V78, P381, DOI 10.1002/jwmg.699. Michener WK, 2012, TRENDS ECOL EVOL, V27, P85, DOI 10.1016/j.tree.2011.11.016. Nelson B, 2009, NATURE, V461, P160, DOI 10.1038/461160a. Perignon C, 2019, SCIENCE, V365, P127, DOI 10.1126/science.aaw2825. Piwowar HA, 2013, PEERJ, V1, DOI 10.7717/peerj.175. Sandve GK, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003285. Stokstad E, 2018, SCIENCE, V361, P1189, DOI 10.1126/science.361.6408.1189. Tenopir C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021101. Vandewalle P, 2012, COMPUT SCI ENG, V14, P42, DOI 10.1109/MCSE.2012.63. Vasilevsky NA, 2017, PEERJ, V5, DOI 10.7717/peerj.3208. Wang DP, 2018, EVOLUTION, V72, P961, DOI 10.1111/evo.13459. Whitlock MC, 2011, TRENDS ECOL EVOL, V26, P61, DOI 10.1016/j.tree.2010.11.006. Wilson EB, 1927, J AM STAT ASSOC, V22, P209, DOI 10.2307/2276774.},
  da = {2021-06-23},
  doc-delivery-number = {LU0PD},
  eissn = {1937-2817},
  journal-iso = {J. Wildl. Manage.},
  keywords-plus = {ECOINFORMATICS},
  language = {English},
  number-of-cited-references = {32},
  oa = {Other Gold},
  orcid-numbers = {Iannarilli, Fabiola/0000-0002-7018-3557 Archer, Althea/0000-0003-1927-0783 Velez, Juliana/0000-0003-0412-2761 Fieberg, John/0000-0002-3180-7021 Nolan, Jane/0000-0001-7023-5217},
  research-areas = {Environmental Sciences \& Ecology; Zoology},
  researcherid-numbers = {Iannarilli, Fabiola/AAG-7774-2021 Archer, Althea/AAV-9801-2020},
  times-cited = {4},
  unique-id = {ISI:000537465000018},
  usage-count-last-180-days = {2},
  usage-count-since-2013 = {5},
  web-of-science-categories = {Ecology; Zoology},
  keywords = {data sharing; meta-analysis; open science; reproducibility; research methods; statistical methods},
  file = {/Users/awwillc/Zotero/storage/4JXP5CNS/Archmiller et al. - 2020 - Computational reproducibility in the wildlife soci.pdf}
}

@article{ISI:000552601500009,
  type = {Article},
  title = {Assessing the Impact of Introductory Programming Workshops on the Computational Reproducibility of Biomedical Workflows},
  author = {Deardorff, Ariel},
  year = {2020},
  month = jul,
  journal = {PLOS ONE},
  volume = {15},
  number = {7},
  publisher = {{PUBLIC LIBRARY SCIENCE}},
  address = {{1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0230697},
  abstract = {Introduction As biomedical research becomes more data-intensive, computational reproducibility is a growing area of importance. Unfortunately, many biomedical researchers have not received formal computational training and often struggle to produce results that can be reproduced using the same data, code, and methods. Programming workshops can be a tool to teach new computational methods, but it is not always clear whether researchers are able to use their new skills to make their work more computationally reproducible. Methods This mixed methods study consisted of in-depth interviews with 14 biomedical researchers before and after participation in an introductory programming workshop. During the interviews, participants described their research workflows and responded to a quantitative checklist measuring reproducible behaviors. The interview data was analyzed using a thematic analysis approach, and the pre and post workshop checklist scores were compared to assess the impact of the workshop on the computational reproducibility of the researchers' workflows. Results Pre and post scores on a checklist of reproducible behaviors did not change in a statistically significant manner. The qualitative interviews revealed that several participants had made small changes to their workflows including switching to open source programming languages for their data cleaning, analysis, and visualization. Overall many of the participants indicated higher levels of programming literacy, and an interest in further training. Factors that enabled change included supportive environments and an immediate research need, while barriers included collaborators that were resistant to new tools, and a lack of time. Conclusion While none of the workshop participants completely changed their workflows, many of them did incorporate new practices, tools, or methods that helped make their work more reproducible and transparent to other researchers. This indicates that programming workshops now offered by libraries and other organizations contribute to computational reproducibility training for researchers.},
  affiliation = {Deardorff, A (Corresponding Author), Univ Calif San Francisco, UCSF Lib, San Francisco, CA 94143 USA. Deardorff, Ariel, Univ Calif San Francisco, UCSF Lib, San Francisco, CA 94143 USA.},
  article-number = {e0230697},
  author-email = {ariel.deardorff@ucsf.edu},
  cited-references = {Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716. Baker M, 2016, NATURE, V533, P452, DOI 10.1038/533452a. Deardorff A, 2020, J MED LIBR ASSOC, V108, P29, DOI 10.5195/jmla.2020.819. Denaxas S, 2017, BIODATA MIN, V10, DOI 10.1186/s13040-017-0151-7. Garijo D, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080278. Gorgolewski KJ, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002506. Guest G., 2012, APPL THEMATIC ANAL, DOI [10.4135/9781483384436.n4, DOI 10.4135/9781483384436, 10.4135/9781483384436.n4.]. Guest G, 2006, FIELD METHOD, V18, P59, DOI 10.1177/1525822X05279903. Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124. Jordan K., 2018, ZENODO, DOI [10.5281/zenodo.1402200, DOI 10.5281/ZENODO.1402200]. Jordan KL, 2020, ZENODO, DOI [10.5281/zenodo.3753528, DOI 10.5281/ZENODO.3753528]. Kitzes J., 2018, PRACTICE REPRODUCIBL. Lakens D, 2016, BMC PSYCHOL, V4, DOI [10.1186/s40359-016-0126-3 27241618, DOI 10.1186/S40359-016-0126-3 27241618]. Markowetz F, 2015, GENOME BIOL, V16, DOI 10.1186/s13059-015-0850-7. National Academies of Sciences E, 2019, REPRODUCIBILITY REPL, DOI [10.17226/25303 31596559, DOI 10.17226/25303 31596559]. Nosek BA, 2015, SCIENCE, V348, P1422, DOI 10.1126/science.aab2374. Samsa G, 2019, ACAD MED, V94, P47, DOI 10.1097/ACM.0000000000002351. Sandve GK, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003285. Stodden V., 2014, J OPEN RES STW, V2, P8, DOI [10.5334/jors.ay, DOI 10.5334/JORS.AY, DOI 10.5334/jors.ay]. Stodden V., 2010, 1550193 SOC SCI RES. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Wilson G, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001745.},
  da = {2021-06-23},
  doc-delivery-number = {MQ0QI},
  journal-iso = {PLoS One},
  language = {English},
  number-of-cited-references = {22},
  oa = {DOAJ Gold, Green Published},
  orcid-numbers = {Deardorff, Ariel/0000-0001-8930-6089},
  research-areas = {Science \& Technology - Other Topics},
  times-cited = {0},
  unique-id = {ISI:000552601500009},
  usage-count-last-180-days = {1},
  usage-count-since-2013 = {3},
  web-of-science-categories = {Multidisciplinary Sciences},
  file = {/Users/awwillc/Zotero/storage/CZ5W2E52/Deardorff - 2020 - Assessing the impact of introductory programming w.pdf}
}

@inproceedings{ISI:000555928200108,
  type = {Proceedings Paper},
  title = {Preparing Code and Data for Computational Reproducibility},
  booktitle = {2019 {{ACM}}/{{IEEE JOINT CONFERENCE ON DIGITAL LIBRARIES}} ({{JCDL}} 2019)},
  author = {Fei, Xu},
  editor = {{Bonn, M and Wu, D and Downie, SJ and Martaus, A}},
  year = {2019},
  series = {{{ACM}}-{{IEEE}} Joint Conference on Digital Libraries {{JCDL}}},
  pages = {449--450},
  publisher = {{IEEE}},
  address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
  issn = {2575-7865},
  doi = {10.1109/jcdl.2019.00114},
  affiliation = {Fei, X (Corresponding Author), Code Ocean, New York, NY 10036 USA. Fei, Xu, Code Ocean, New York, NY 10036 USA.},
  da = {2021-06-23},
  doc-delivery-number = {BP5KE},
  eissn = {2575-8152},
  isbn = {978-1-72811-547-4},
  language = {English},
  number-of-cited-references = {0},
  orcid-numbers = {Clyburne-Sherin, April/0000-0002-5401-7751},
  organization = {{IEEE Comp Soc; Assoc Comp Machinery; IEEE}},
  research-areas = {Computer Science; Information Science \& Library Science},
  times-cited = {0},
  unique-id = {ISI:000555928200108},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {0},
  web-of-science-categories = {Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory \& Methods; Information Science \& Library Science}
}

@article{ISI:000567826800017,
  type = {Article},
  title = {Curious {{Containers}}: {{A}} Framework for Computational Reproducibility in Life Sciences with Support for {{Deep Learning}} Applications},
  author = {Jansen, Christoph and Annuscheit, Jonas and Schilling, Bruno and Strohmenger, Klaus and Witt, Michael and Bartusch, Felix and Herta, Christian and Hufnagl, Peter and Krefting, Dagmar},
  year = {2020},
  month = nov,
  journal = {FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE},
  volume = {112},
  pages = {209--227},
  publisher = {{ELSEVIER}},
  address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
  issn = {0167-739X},
  doi = {10.1016/j.future.2020.05.007},
  abstract = {In clinical scenarios, there is an increasing interest in complex computational experiments, as for example the training of Deep Learning models. Reproducibility is an essential property of such experiments, especially if the result contributes to a patient's treatment. This paper introduces Curious Containers, a software framework for computational reproducibility that treats data, software and runtime environment as decentralized network resources. All experiment resources are described in a single file, using a new format that is compatible with a subset of the Common Workflow Language. Docker is used to deploy the experiment software in a container image, including arbitrary data transmission programs to connect with existing storage solutions. The framework supports Deep Learning applications, that have a high demand in storage and processing capabilities. Large datasets can be mounted inside containers via network filesystems like SSHFS based on the filesystem in user-space technology. The Nvidia-Container-Toolkit enables GPU usage. Curious Containers has been tested in two biomedical scenarios. The first use case is a Deep Learning application for tumor classification in images that requires a large dataset and a GPU. In this context, a prototypical integration of the framework with the existing Data Version Control system for exploratory Deep Learning modeling has been developed. The second use case extends an existing container image, including a scientific workflow for detection and comparison of human protein in mass spectrography data. The container image was originally developed for an archiving platform and could be extended to be compatible with both Curious Containers and cwltool, the Common Workflow Language reference implementation. The presented solution allows for consistent description and execution of computational experiments, while trying to be both flexible and interoperable with existing software and standards. Support for Deep Learning experiments is gaining importance as such systems are increasingly validated as medical decision support systems. (C) 2020 Elsevier B.V. All rights reserved.},
  affiliation = {Jansen, C (Corresponding Author), HTW Berlin Univ Appl Sci, Ctr Biomed Image \& Informat Proc, Berlin, Germany. Jansen, Christoph; Annuscheit, Jonas; Schilling, Bruno; Strohmenger, Klaus; Witt, Michael; Herta, Christian; Hufnagl, Peter; Krefting, Dagmar, HTW Berlin Univ Appl Sci, Ctr Biomed Image \& Informat Proc, Berlin, Germany. Jansen, Christoph; Strohmenger, Klaus; Hufnagl, Peter, Charite Univ Med Berlin, Inst Pathol, Berlin, Germany. Krefting, Dagmar, Univ Med Ctr Gottingen, Dept Med Informat, Gottingen, Germany. Bartusch, Felix, Univ Tubingen, High Performance \& Cloud Comp Grp, IT Ctr ZDV, Tubingen, Germany. Witt, Michael, Film Univ Babelsberg Konrad Wolf, Potsdam, Germany.},
  author-email = {Christoph.Jansen@charite.de Jonas.Annuscheit@htw-berlin.de Bruno.Schilling@student.htw-berlin.de Klaus.Strohmenger@htw-berlin.de m.witt@filmuniversitaet.de felix.bartusch@uni-tuebingen.de Christian.Herta@htw-berlin.de Peter.Hufnagl@htw-berlin.de Dagmar.Krefting@htw-berlin.de},
  cited-references = {Abadi M, 2015, TENSORFLOW LARGE SCA. Abdallah L, 2020, ALGORITHM MOL BIOL, V15, DOI 10.1186/s13015-020-0162-7. Aloisio G, 2002, FUTURE GENER COMP SY, V18, P1053, DOI 10.1016/S0167-739X(02)00084-5. Bandi P, 2018, IEEE T MED IMAGING. Bartusch F., 2019, 2019 19 IEEE ACM INT. Beaulieu-Jones BK, 2017, NAT BIOTECHNOL, V35, P342, DOI 10.1038/nbt.3780. Beier M, 2017, FUTURE GENER COMP SY, V67, P466, DOI 10.1016/j.future.2016.03.025. Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585. Berthold MR, 2008, STUD CLASS DATA ANAL, P319, DOI 10.1145/1656274.1656280. Chan HP, 2020, ADV EXP MED BIOL, V1213, P3, DOI 10.1007/978-3-030-33128-3\_1. Chan S, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20180416. Chollet F., 2015, KERAS GITHUB. Fillbrunn A, 2017, J BIOTECHNOL, V261, P149, DOI 10.1016/j.jbiotec.2017.07.028. Glatard T., 2015, FRONT NEUROSCI C ABS, V46, P17, DOI [10.3389/conf.fnins.2015.91.00012, DOI 10.3389/CONF.FNINS.2015.91.00012]. Gruning B, 2018, CELL SYST, V6, P631, DOI 10.1016/j.cels.2018.03.014. Gruening Bjorn, 2018, F1000Res, V7, DOI 10.12688/f1000research.15140.2. Hartig K., 2018, TECH REP. Herrick R, 2016, NEUROIMAGE, V124, P1093, DOI 10.1016/j.neuroimage.2015.06.076. Ianni JD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59985-2. Jansen C, 2017, COMPANION PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UTILITY AND CLOUD COMPUTING (UCC'17 COMPANION), P3, DOI 10.1145/3147234.3148104. Jansen C, 2019, IEEE ACM INT SYMP, P621, DOI 10.1109/CCGRID.2019.00080. Jansen C, 2016, LECT NOTES COMPUT SC, V9787, P303, DOI 10.1007/978-3-319-42108-7\_23. Jansen C, 2015, SCALABLE COMPUT-PRAC, V16, P85, DOI 10.12694/scpe.v16i1.1062. Jimenez G, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00145. Kenar E, 2014, MOL CELL PROTEOMICS, V13, P348, DOI 10.1074/mcp.M113.031278. Krefting D., 2011, HP MICCAI MICCAI DCI. Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386. Kurc T, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00027. Kurtzer GM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177459. Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791. Lin H, 2018, IEEE WINT CONF APPL, P539, DOI 10.1109/WACV.2018.00065. Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005. Lumley JA, 2020, SLAS DISCOV, V25, P950, DOI 10.1177/2472555220907091. Marcus DS, 2007, NEUROINFORMATICS, V5, P11, DOI 10.1385/NI:5:1:11. Martin A, 2018, COMPUT COMMUN, V122, P30, DOI 10.1016/j.comcom.2018.03.011. Mazanetz MP, 2020, CURR MED CHEM, V27, P6458, DOI 10.2174/0929867326666190409141016. Nagendran M, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m689. Niazi S, 2017, PROCEEDINGS OF FAST `17: 15TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P89. OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076. Prinz F, 2011, NAT REV DRUG DISCOV, V10, P712, DOI 10.1038/nrd3439-c1. Ricciardi C, 2020, COMPUT METH PROG BIO, V189, DOI 10.1016/j.cmpb.2020.105343. Sandve GK, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003285. Shvachko K., 2010, P 2010 IEEE 26 S MAS, P1, DOI DOI 10.1109/MSST.2010.5496972. Simko T., 2018, CERNIT2018003. Stodden V, 2012, COMPUT SCI ENG, V14, P11, DOI 10.1109/MCSE.2012.82. Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308. Tatman R., 2018, REPR MACH LEARN WORK. Vangoor BKR, 2017, PROCEEDINGS OF FAST `17: 15TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P59. Weisser H, 2013, J PROTEOME RES, V12, P1628, DOI 10.1021/pr300992u. Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18.},
  da = {2021-06-23},
  doc-delivery-number = {NM0WZ},
  eissn = {1872-7115},
  funding-acknowledgement = {German Federal Ministry of Education and ResearchFederal Ministry of Education \& Research (BMBF) [01IS17056, 13FH770IX6, 03FH0061X5]},
  funding-text = {This work is supported by the German Federal Ministry of Education and Research (project deep.TEACHING, grant number 01IS17056, project deep.HEALTH, grant number 13FH770IX6 and project BB-ITBoost, grant number 03FH0061X5).},
  journal-iso = {Futur. Gener. Comp. Syst.},
  keywords-plus = {KNIME},
  language = {English},
  number-of-cited-references = {50},
  research-areas = {Computer Science},
  times-cited = {1},
  unique-id = {ISI:000567826800017},
  usage-count-last-180-days = {2},
  usage-count-since-2013 = {17},
  web-of-science-categories = {Computer Science, Theory \& Methods},
  keywords = {Reproducibility; Deep Learning; Machine learning; Container; FAIR principles; Common Workflow Language}
}

@article{ISI:000589972402305,
  type = {Meeting Abstract},
  title = {Improving the Computational Reproducibility of Immunological Research},
  author = {Anderson, Brooke and Lyons, Michael and {Henao-Tamayo, I}, Marcela and Juarrero, Mercedes Gonzalez and Robertson, Gregory},
  year = {2020},
  month = may,
  journal = {JOURNAL OF IMMUNOLOGY},
  volume = {204},
  number = {1, S},
  publisher = {{AMER ASSOC IMMUNOLOGISTS}},
  address = {{9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA}},
  issn = {0022-1767},
  affiliation = {Anderson, Brooke; Lyons, Michael; Henao-Tamayo, Marcela, I; Juarrero, Mercedes Gonzalez; Robertson, Gregory, Colorado State Univ, Ft Collins, CO 80523 USA.},
  da = {2021-06-23},
  doc-delivery-number = {OS2CB},
  eissn = {1550-6606},
  journal-iso = {J. Immunol.},
  language = {English},
  meeting = {222.25},
  number-of-cited-references = {0},
  organization = {{Amer Assoc Immunologists}},
  research-areas = {Immunology},
  times-cited = {0},
  unique-id = {ISI:000589972402305},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {0},
  web-of-science-categories = {Immunology},
  keywords = {⛔ No DOI found}
}

@article{ISI:000606077000009,
  type = {Article},
  title = {Unifying Package Managers, Workflow Engines, and Containers: {{Computational}} Reproducibility with {{BioNix}}},
  author = {Bedo, Justin and Di Stefano, Leon and Papenfuss, Anthony T.},
  year = {2020},
  month = nov,
  journal = {GIGASCIENCE},
  volume = {9},
  number = {11},
  publisher = {{OXFORD UNIV PRESS}},
  address = {{GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND}},
  issn = {2047-217X},
  doi = {10.1093/gigascience/giaa121},
  abstract = {Motivation: A challenge for computational biologists is to make our analyses reproducible-i.e. to rerun, combine, and share, with the assurance that equivalent runs will generate identical results. Current best practice aims at this using a combination of package managers, workflow engines, and containers. Results: We present BioNix, a lightweight library built on the Nix deployment system. BioNix manages software dependencies, computational environments, and workflow stages together using a single abstraction: pure functions. This lets users specify workflows in a clean, uniform way, with strong reproducibility guarantees. Availability and Implementation: BioNix is implemented in the Nix expression language and is released on GitHub under the 3-clause BSD license: https://github.com/PapenfussLab/bionix (biotools:BioNix) (BioNix, RRID:SCR 017662).},
  affiliation = {Bedo, J (Corresponding Author), Walter \& Eliza Hall Inst Med Res, Bioinformat Div, 1G Royal Pde, Parkville, Vic 3052, Australia. Bedo, Justin; Di Stefano, Leon; Papenfuss, Anthony T., Walter \& Eliza Hall Inst Med Res, Bioinformat Div, 1G Royal Pde, Parkville, Vic 3052, Australia. Bedo, Justin, Univ Melbourne, Sch Comp \& Informat Syst, Melbourne, Vic 3010, Australia. Papenfuss, Anthony T., Peter MacCallum Canc Ctr, 305 Grattan St, Melbourne, Vic 3000, Australia. Papenfuss, Anthony T., Univ Melbourne, Dept Med Biol, Melbourne, Vic 3010, Australia. Papenfuss, Anthony T., Univ Melbourne, Sir Peter MacCallum Dept Oncol, Melbourne, Vic 3010, Australia. Papenfuss, Anthony T., Univ Melbourne, Sch Math \& Stat, Melbourne, Vic 3010, Australia. Di Stefano, Leon, Johns Hopkins Univ, Bloomberg Sch Publ Hlth, Dept Biostat, 615 N Wolfe St, Baltimore, MD USA.},
  article-number = {giaa121},
  author-email = {cu@cau0.org},
  cited-references = {Afgan E, 2018, NUCLEIC ACIDS RES, V46, pW537, DOI 10.1093/nar/gky379. Andrews S., 2010, FASTQC. [Anonymous], 2016, NATURE, V533, P437, DOI 10.1038/533437a. [Anonymous], 2018, PACKAGE DEPENDENCY E. [Anonymous], 2018, How to stop data centres from gobbling up the world's electricity.. [Anonymous], 2019, TORQUE RESOURCE MANA. [Anonymous], 2019, REUSABLE REPROD COMP. [Anonymous], 2019, WORKFLOW DESCRIPTION. [Anonymous], 2019, AHASKELL RE IMPLEMEN. [Anonymous], 2018, SINGULARITY. [Anonymous], 2018, ENTERPRISE CONTAINER. [Anonymous], 2019, NEXTFLOW BASIC PIPEL. [Anonymous], SPEC CONT YOUR WORKL. Archibald B., 2017, REPROD ENV NIX SOFTW. Bedo J, 2019, PEERJ, V7, DOI 10.7717/peerj.7223. Bochynska AI, 2017, J MATER SCI-MATER M, V28, DOI 10.1007/s10856-016-5790-6. Bouttier PA, 2018, NIXCON. Brandt J, 2015, P WORKSH EDBT ICDT B, DOI [10.13140/RG.2.1.3547.6561, DOI 10.13140/RG.2.1.3547.6561]. Brandt J, 2017, J FUNCT PROGRAM, V27, DOI 10.1017/S0956796817000119. Bzeznik B, 2017, P 4 INT WORKSH HPC U, DOI [10.1145/3152493.3152556, DOI 10.1145/3152493.3152556]. Cameron DL, 2017, GENOME RES, V27, P2050, DOI 10.1101/gr.222109.117. Cameron DL, 2020, BIORXIV, DOI [10.1101/781013., DOI 10.1101/781013]. Crouch S, 2013, COMPUT SCI ENG, V15, P74, DOI 10.1109/MCSE.2013.133. Di Tommaso P, 2017, NAT BIOTECHNOL, V35, P316, DOI 10.1038/nbt.3820. Dolstra E, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE EIGHTEENTH LARGE INSTALLATION SYSTEM ADMINISTRATION CONFERENCE, P79. Dolstra E., 2006, THESIS. Dolstra E, 2010, J FUNCT PROGRAM, V20, P577, DOI 10.1017/S0956796810000195. Dubus G., 2018, MIX NIX DATA PIPELIN. Goodstadt L, 2010, BIOINFORMATICS, V26, P2778, DOI 10.1093/bioinformatics/btq524. Gruning B, 2018, NAT METHODS, V15, P475, DOI 10.1038/s41592-018-0046-7. Gruning B, 2018, CELL SYST, V6, P631, DOI 10.1016/j.cels.2018.03.014. Kim S, 2018, NAT METHODS, V15, P591, DOI 10.1038/s41592-018-0051-x. Koster J, 2012, BIOINFORMATICS, V28, P2520, DOI 10.1093/bioinformatics/bts480. Lampa S, 2019, GIGASCIENCE, V8, DOI 10.1093/gigascience/giz044. Leipzig J, 2017, BRIEF BIOINFORM, V18, P530, DOI 10.1093/bib/bbw020. LI H, 2013, 13033997 ARXIV, V1303, P3997, DOI DOI 10.1093/BI0INF0RMATICS/BTP352. Li H, 2018, BIOINFORMATICS, V34, P3094, DOI 10.1093/bioinformatics/bty191. Li H, 2009, BIOINFORMATICS, V25, P1754, DOI 10.1093/bioinformatics/btp324. Pope B., 2020, COMPUTATIONAL DATA A. Rimmer A, 2014, NAT GENET, V46, P912, DOI 10.1038/ng.3036. Talevich E, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004873. Vieira B., 2017, TRULY REPROD SCI PAP. Vivian J, 2017, NAT BIOTECHNOL, V35, P314, DOI 10.1038/nbt.3772. Wurmus R., 2019, GWL GNU WORKFLOW LAN. Wurmus R, 2018, GIGASCIENCE, V7, DOI 10.1093/gigascience/giy123.},
  da = {2021-06-23},
  doc-delivery-number = {PP7ZU},
  funding-acknowledgement = {Lorenzo and Pamela Galli Charitable Trust; Australian National Health and Medical Research Council (NHMRC)National Health and Medical Research Council of Australia [1054618]; NHMRCNational Health and Medical Research Council of Australia [1116955]; Victorian State Government Operational Infrastructure Support; Australian Government NHMRC Independent Research Institute Infrastructure SupportNational Health and Medical Research Council of Australia; Stafford Fox Medical Research Foundation},
  funding-text = {A.T.P. was supported by the Lorenzo and Pamela Galli Charitable Trust and by an Australian National Health and Medical Research Council (NHMRC) Program Grant (1054618) and NHMRC Senior Research Fellowship (1116955). The research benefitted by support from the Victorian State Government Operational Infrastructure Support and Australian Government NHMRC Independent Research Institute Infrastructure Support. J.B. was supported by the Stafford Fox Medical Research Foundation.},
  journal-iso = {GigaScience},
  language = {English},
  number-of-cited-references = {45},
  oa = {DOAJ Gold, Green Published},
  orcid-numbers = {Papenfuss, Anthony T/0000-0002-1102-8506 Bedo, Justin/0000-0001-5704-0212},
  research-areas = {Life Sciences \& Biomedicine - Other Topics; Science \& Technology - Other Topics},
  researcherid-numbers = {Papenfuss, Anthony T/C-6297-2008},
  times-cited = {0},
  unique-id = {ISI:000606077000009},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {0},
  web-of-science-categories = {Biology; Multidisciplinary Sciences},
  file = {/Users/awwillc/Zotero/storage/R837F2YB/Bedo et al. - 2020 - Unifying package managers, workflow engines, and c.pdf}
}

@article{ISI:000638003500011,
  type = {Article},
  title = {Containers and Orchestration of Numerical Ocean Model for Computational Reproducibility and Portability in Public and Private Clouds: {{Application}} of {{ROMS}} 3.6},
  author = {Jung, Kwangwoog and Cho, Yang-Ki and Tak, Yong-Jin},
  year = {2021},
  month = may,
  journal = {SIMULATION MODELLING PRACTICE AND THEORY},
  volume = {109},
  publisher = {{ELSEVIER}},
  address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
  issn = {1569-190X},
  doi = {10.1016/j.simpat.2021.102305},
  abstract = {Various numerical models have been used to understand and predict ocean dynamics. For this reason, many information technology (IT) resources are required for high-resolution global ocean modeling. The development of cloud-computing technologies has enabled earth scientists to easily use numerical ocean models that require high-performance computing (HPC) and messagepassing interface (MPI) software in private and public clouds. Although it is easier today to use computing resources than it was in the past, computational reproducibility and portability in diverse IT environments remain crucial issues. This study proposes a model execution architecture for computational reproducibility, portability, and agility based on container-based virtualization and orchestration technologies. We implement a containerized regional ocean-modeling system (ROMS), an MPI-based numerical ocean model that exists in various public or private cloud environments (e.g., personal computers and multiple-node servers). The preparation time for model setup is greatly reduced using our container-based HPC architecture. Containerization of ROMS is tested for its support of the portability of numerical modeling in a wide range of public-cloud environments. When leveraging an abstraction layer of complex and diverse infrastructure environments, we can run the ocean model more easily while obtaining computational reproducibility using a shareable deployment code. This advancement can be used to guide the containerization of various numerical models and to run them in parallel in public and private cloud-computing environments.},
  affiliation = {Cho, YK (Corresponding Author), Seoul Natl Univ, Sch Earth \& Environm Sci, Seoul, South Korea. Cho, YK (Corresponding Author), Seoul Natl Univ, Sch Earth \& Environm Sci, Res Inst Oceanog, Seoul, South Korea. Jung, Kwangwoog; Cho, Yang-Ki, Seoul Natl Univ, Sch Earth \& Environm Sci, Seoul, South Korea. Cho, Yang-Ki, Seoul Natl Univ, Sch Earth \& Environm Sci, Res Inst Oceanog, Seoul, South Korea. Tak, Yong-Jin, Yonsei Univ, Inst Earth Atmosphere Astron, 50 Yonsei Ro, Seoul, South Korea.},
  article-number = {102305},
  author-email = {choyk@snu.ac.kr},
  cited-references = {Amante C., 2009, NOAA TECH MEM NESDIS, DOI [DOI 10.7289/V5C8276M, 10.7289/V5C8276M]. Antonov J.I., 2010, NOAA ATLAS NESDIS, V69, P184. Beltre A, 2019, PROCEEDINGS OF CANOPIE-HPC 2019:2019 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON CONTAINERS AND NEW ORCHESTRATION PARADIGMS FOR ISOLATED ENVIRONMENTS IN HPC (CANOPIE-HPC), P11, DOI 10.1109/CANOPIE-HPC49598.2019.00007. Blackport R, 2018, J CLIMATE, V31, P9193, DOI 10.1175/JCLI-D-18-0192.1. Carton JA, 2008, MON WEATHER REV, V136, P2999, DOI 10.1175/2007MWR1978.1. CHAPMAN DC, 1985, J PHYS OCEANOGR, V15, P1060, DOI 10.1175/1520-0485(1985)015\textexclamdown 1060:NTOCSO\textquestiondown 2.0.CO;2. Chen XH, 2017, COMPUT GEOSCI-UK, V98, P21, DOI 10.1016/j.cageo.2016.09.014. Dee DP, 2011, Q J ROY METEOR SOC, V137, P553, DOI 10.1002/qj.828. Egbert GD, 2002, J ATMOS OCEAN TECH, V19, P183, DOI 10.1175/1520-0426(2002)019\textexclamdown 0183:EIMOBO\textquestiondown 2.0.CO;2. Fairall CW, 1996, J GEOPHYS RES-OCEANS, V101, P3747, DOI 10.1029/95JC03205. Flather R. A., 1976, Memoires de la Societe Royal des Sciences de Liege. Collection in-8, V10, P141. Gruning B, 2018, CELL SYST, V6, P631, DOI 10.1016/j.cels.2018.03.014. Konkol M, 2019, INT J GEOGR INF SCI, V33, P408, DOI 10.1080/13658816.2018.1508687. LARGE WG, 1994, REV GEOPHYS, V32, P363, DOI 10.1029/94RG01872. Locarnini R. A., 2010, WORLD OCEAN ATLAS 20, V1, P184. Luksa M., 2018, KUBERNETES ACTION. McCalpin J.D., 2017, STREAM SUSTAINABLE M. Montes D, 2017, GEOSCI MODEL DEV, V10, P811, DOI 10.5194/gmd-10-811-2017. Nust D., 2017, OPENING PUBLICATION. OCIOpen, 2020, CONT IN. Sande Veiga Victor, 2019, 2019 IEEE/ACM International Workshop on Containers and New Orchestration Paradigms for Isolated Environments in HPC (CANOPIE-HPC), P1, DOI 10.1109/CANOPIE-HPC49598.2019.00006. Seo GH, 2014, J GEOPHYS RES-OCEANS, V119, P3497, DOI 10.1002/2013JC009646. Shah J, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P184, DOI 10.1109/CCWC.2019.8666479. Shchepetkin AF, 2005, OCEAN MODEL, V9, P347, DOI 10.1016/j.ocemod.2004.08.002. Signell RP, 2019, J MAR SCI ENG, V7, DOI 10.3390/jmse7040110. Sultan S, 2019, IEEE ACCESS, V7, P52976, DOI 10.1109/ACCESS.2019.2911732. Vance TC, 2019, FRONT MAR SCI, V6, DOI 10.3389/fmars.2019.00211. Vorosmarty C., 1996, CONTRIBUTION IHP V T, V1. Wang Q, 2008, J GEOPHYS RES-OCEANS, V113, DOI 10.1029/2007JC004555. Zhuang JW, 2020, J ADV MODEL EARTH SY, V12, DOI 10.1029/2020MS002064.},
  da = {2021-06-23},
  doc-delivery-number = {RK0NZ},
  eissn = {1878-1462},
  funding-acknowledgement = {Basic Science Research Program through the National Research Foundation (NRF) of Korea - Ministry of Science and ICT [2017R1E1A1A03070224]; Ministry of Oceans and Fisheries, Korea},
  funding-text = {This research was supported by the Basic Science Research Program through the National Research Foundation (NRF) of Korea funded by the Ministry of Science and ICT (2017R1E1A1A03070224) and a part of the ``Long-term change of structure and function in marine ecosystems of Korea'' project funded by the Ministry of Oceans and Fisheries, Korea.},
  journal-iso = {Simul. Model. Pract. Theory},
  language = {English},
  number-of-cited-references = {30},
  research-areas = {Computer Science},
  times-cited = {0},
  unique-id = {ISI:000638003500011},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {0},
  web-of-science-categories = {Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering},
  keywords = {Numerical ocean model; Computational reproducibility; High-performance computing; Cloud computing; Infra abstraction; Containerization; Docker; Regional Ocean-modeling System; Kubernetes; Public and Private Cloud}
}

@article{ISI:000641472100002,
  type = {Article},
  title = {Epistemic Issues in Computational Reproducibility: Software as the Elephant in the Room},
  author = {Hocquet, Alexandre and Wieber, Frederic},
  year = {2021},
  month = jun,
  journal = {EUROPEAN JOURNAL FOR PHILOSOPHY OF SCIENCE},
  volume = {11},
  number = {2},
  publisher = {{SPRINGER}},
  address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
  issn = {1879-4912},
  doi = {10.1007/s13194-021-00362-9},
  abstract = {Computational reproducibility (i.e. issues of reproducibility stemming from the computer as a scientific tool) possesses its own dynamics and narratives of crisis. Alongside the difficulties of computing as an ubiquitous yet complex scientific activity, computational reproducibility suffers from a naive expectancy of total reproducibility and a moral imperative to embrace the principles of free software as a non-negotiable epistemic virtue. We argue that the epistemic issues at stake in actual practices of computational reproducibility are best unveiled by focusing on software as a pivotal concept, one that is surprisingly often overlooked in accounts of reproducibility issues. Software is not only about designing and coding but also about maintaining, supporting, distributing, licensing, and governance; it is not only about developers but also about users. We focus on openness debates among computational chemists involved in molecular modeling software packages as empirical grounding for our argument. We then identify and analyse four epistemic characteristics (transparency, consistency, sustainability and inclusivity) as key to the role of software in computational reproducibility.},
  affiliation = {Hocquet, A (Corresponding Author), CNRS, UMR 7117, Arch Poincare, 91 Ave Liberat, F-54001 Nancy, France. Hocquet, A (Corresponding Author), Univ Lorraine, 91 Ave Liberat, F-54001 Nancy, France. Hocquet, Alexandre; Wieber, Frederic, CNRS, UMR 7117, Arch Poincare, 91 Ave Liberat, F-54001 Nancy, France. Hocquet, Alexandre; Wieber, Frederic, Univ Lorraine, 91 Ave Liberat, F-54001 Nancy, France.},
  article-number = {38},
  author-email = {alexandre.hocquet@univ-lorraine.fr},
  cited-references = {AlNoamany Y, 2018, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.163. Atmanspacher H., 2016, REPRODUCIBILITY PRIN, DOI [10.1002/9781118865064, DOI 10.1002/9781118865064]. Baker M, 2016, NATURE, V533, P452, DOI 10.1038/533452a. Benureau FCY, 2018, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00069. Chue Hong, 2015, SOFTWARE SUSTAINABIL. Ensmenger NL., 2010, COMPUTER BOYS TAKE C, DOI [10.7551/mitpress/9780262050937.001.0001, DOI 10.7551/MITPRESS/9780262050937.001.0001]. Geiger S., 2019, 4S ANN M. Gelfert Axel., 2011, MODELS SIMULATIONS R, P145. Gezelter JD, 2015, J PHYS CHEM LETT, V6, P1168, DOI 10.1021/acs.jpclett.5b00285. Hatton L, 2019, IEEE SOFTWARE, V36, P137, DOI 10.1109/MS.2018.2883805. Hey T, 2015, NAT PHYS, V11, P367, DOI 10.1038/nphys3313. Hinsen K, 2019, NATURE, V574, P634, DOI 10.1038/d41586-019-03296-8. Hinsen Konrad, 2014, F1000Res, V3, P101, DOI 10.12688/f1000research.3978.1. Hocquet A, 2017, IEEE ANN HIST COMPUT, V39, P40, DOI 10.1109/MAHC.2018.1221048. Horner J., 2014, PHILOS TECHNOLOGY, V27, P491, DOI [10.1007/s13347-014-0172-9, DOI 10.1007/S13347-014-0172-9]. Humphreys P., 2004, EXTENDING OURSELVES, DOI [10.1093/0195158709.001.0001, DOI 10.1093/0195158709.001.0001]. Jacob CR, 2016, J PHYS CHEM LETT, V7, P351, DOI 10.1021/acs.jpclett.5b02609. Kelty C, 2008, 2 BITS CULTURAL SIGN, DOI [10.1215/9780822389002, DOI 10.1215/9780822389002]. Krylov AI, 2015, J PHYS CHEM LETT, V6, P2751, DOI 10.1021/acs.jpclett.5b01258. Le Onelli S, 2018, RES HIST ECON THOUGH, V36, P129, DOI 10.1108/S0743-41542018000036B009. Lejaeghere K, 2016, SCIENCE, V351, DOI 10.1126/science.aad3000. Lenhard J, 2019, MIND MACH, V29, P19, DOI 10.1007/s11023-019-09492-9. Mahoney MS, 2008, IEEE ANN HIST COMPUT, V30, P8, DOI 10.1109/MAHC.2008.55. Miletic V, 2015, WHAT IS PRICE OPEN S. Neupane JB, 2019, ORG LETT, V21, P8449, DOI 10.1021/acs.orglett.9b03216. Peng RD, 2011, SCIENCE, V334, P1226, DOI 10.1126/science.1213847. Reinhardt C., 2001, CHEM SCI 20 CENTURY. Reinhardt C, 2006, ISIS, V97, P205, DOI 10.1086/504732. Schappals M, 2017, J CHEM THEORY COMPUT, V13, P4270, DOI 10.1021/acs.jctc.7b00489. Spencer Matt, 2015, Perspectives on Science, V23, P466, DOI 10.1162/POSC\_a\_00184. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Symons J, 2019, MIND MACH, V29, P37, DOI 10.1007/s11023-018-9487-0. Wieber Frederic, 2020, Perspectives on Science, V28, P610, DOI 10.1162/posc\_a\_00352. Winsberg E., 2010, SCI AGE COMPUTER SIM, DOI [10.7208/chicago/9780226902050.001.0001, DOI 10.7208/CHICAGO/9780226902050.001.0001]. Winsberg E, 2019, STANFORD ENCY PHILOS.},
  da = {2021-06-23},
  doc-delivery-number = {RP1CB},
  eissn = {1879-4920},
  funding-acknowledgement = {Science History Institute (Philadelphia); MSH Lorraine, France},
  funding-text = {The authors gratefully acknowledge the Science History Institute (Philadelphia) for a fellowship during which some of this research had been pursued. This research project is being supported by a grant from the MSH Lorraine, France.},
  journal-iso = {Eur. J. Philos. Sci.},
  keywords-plus = {SCIENCE; MODELS},
  language = {English},
  number-of-cited-references = {35},
  orcid-numbers = {Hocquet, Alexandre/0000-0001-6361-5780},
  research-areas = {History \& Philosophy of Science},
  researcherid-numbers = {Hocquet, Alexandre/G-1940-2013},
  times-cited = {0},
  unique-id = {ISI:000641472100002},
  usage-count-last-180-days = {4},
  usage-count-since-2013 = {4},
  web-of-science-categories = {History \& Philosophy Of Science},
  keywords = {Computational reproducibility; Software; Computational chemistry; Transparency; Consistency; Sustainability; Inclusivity}
}

@article{ISI:000654021000012,
  type = {Article},
  title = {Computational {{Reproducibility}} of {{Named Entity Recognition}} Methods in the Biomedical Domain},
  author = {{Garcia-Serrano}, Ana and Hennig, Sebastian and Nuernberger, Andreas},
  year = {2021},
  month = mar,
  journal = {PROCESAMIENTO DEL LENGUAJE NATURAL},
  number = {66},
  pages = {141--152},
  publisher = {{SOC ESPANOLA PROCESAMIENTO LENGUAJE NATURAL-SEPLN}},
  address = {{DEPT LENGUAJES \& SISTEMAS INFORMATICOS, UNIV ALICANTE, APDO 99, ALICANTE, 03080, SPAIN}},
  issn = {1135-5948},
  doi = {10.26342/2021-66-12},
  abstract = {Unsupervised Named Entity Recognition (NER) approaches do not depend on labelled data to function properly but rather on a source of knowledge, in which promising candidates can be looked up to find the corresponding concept. In the biomedical domain knowledge source like this already exists; namely the Unified Medical Language System (UMLS). In this paper, three different unsupervised NER models using UMLS, namely MetaMap, cTakes and MetaMapLite are evaluated and compared from the results published by Demner-Fushman, Rogers and Aronson (2017) and Reategui and Ratte (2018). The Unsupervised Biomedical Named Entity Recognition framework (UB-NER) is developed, with which the results of the experiments of the three models, five datasets and two NER tasks are presented.},
  affiliation = {Garcia-Serrano, A (Corresponding Author), ETSI Informat UNED, Madrid, Spain. Garcia-Serrano, Ana, ETSI Informat UNED, Madrid, Spain. Hennig, Sebastian; Nuernberger, Andreas, Comp Sci Dept OVGU, Magdeburg, Germany.},
  author-email = {agarcia@lsi.uned.es sebastian.hennig@st.ovgu.de andreas.nuernberger@ovgu.de},
  cited-references = {Aronson AR, 2001, J AM MED INFORM ASSN, P17. Bhasuran B, 2016, J BIOMED INFORM, V64, P1, DOI 10.1016/j.jbi.2016.09.009. Campos D, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-54. Cho M, 2020, J BIOMED INFORM, V103, DOI 10.1016/j.jbi.2020.103381. Demner-Fushman D, 2017, J AM MED INFORM ASSN, V24, P841, DOI 10.1093/jamia/ocw177. Devlin J, 2018, BERT PRETRAINING DEE. Dogan RI, 2014, J BIOMED INFORM, V47, P1, DOI 10.1016/j.jbi.2013.12.006. Gang Y, 2020, J BIOMED INFORM, V108. Garcia-Serrano A, 2010, EXPERIENCES IMAGECLE, V1176. Hennig S, 2020, EXPT SURVEY NAMED EN. Hennig S, 2020, UNED e-cienciaDatos, VV1, DOI 10.21950/DYAZRE. Lample G, 2016, P 2016 C N AM CHAPT, P260, DOI [10.18653/v1/N16-1030, DOI 10.18653/V1/N16-1030]. Lara-Clares A., 2019, LSI2 UNED EHEALTH KD, V2421. Lastra-Diaz JJ, 2015, ENG APPL ARTIF INTEL, V46, P140, DOI 10.1016/j.engappai.2015.09.006. Lastra-Diaz JJ, 2015, KNOWL-BASED SYST, V89, P509, DOI 10.1016/j.knosys.2015.08.019. Lee JB, 2020, AM J SPEECH-LANG PAT, V29, P393, DOI [10.1093/bioinformatics/btz682, 10.1044/2019\_AJSLP-CAC48-18-0220]. Merkel D, 2014, DOCKER LIGHTWEIGHT L, DOI [10.5555/ 2600239.2600241, DOI 10.5555/2600239.2600241]. Mowery D., 2013, SHARECLEF EHEALTH EV, DOI [10.13026/0zgk-9j94, DOI 10.13026/0ZGK-9J94]. Reategui R, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0654-2. Sagae K., 2007, P EMNLP CONLL, P1044. Savova GK, 2010, J AM MED INFORM ASSN, V17, P507, DOI 10.1136/jamia.2009.001560. Segura-Bedmar I, 2017, J BIOMED SEMANT, V8, DOI 10.1186/s13326-017-0156-7. Uzuner O, 2009, J AM MED INFORM ASSN, V16, P561, DOI 10.1197/jamia.M3115.},
  da = {2021-06-23},
  doc-delivery-number = {SH3FM},
  eissn = {1989-7553},
  journal-iso = {Proces. Leng. Nat.},
  keywords-plus = {EXTRACTION; METAMAP; CTAKES; FAMILY},
  language = {English},
  number-of-cited-references = {23},
  research-areas = {Linguistics},
  times-cited = {0},
  unique-id = {ISI:000654021000012},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {0},
  web-of-science-categories = {Linguistics},
  keywords = {⚠️ Invalid DOI,Named Entity Recognition (NER); Biomedical; supervised and unsupervised models; Unified Medical Language System}
}

@article{ivieReproducibilityScientificComputing2018,
  title = {Reproducibility in {{Scientific Computing}}},
  author = {Ivie, Peter and Thain, Douglas},
  year = {2018},
  month = jul,
  journal = {ACM COMPUTING SURVEYS},
  volume = {51},
  number = {3},
  issn = {03600300},
  doi = {10/ggcqvn},
  keywords = {computational science,replicability,Reproducibility,reproducible,scientific computing,scientific workflow,scientific workflows,workflow,workflows},
  file = {/Users/awwillc/Zotero/storage/TSGP9WIH/Ivie and Thain - 2018 - Reproducibility in Scientific Computing.pdf}
}

@inproceedings{j.e.hannayHowScientistsDevelop2009,
  title = {How Do Scientists Develop and Use Scientific Software?},
  booktitle = {2009 {{ICSE Workshop}} on {{Software Engineering}} for {{Computational Science}} and {{Engineering}}},
  author = {{J. E. Hannay} and {C. MacLeod} and {J. Singer} and {H. P. Langtangen} and {D. Pfahl} and {G. Wilson}},
  year = {2009},
  month = may,
  pages = {1--8},
  doi = {10/bw966x},
  abstract = {New knowledge in science and engineering relies increasingly on results produced by scientific software. Therefore, knowing how scientists develop and use software in their research is critical to assessing the necessity for improving current development practices and to making decisions about the future allocation of resources. To that end, this paper presents the results of a survey conducted online in October-December 2008 which received almost 2000 responses. Our main conclusions are that (1) the knowledge required to develop and use scientific software is primarily acquired from peers and through self-study, rather than from formal education and training; (2) the number of scientists using supercomputers is small compared to the number using desktop or intermediate computers; (3) most scientists rely primarily on software with a large user base; (4) while many scientists believe that software testing is important, a smaller number believe they have sufficient understanding about testing concepts; and (5) that there is a tendency for scientists to rank standard software engineering concepts higher if they work in large software development projects and teams, but that there is no uniform trend of association between rank of importance of software engineering concepts and project/team size.},
  keywords = {Automatic testing,Computer science education,Knowledge engineering,Peer to peer computing,Resource management,scientific information systems,scientific software,software development projects,software engineering,Software engineering,Software standards,software testing,Software testing,Standards development,supercomputers,Supercomputers},
  file = {/Users/awwillc/Zotero/storage/P7UXHBC8/J. E. Hannay et al. - 2009 - How do scientists develop and use scientific softw.pdf}
}

@article{jabbariBenefitsDependencyNetwork2018,
  title = {Towards a Benefits Dependency Network for {{DevOps}} Based on a Systematic Literature Review.},
  author = {Jabbari, Ramtin and Ali, Nauman and Petersen, Kai and Tanveer, Binish},
  year = {2018},
  month = nov,
  journal = {Journal of Software: Evolution \& Process},
  volume = {30},
  number = {11},
  pages = {N.PAG},
  issn = {20477473},
  doi = {10/gd8vj5},
  abstract = {DevOps as a new way of thinking for software development and operations has received much attention in the industry, while it has not been thoroughly investigated in academia yet. The objective of this study is to characterize DevOps by exploring its central components in terms of principles, practices and their relations to the principles, challenges of DevOps adoption, and benefits reported in the peer-reviewed literature. As a key objective, we also aim to realize the relations between DevOps practices and benefits in a systematic manner. A systematic literature review was conducted. Also, we used the concept of benefits dependency network to synthesize the findings, in particular, to specify dependencies between DevOps practices and link the practices to benefits. We found that in many cases, DevOps characteristics, ie, principles, practices, benefits, and challenges, were not sufficiently defined in detail in the peer-reviewed literature. In addition, only a few empirical studies are available, which can be attributed to the nascency of DevOps research. Also, an initial version of the DevOps benefits dependency network has been derived. The definition of DevOps principles and practices should be emphasized given the novelty of the concept. Further empirical studies are needed to improve the benefits dependency network presented in this study. In this paper, we aim to realize the relations between DevOps practices and benefits in a systematic manner. We used the concept of benefits dependency network to synthesize the findings of the literature, in particular, to specify dependencies between DevOps practices and link the practices to benefits. Only a few empirical studies are available that can be attributed to the nascency of DevOps research. An initial version of the DevOps benefits dependency network has been derived. [ABSTRACT FROM AUTHOR]},
  keywords = {benefits and values,BEST practices,challenges,COMPUTER software development,development and operations,DevOps,EMPIRICAL research,LITERATURE reviews,principles and practices,SOFTWARE patterns,systematic literature review},
  file = {/Users/awwillc/Zotero/storage/R4ABC6PY/Jabbari et al. - 2018 - Towards a benefits dependency network for DevOps b.pdf}
}

@article{jansenCuriousContainersFramework2020,
  title = {Curious {{Containers}}: {{A}} Framework for Computational Reproducibility in Life Sciences with Support for {{Deep Learning}} Applications},
  author = {Jansen, Christoph and Annuscheit, Jonas and Schilling, Bruno and Strohmenger, Klaus and Witt, Michael and Bartusch, Felix and Herta, Christian and Hufnagl, Peter and Krefting, Dagmar},
  year = {2020/11/01/November 2020///},
  journal = {Future Generation Computer Systems},
  volume = {112},
  pages = {209--227},
  issn = {0167-739X},
  doi = {10/ghkb9g},
  abstract = {In clinical scenarios, there is an increasing interest in complex computational experiments, as for example the training of Deep Learning models. Reproducibility is an essential property of such experiments, especially if the result contributes to a patient's treatment. This paper introduces Curious Containers, a software framework for computational reproducibility that treats data, software and runtime environment as decentralized network resources. All experiment resources are described in a single file, using a new format that is compatible with a subset of the Common Workflow Language. Docker is used to deploy the experiment software in a container image, including arbitrary data transmission programs to connect with existing storage solutions. The framework supports Deep Learning applications, that have a high demand in storage and processing capabilities. Large datasets can be mounted inside containers via network filesystems like SSHFS based on the filesystem in user-space technology. The Nvidia-Container-Toolkit enables GPU usage. Curious Containers has been tested in two biomedical scenarios. The first use case is a Deep Learning application for tumor classification in images that requires a large dataset and a GPU. In this context, a prototypical integration of the framework with the existing Data Version Control system for exploratory Deep Learning modeling has been developed. The second use case extends an existing container image, including a scientific workflow for detection and comparison of human protein in mass spectrography data. The container image was originally developed for an archiving platform and could be extended to be compatible with both Curious Containers and cwltool, the Common Workflow Language reference implementation. The presented solution allows for consistent description and execution of computational experiments, while trying to be both flexible and interoperable with existing software and standards. Support for Deep Learning experiments is gaining importance as such systems are increasingly validated as medical decision support systems.},
  keywords = {Common Workflow Language,Container,Deep Learning,FAIR principles,Machine learning,Reproducibility},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Elsevier B.V."\}\}},
  file = {/Users/awwillc/Zotero/storage/EHDGU6MQ/Jansen et al. - 2020 - Curious Containers A framework for computational .pdf}
}

@misc{JenkinsVsGitLab2020,
  title = {Jenkins vs {{GitLab CI}}: {{Battle}} of {{CI}}/{{CD Tools}}},
  shorttitle = {Jenkins vs {{GitLab CI}}},
  year = {2020},
  month = aug,
  journal = {LambdaTest},
  abstract = {The battle of CI/CD tools rages on as we dig deeper into the difference between Jenkins vs GitLab CI, come and find out which is the right tool for your DevOps testing needs.},
  chapter = {Automation},
  language = {en-US},
  file = {/Users/awwillc/Zotero/storage/JVIA7ZUB/jenkins-vs-gitlab-ci-battle-of-ci-cd-tools.html}
}

@article{jochenschirrwagenExpandingResearchData2019,
  title = {Expanding the {{Research Data Management Service Portfolio}} at {{Bielefeld University According}} to the {{Three}}-Pillar {{Principle Towards Data FAIRness}}},
  author = {{Jochen Schirrwagen} and {Philipp Cimiano} and {Vidya Ayer} and {Christian Pietsch} and {Cord Wiljes} and {Johanna Vompras} and {Dirk Pieper}},
  year = {2019},
  month = jan,
  journal = {Data Science Journal},
  volume = {18},
  number = {1},
  issn = {1683-1470},
  doi = {10/ghkb8s},
  abstract = {Research Data Management at Bielefeld University is considered as a cross-cutting task among central facilities and research groups at the faculties. While initially started as project ``Bielefeld Data Informium'' lasting over seven years (2010\textendash 2015), it is now being expanded by setting up a Competence Center for Research Data. The evolution of the institutional RDM is based on the three-pillar principle: 1. Policies, 2. Technical infrastructure and 3. Support structures. The problem of data quality and the issues with reproducibility of research data is addressed in the project Conquaire. It is creating an infrastructure for the processing and versioning of research data which will finally allow publishing of research data in the institutional repository. Conquaire extends the existing RDM infrastructure in three ways: with a Collaborative Platform, Data Quality Checking, and Reproducible Research.},
  keywords = {Continuous Integration,Q1-390,Reproducibility,Research Data Management,Science (General)},
  annotation = {mlzsync1:0046\{"extrafields":\{"publisher":"Ubiquity Press"\}\}},
  file = {/Users/awwillc/Zotero/storage/8RZMCXRT/Jochen Schirrwagen et al. - 2019 - Expanding the Research Data Management Service Por.pdf}
}

@article{jungContainersOrchestrationNumerical2021,
  title = {Containers and Orchestration of Numerical Ocean Model for Computational Reproducibility and Portability in Public and Private Clouds: {{Application}} of {{ROMS}} 3.6},
  author = {Jung, Kwangwoog and Cho, Yang-Ki and Tak, Yong-Jin},
  year = {2021/05/01/May 2021///},
  journal = {Simulation Modelling Practice and Theory},
  volume = {109},
  publisher = {{Elsevier B.V.}},
  issn = {1569-190X},
  abstract = {Highlights \textbullet Containerized regional ocean-modeling system is implemented in various clouds.\textbullet Container-based architecture is useful for reproducibility and portability of ROMS.\textbullet Container-based HPC architecture increases flexibility in private and public clouds.\textbullet Proposed container-based HPC architecture reduces preparation time for model setup.\textbullet Kubernetes-managed container cluster architecture is used for ocean modeling.},
  keywords = {⛔ No DOI found,Cloud computing,Computational reproducibility,Containerization,Docker,High-performance computing,Infra abstraction,Kubernetes,Numerical ocean model,Public and Private Cloud,Regional Ocean-modeling System}
}

@article{k.jarrodmillmanTeachingComputationalReproducibility2018,
  title = {Teaching {{Computational Reproducibility}} for {{Neuroimaging}}},
  author = {{K. Jarrod Millman} and {Matthew Brett} and {Ross Barnowski} and {Jean-Baptiste Poline}},
  year = {2018},
  month = oct,
  journal = {Frontiers in Neuroscience},
  volume = {12},
  issn = {1662-453X},
  doi = {10/gfk8n5},
  abstract = {We describe a project-based introduction to reproducible and collaborative neuroimaging analysis. Traditional teaching on neuroimaging usually consists of a series of lectures that emphasize the big picture rather than the foundations on which the techniques are based. The lectures are often paired with practical workshops in which students run imaging analyses using the graphical interface of specific neuroimaging software packages. Our experience suggests that this combination leaves the student with a superficial understanding of the underlying ideas, and an informal, inefficient, and inaccurate approach to analysis. To address these problems, we based our course around a substantial open-ended group project. This allowed us to teach: (a) computational tools to ensure computationally reproducible work, such as the Unix command line, structured code, version control, automated testing, and code review and (b) a clear understanding of the statistical techniques used for a basic analysis of a single run in an MR scanner. The emphasis we put on the group project showed the importance of standard computational tools for accuracy, efficiency, and collaboration. The projects were broadly successful in engaging students in working reproducibly on real scientific questions. We propose that a course on this model should be the foundation for future programs in neuroimaging. We believe it will also serve as a model for teaching efficient and reproducible research in other fields of computational science.},
  keywords = {computational reproducibility,education,FMRI,neuroimaging,Neurosciences. Biological psychiatry. Neuropsychiatry,RC321-571,scientific computing,statistics},
  annotation = {mlzsync1:0052\{"extrafields":\{"publisher":"Frontiers Media S.A."\}\} QID: Q58580656},
  file = {/Users/awwillc/Zotero/storage/N3XFF4JZ/K. Jarrod Millman et al. - 2018 - Teaching Computational Reproducibility for Neuroim.pdf}
}

@article{karamitsosApplyingDevOpsPractices2020,
  title = {Applying {{DevOps Practices}} of {{Continuous Automation}} for {{Machine Learning}}.},
  author = {Karamitsos, Ioannis and Albarhami, Saeed and Apostolopoulos, Charalampos},
  year = {2020},
  month = jul,
  journal = {Information (2078-2489)},
  volume = {11},
  number = {7},
  pages = {363},
  issn = {20782489},
  doi = {10/ghkb9r},
  abstract = {This paper proposes DevOps practices for machine learning application, integrating both the development and operation environment seamlessly. The machine learning processes of development and deployment during the experimentation phase may seem easy. However, if not carefully designed, deploying and using such models may lead to a complex, time-consuming approaches which may require significant and costly efforts for maintenance, improvement, and monitoring. This paper presents how to apply continuous integration (CI) and continuous delivery (CD) principles, practices, and tools so as to minimize waste, support rapid feedback loops, explore the hidden technical debt, improve value delivery and maintenance, and improve operational functions for real-world machine learning applications. [ABSTRACT FROM AUTHOR]},
  keywords = {AUTOMATION,CD,CI,CRISP-DM,DevOps,LEARNING,machine learning,MACHINE learning,MAINTENANCE,pipeline,SEMMA,TDSP},
  file = {/Users/awwillc/Zotero/storage/L8VI7VH2/Karamitsos et al. - 2020 - Applying DevOps Practices of Continuous Automation.pdf}
}

@article{karvonenSystematicLiteratureReview2017,
  title = {Systematic Literature Review on the Impacts of Agile Release Engineering Practices},
  author = {Karvonen, Teemu and Behutiye, Woubshet and Oivo, Markku and Kuvaja, Pasi},
  year = {2017/06/01/June 2017///},
  journal = {Information and Software Technology},
  volume = {86},
  pages = {87--100},
  issn = {0950-5849},
  doi = {10/f956r8},
  abstract = {Context Agile release engineering (ARE) practices are designed to deliver software faster and cheaper to end users; hence, claims of such impacts should be validated by rigorous and relevant empirical studies.},
  keywords = {Agile,Continuous delivery,Continuous deployment,Continuous integration,Rapid release,Release engineering},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Elsevier B.V."\}\}}
}

@article{kavishwarb.wagholikarImplementationInformaticsIntegrating2018,
  title = {Implementation of Informatics for Integrating Biology and the Bedside (I2b2) Platform as {{Docker}} Containers},
  author = {{Kavishwar B. Wagholikar} and {Pralav Dessai} and {Javier Sanz} and {Michael E. Mendis} and {Douglas S. Bell} and {Shawn N. Murphy}},
  year = {2018},
  month = jul,
  journal = {BMC Medical Informatics and Decision Making},
  volume = {18},
  number = {1},
  pages = {1--6},
  issn = {1472-6947},
  doi = {10/gdxkt4},
  abstract = {Abstract Background Informatics for Integrating Biology and the Bedside (i2b2) is an open source clinical data analytics platform used at over 200 healthcare institutions for querying patient data. The i2b2 platform has several components with numerous dependencies and configuration parameters, which renders the task of installing or upgrading i2b2 a challenging one. Even with the availability of extensive documentation and tutorials, new users often require several weeks to correctly install a functional i2b2 platform. The goal of this work is to simplify the installation and upgrade process for i2b2. Specifically, we have containerized the core components of the platform, and evaluated the containers for ease of installation. Results We developed three Docker container images: WildFly, database, and web, to encapsulate the three major deployment components of i2b2. These containers isolate the core functionalities of the i2b2 platform, and work in unison to provide its functionalities. Our evaluations indicate that i2b2 containers function successfully on the Linux platform. Our results demonstrate that the containerized components work out-of-the-box, with minimal configuration. Conclusions Containerization offers the potential to package the i2b2 platform components into standalone executable packages that are agnostic to the underlying host operating system. By releasing i2b2 as a Docker container, we anticipate that users will be able to create a working i2b2 hive installation without the need to download, compile, and configure individual components that constitute the i2b2 cells, thus making this platform accessible to a greater number of institutions.},
  keywords = {Biomedical research,Computer applications to medicine. Medical informatics,Containerization,Docker,High performance computing,I2B2,R858-859.7},
  annotation = {mlzsync1:0035\{"extrafields":\{"publisher":"BMC"\}\} QID: Q62718236},
  file = {/Users/awwillc/Zotero/storage/32EBIP97/Kavishwar B. Wagholikar et al. - 2018 - Implementation of informatics for integrating biol.pdf}
}

@article{Kim2019688,
  title = {Toward Computational Reproducibility: {{A}} Doctoral Student's Story of Passing the Baton},
  author = {Kim, J. and Blake, C. and Darch, P.T.},
  year = {2019},
  journal = {Proceedings of the Association for Information Science and Technology},
  volume = {56},
  number = {1},
  pages = {688--690},
  publisher = {{John Wiley and Sons Inc}},
  issn = {23739231},
  doi = {10.1002/pra2.134},
  abbrev_source_title = {Proceedings of the Association for Information Science and Technology},
  abstract = {Computational reproducibility is a critical first step to supporting data reuse. Incentives that encourage data reuse within an academic setting are unlikely to be compelling for students who decide not to continue in academe. The goal of this work is to identify key barriers in the most likely of scenarios with computational reuse, when a doctoral student reproduces work done by another student from the same lab. Author(s) retain copyright, but ASIS\&T receives an exclusive publication license},
  affiliation = {School of Information Sciences, University of Illinois at Urbana-Champaign, Urbana, IL, United States},
  author_keywords = {data curation; data reuse; Reproducibility},
  document_type = {Article},
  language = {English},
  source = {Scopus}
}

@article{kimInstitutionalIndividualFactors2016,
  title = {Institutional and Individual Factors Affecting Scientists' Data-Sharing Behaviors: {{A}} Multilevel Analysis},
  author = {Kim, Youngseek and Stanton, Jeffrey M.},
  year = {2016},
  month = apr,
  journal = {Journal of the Association for Information Science and Technology},
  volume = {67},
  number = {4},
  pages = {776--799},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {2330-1635},
  doi = {10/gg5vb3},
  abstract = {The objective of this research was to investigate the institutional and individual factors that influence scientists' data-sharing behaviors across different scientific disciplines. Two theoretical perspectives, institutional theory, and theory of planned behavior, were employed in developing a research model that showed the complementary nature of the institutional and individual factors influencing scientists' data-sharing behaviors. This research used a survey method to examine to what extent those institutional and individual factors influence scientists' data-sharing behaviors in a range of scientific disciplines. A national survey (with 1,317 scientists in 43 disciplines) showed that regulative pressure by journals, normative pressure at a discipline level, and perceived career benefit and scholarly altruism at an individual level had significant positive relationships with data-sharing behaviors, and that perceived effort had a significant negative relationship. Regulative pressure by funding agencies and the availability of data repositories at a discipline level and perceived career risk at an individual level were not found to have any significant relationships with data-sharing behaviors.},
  keywords = {data},
  file = {/Users/awwillc/Zotero/storage/4ITPT6TK/Kim and Stanton - 2016 - Institutional and individual factors affecting sci.pdf}
}

@book{kitzesPracticeReproducibleResearch,
  title = {The {{Practice}} of {{Reproducible Research}}},
  author = {Kitzes, Justin and Turek, Daniel and Deniz, Fatma},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/WPYW52MA/Kitzes et al. - The Practice of Reproducible Research.pdf}
}

@article{koehlerlemanBetterTogetherElements2020,
  title = {Better Together: {{Elements}} of Successful Scientific Software Development in a  Distributed Collaborative Community.},
  author = {Koehler Leman, Julia and Weitzner, Brian D. and Renfrew, P. Douglas and Lewis, Steven M. and Moretti, Rocco and Watkins, Andrew M. and Mulligan, Vikram Khipple and Lyskov, Sergey and {Adolf-Bryfogle}, Jared and Labonte, Jason W. and Krys, Justyna and Bystroff, Christopher and Schief, William and Gront, Dominik and {Schueler-Furman}, Ora and Baker, David and Bradley, Philip and Dunbrack, Roland and Kortemme, Tanja and {Leaver-Fay}, Andrew and Strauss, Charlie E. M. and Meiler, Jens and Kuhlman, Brian and Gray, Jeffrey J. and Bonneau, Richard},
  year = {2020},
  month = may,
  journal = {PLoS computational biology},
  volume = {16},
  number = {5},
  pages = {e1007507},
  issn = {1553-7358 1553-734X 1553-734X},
  doi = {10/ggt62r},
  abstract = {Many scientific disciplines rely on computational methods for data analysis, model  generation, and prediction. Implementing these methods is often accomplished by  researchers with domain expertise but without formal training in software  engineering or computer science. This arrangement has led to underappreciation of  sustainability and maintainability of scientific software tools developed in  academic environments. Some software tools have avoided this fate, including the  scientific library Rosetta. We use this software and its community as a case study  to show how modern software development can be accomplished successfully,  irrespective of subject area. Rosetta is one of the largest software suites for  macromolecular modeling, with 3.1 million lines of code and many state-of-the-art  applications. Since the mid 1990s, the software has been developed collaboratively  by the RosettaCommons, a community of academics from over 60 institutions worldwide  with diverse backgrounds including chemistry, biology, physiology, physics,  engineering, mathematics, and computer science. Developing this software suite has  provided us with more than two decades of experience in how to effectively develop  advanced scientific software in a global community with hundreds of contributors.  Here we illustrate the functioning of this development community by addressing  technical aspects (like version control, testing, and maintenance),  community-building strategies, diversity efforts, software dissemination, and user  support. We demonstrate how modern computational research can thrive in a  distributed collaborative community. The practices described here are independent of  subject area and can be readily adopted by other software development communities.},
  language = {eng},
  pmcid = {PMC7197760},
  pmid = {32365137},
  keywords = {Computational Biology/*methods,Cooperative Behavior,Data Analysis,Engineering,Gene Library,Humans,Models; Molecular,Research Personnel,Research/*trends,Social Behavior,Software/*trends,User-Computer Interface},
  annotation = {QID: Q94512363},
  file = {/Users/awwillc/Zotero/storage/CD4MKHFZ/Koehler Leman et al. - 2020 - Better together Elements of successful scientific.pdf}
}

@article{konkolComputationalReproducibilityGeoscientific2019,
  title = {Computational Reproducibility in Geoscientific Papers: {{Insights}} from a Series of Studies with Geoscientists and a Reproduction Study.},
  author = {Konkol, Markus and Kray, Christian and Pfeiffer, Max},
  year = {2019},
  month = feb,
  journal = {International Journal of Geographical Information Science},
  volume = {33},
  number = {2},
  pages = {408--429},
  issn = {13658816},
  doi = {10/gg5vcc},
  abstract = {Reproducibility is a cornerstone of science and thus for geographic research as well. However, studies in other disciplines such as biology have shown that published work is rarely reproducible. To assess the state of reproducibility, specifically computational reproducibility (i.e. rerunning the analysis of a paper using the original code), in geographic research, we asked geoscientists about this topic using three methods: a survey (n~=~146), interviews (n~=~9), and a focus group (n~=~5). We asked participants about their understanding of open reproducible research (ORR), how much it is practiced, and what obstacles hinder ORR. We found that participants had different understandings of ORR and that there are several obstacles for authors and readers (e.g. effort, lack of openness). Then, in order to complement the subjective feedback from the participants, we tried to reproduce the results of papers that use spatial statistics to address problems in the geosciences. We selected 41 open access papers from Copernicus and Journal of Statistical Software and executed the R code. In doing so, we identified several technical issues and specific issues with the reproduced figures depicting the results. Based on these findings, we propose guidelines for authors to overcome the issues around reproducibility in the computational geosciences. [ABSTRACT FROM AUTHOR]},
  keywords = {COMPUTATIONAL complexity,computational research,EARTH sciences,EARTH scientists,GEOLOGICAL statistics,Open reproducible research,REPRODUCIBLE research,spatial statistics},
  annotation = {mlzsync1:0052\{"extrafields":\{"publisher":"Taylor \& Francis Ltd"\}\}},
  file = {/Users/awwillc/Zotero/storage/VPNMZS7C/Konkol et al. - 2019 - Computational reproducibility in geoscientific pap.pdf}
}

@misc{krcmarResearchPracticeDevOps,
  title = {Research for {{Practice}}: {{The DevOps Phenomenon}}},
  shorttitle = {Research for {{Practice}}},
  author = {Krcmar, Nicole Forsgren, Manuel Wiesche, Heiko Gewald, Helmut, Anna Wiedemann},
  abstract = {An executive crash course.},
  howpublished = {https://cacm.acm.org/magazines/2019/8/238341-research-for-practice-the-devops-phenomenon/fulltext},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/GFUMWBVQ/fulltext.html}
}

@article{Kreibig201793,
  title = {Computational Reproducibility of ``{{Goal}} Relevance and Goal Conduciveness Appraisals Lead to Differential Autonomic Reactivity in Emotional Responding to Performance Feedback'' ({{Kreibig}}, {{Gendolla}}, \& {{Scherer}}, 2012): {{A}} Guide and New Evidence},
  author = {Kreibig, S.D.},
  year = {2017},
  journal = {International Journal of Psychophysiology},
  volume = {119},
  pages = {93--107},
  publisher = {{Elsevier B.V.}},
  issn = {01678760},
  doi = {10.1016/j.ijpsycho.2017.06.001},
  abbrev_source_title = {Int. J. Psychophysiol.},
  abstract = {The emerging field of the psychophysiology of motivation bears many new findings, but little replication. Using my own data (Kreibig, Gendolla, \& Scherer, 2012), I test the reproducibility of this specific study, provide the necessary materials to make the study reproducible, and instantiate proper reproducibility practices that other researchers can use as a road map toward the same goal. In addition, based on re-analyses of the original data, I report new evidence for the motivational effects of emotional responding to performance feedback. Specifically, greater appraisal of goal relevance amplifies the emotional response to events appraised as conducive (i.e., effort mobilization), but not to those appraised as obstructive to a person's goals (i.e., effort withdrawal). I conclude by providing a ten-step road map of best practices to facilitate computational reproducibility for future studies. \textcopyright{} 2017 Elsevier B.V.},
  affiliation = {Department of Psychology, Stanford University, Stanford, United States},
  author_keywords = {Appraisal; Computational reproducibility; Emotion; Motivation; Psychophysiology; Replication},
  coden = {IJPSE},
  document_type = {Article},
  funding_details = {National Institute of Dental and Craniofacial ResearchNational Institute of Dental and Craniofacial Research, NIDCR, R56DE025321},
  language = {English},
  pubmed_id = {28600152},
  source = {Scopus},
  keywords = {adult,Adult,autonomic nervous system,Autonomic Nervous System,bear,emotion,Emotions,Feedback,female,Female,Goals,human,Humans,male,Male,motivation,Motivation,nonhuman,physiology,Psychological,psychological feedback,psychomotor performance,Psychomotor Performance,psychophysiology,reproducibility,Reproducibility of Results,scientist,young adult,Young Adult}
}

@article{kriegerFacilitatingReproducibleProject2019,
  title = {Facilitating Reproducible Project Management and Manuscript Development in Team  Science: {{The}} Projects {{R}} Package.},
  author = {Krieger, Nikolas I. and Perzynski, Adam T. and Dalton, Jarrod E.},
  year = {2019},
  journal = {PloS one},
  volume = {14},
  number = {7},
  pages = {e0212390},
  issn = {1932-6203 1932-6203},
  doi = {10/ggnm76},
  abstract = {The contemporary scientific community places a growing emphasis on the  reproducibility of research. The projects R package is a free, open-source package  created in the interest of facilitating reproducible research workflows. It adds to  existing software tools for reproducible research and introduces several practical  features that are helpful for scientists and their collaborative research teams. For  each individual project, it supplies a framework for storing raw and cleaned study  data sets, and it provides script templates for protocol creation, data cleaning,  data analysis and manuscript development. Internal databases of project and author  information are generated and displayed, and manuscript title pages containing  author lists and their affiliations are automatically generated from the internal  database. File management tools allow teams to organize multiple projects. When used  on a shared file system, multiple researchers can harmoniously contribute to the  same project in a less punctuated manner, reducing the frequency of  misunderstandings and the need for status updates.},
  language = {eng},
  pmcid = {PMC6662995},
  pmid = {31356588},
  keywords = {*Interdisciplinary Research,*Software,Databases; Factual,Humans},
  annotation = {QID: Q92251648},
  file = {/Users/awwillc/Zotero/storage/P8JGL5UB/Krieger et al. - 2019 - Facilitating reproducible project management and m.pdf}
}

@article{l.hattonComputationalReproducibilityElephant2019,
  title = {Computational {{Reproducibility}}: {{The Elephant}} in the {{Room}}},
  author = {{L. Hatton} and {M. van Genuchten}},
  year = {2019},
  month = mar,
  journal = {IEEE Software},
  volume = {36},
  number = {2},
  pages = {137--144},
  issn = {1937-4194},
  doi = {10/ggkvtr},
  abstract = {Examines the concept of computational reproducibility. Reports on the development of software programming and addresses the challenges of managing software development and developing reliability software update and maintenance procedures.},
  keywords = {Software engineering,Software maintenance,Software reliability},
  file = {/Users/awwillc/Zotero/storage/5J35WLW8/L. Hatton and M. van Genuchten - 2019 - Computational Reproducibility The Elephant in the.pdf}
}

@article{landauDrakePackagePipeline2018,
  title = {The Drake {{R}} Package: A Pipeline Toolkit for Reproducibility and High-Performance Computing},
  author = {Landau, William},
  year = {2018},
  month = jan,
  journal = {The Journal of Open Source Software},
  volume = {3},
  pages = {550},
  doi = {10/gd876m},
  file = {/Users/awwillc/Zotero/storage/7SHTVS9D/Landau - 2018 - The drake R package a pipeline toolkit for reprod.pdf}
}

@article{laukkanenProblemsCausesSolutions2017,
  title = {Problems, Causes and Solutions When Adopting Continuous Delivery\textemdash{{A}} Systematic Literature Review.},
  author = {Laukkanen, Eero and Itkonen, Juha and Lassenius, Casper},
  year = {2017},
  month = feb,
  journal = {Information \& Software Technology},
  volume = {82},
  pages = {55--79},
  issn = {09505849},
  doi = {10/f9d8qc},
  abstract = {Context: Continuous delivery is a software development discipline in which software is always kept releasable. The literature contains instructions on how to adopt continuous delivery, but the adoption has been challenging in practice. Objective: In this study, a systematic literature review is conducted to survey the faced problems when adopting continuous delivery. In addition, we identify causes for and solutions to the problems. Method: By searching five major bibliographic databases, we identified 293 articles related to continuous delivery. We selected 30 of them for further analysis based on them containing empirical evidence of adoption of continuous delivery, and focus on practice instead of only tooling. We analyzed the selected articles qualitatively and extracted problems, causes and solutions. The problems and solutions were thematically synthesized into seven themes: build design, system design, integration, testing, release, human and organizational and resource. Results: We identified a total of 40 problems, 28 causal relationships and 29 solutions related to adoption of continuous delivery. Testing and integration problems were reported most often, while the most critical reported problems were related to testing and system design. Causally, system design and testing were most connected to other themes. Solutions in the system design, resource and human and organizational themes had the most significant impact on the other themes. The system design and build design themes had the least reported solutions. Conclusions: When adopting continuous delivery, problems related to system design are common, critical and little studied. The found problems, causes and solutions can be used to solve problems when adopting continuous delivery in practice. [ABSTRACT FROM AUTHOR]},
  keywords = {Computer software development,Continuous delivery,Continuous deployment,Continuous integration,Information technology,Organizational research,Problem solving,Systematic literature review,Systems design},
  annotation = {QID: Q59620049}
}

@misc{lazzeriIntegratingDataScience2019,
  title = {Integrating the {{Data Science}} and {{App Development Cycles}}},
  author = {Lazzeri, Francesca},
  year = {2019},
  month = jun,
  journal = {Medium},
  abstract = {As data scientists, we are used to developing and training machine learning models in our favorite Python notebook or an integrated\ldots},
  howpublished = {https://medium.com/microsoftazure/integrating-the-data-science-and-app-development-cycles-9845da423adc},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/N9FZ5D54/Lazzeri - 2019 - Integrating the Data Science and App Development C.pdf;/Users/awwillc/Zotero/storage/VTZI3CQW/integrating-the-data-science-and-app-development-cycles-9845da423adc.html}
}

@article{leipzigRoleMetadataReproducible2020,
  title = {The Role of Metadata in Reproducible Computational Research},
  author = {Leipzig, Jeremy and N{\"u}st, Daniel and Hoyt, Charles Tapley and {Soiland-Reyes}, Stian and Ram, Karthik and Greenberg, Jane},
  year = {2020},
  abstract = {Reproducible computational research (RCR) is the keystone of the scientific method for in silico analyses, packaging the transformation of raw data to published results. In addition to its role in research integrity, RCR has the capacity to significantly accelerate evaluation and reuse. This potential and wide-support for the FAIR principles have motivated interest in metadata standards supporting RCR. Metadata provides context and provenance to raw data and methods and is essential to both discovery and validation. Despite this shared connection with scientific data, few studies have explicitly described the relationship between metadata and RCR. This article employs a functional content analysis to identify metadata standards that support RCR functions across an analytic stack consisting of input data, tools, notebooks, pipelines, and publications. Our article provides background context, explores gaps, and discovers component trends of embeddedness and methodology weight from which we derive recommendations for future work.},
  keywords = {⛔ No DOI found,Computer Science - Digital Libraries,Computer Science - Software Engineering},
  file = {/Users/awwillc/Zotero/storage/RBUUZ6SU/Leipzig et al. - 2020 - The role of metadata in reproducible computational.pdf}
}

@article{leiteSurveyDevOpsConcepts2020,
  title = {A {{Survey}} of {{DevOps Concepts}} and {{Challenges}}.},
  author = {LEITE, LEONARDO and ROCHA, CARLA and KON, FABIO and MILOJICIC, DEJAN and MEIRELLES, PAULO},
  year = {2020},
  month = jan,
  journal = {ACM Computing Surveys},
  volume = {52},
  number = {6},
  pages = {1--35},
  issn = {03600300},
  doi = {10/ggmt4t},
  abstract = {DevOps is a collaborative and multidisciplinary organizational effort to automate continuous delivery of new software updates while guaranteeing their correctness and reliability. The present survey investigates and discusses DevOps challenges from the perspective of engineers, managers, and researchers. We review the literature and develop a DevOps conceptual map, correlating the DevOps automation tools with these concepts. We then discuss their practical implications for engineers, managers, and researchers. Finally, we critically explore some of the most relevant DevOps challenges reported by the literature. [ABSTRACT FROM AUTHOR]},
  keywords = {and build process,Concept mapping,Concepts,Conceptual structures,configuration management,Configuration management,continuous (delivery deployment integration),DevOps,Engineers,Literature reviews,release process versioning},
  annotation = {mlzsync1:0067\{"extrafields":\{"publisher":"Association for Computing Machinery"\}\}},
  file = {/Users/awwillc/Zotero/storage/JLCBQRAL/LEITE et al. - 2020 - A Survey of DevOps Concepts and Challenges..pdf}
}

@article{levequeReproducibleResearchScientific2012,
  title = {Reproducible Research for Scientific Computing: {{Tools}} and Strategies for Changing the Culture},
  author = {LeVeque, R.J. and Mitchell, I.M. and Stodden, V.},
  year = {2012},
  month = jul,
  journal = {Computing in Science \& Engineering, Comput. Sci. Eng.},
  volume = {14},
  number = {4},
  pages = {13--17},
  issn = {1521-9615},
  doi = {10/gg22fc},
  abstract = {This article considers the obstacles involved in creating reproducible computational research as well as some efforts and approaches to overcome them.},
  keywords = {Bioengineering,Communication; Networking and Broadcast Technologies,Computational complexity,computational science and engineering,Computing and Processing,data and code disclosure,Hidden Markov models,reproducibility,Reproducibility of results,reproducible research,Research and development,scientific computing,Scientific computing},
  annotation = {mlzsync1:0050\{"extrafields":\{"place":"USA","publisher":"IEEE"\}\}},
  file = {/Users/awwillc/Zotero/storage/X3FC55WI/LeVeque et al. - 2012 - Reproducible research for scientific computing To.pdf}
}

@inproceedings{lwakatareDimensionsDevOps2015,
  title = {Dimensions of {{DevOps}}},
  booktitle = {Agile {{Processes}} in {{Software Engineering}} and {{Extreme Programming}}},
  author = {Lwakatare, Lucy Ellen and Kuvaja, Pasi and Oivo, Markku},
  editor = {Lassenius, Casper and Dings{\o}yr, Torgeir and Paasivaara, Maria},
  year = {2015},
  pages = {212--217},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {DevOps has been identified as an important aspect in the continuous deployment paradigm in practitioner communities and academic research circles. However, little has been presented to describe and formalize what it constitutes. The absence of such understanding means that the phenomenon will not be effectively communicated and its impact not understood in those two communities. This study investigates the elements that characterize the DevOps phenomenon using a literature survey and interviews with practitioners actively involved in the DevOps movement. Four main dimensions of DevOps are identified: collaboration, automation, measurement and monitoring. An initial conceptual framework is developed to communicate the phenomenon to practitioners and the scientific community as well as to facilitate input for future research.},
  isbn = {978-3-319-18612-2},
  file = {/Users/awwillc/Zotero/storage/UYPKDSSF/Lwakatare et al. - 2015 - Dimensions of DevOps.pdf}
}

@inproceedings{lwakatareDimensionsDevOps2015a,
  title = {Dimensions of {{DevOps}}},
  booktitle = {Agile {{Processes}} in {{Software Engineering}} and {{Extreme Programming}}},
  author = {Lwakatare, Lucy Ellen and Kuvaja, Pasi and Oivo, Markku},
  editor = {Lassenius, Casper and Dings{\o}yr, Torgeir and Paasivaara, Maria},
  year = {2015},
  pages = {212--217},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {DevOps has been identified as an important aspect in the continuous deployment paradigm in practitioner communities and academic research circles. However, little has been presented to describe and formalize what it constitutes. The absence of such understanding means that the phenomenon will not be effectively communicated and its impact not understood in those two communities. This study investigates the elements that characterize the DevOps phenomenon using a literature survey and interviews with practitioners actively involved in the DevOps movement. Four main dimensions of DevOps are identified: collaboration, automation, measurement and monitoring. An initial conceptual framework is developed to communicate the phenomenon to practitioners and the scientific community as well as to facilitate input for future research.},
  isbn = {978-3-319-18612-2},
  file = {/Users/awwillc/Zotero/storage/MRSCCAWG/Lwakatare et al. - 2015 - Dimensions of DevOps.pdf}
}

@inproceedings{lwakatareRelationshipDevOpsAgile2016,
  title = {Relationship of {{DevOps}} to {{Agile}}, {{Lean}} and {{Continuous Deployment}}},
  booktitle = {Product-{{Focused Software Process Improvement}}},
  author = {Lwakatare, Lucy Ellen and Kuvaja, Pasi and Oivo, Markku},
  editor = {Abrahamsson, Pekka and Jedlitschka, Andreas and Nguyen Duc, Anh and Felderer, Michael and Amasaki, Sousuke and Mikkonen, Tommi},
  year = {2016},
  pages = {399--415},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {In recent years, the DevOps phenomenon has attaracted interest amongst practitioners and researchers in software engineering, reflecting the greater emphasis on collaboration between development and IT operations. However, despite this growing interest, DevOps is often conflated with agile and continuous deployment approaches of software development. This study compares DevOps with agile, lean and continuous deployment approaches in software development from four perspectives: origin, adoption, implementation and goals. The study also reports on the claimed effects and on the metrics of DevOps used to asses those effects. The research is based on an interpretative analysis of qualitative data from documents describing DevOps and practitioner's responses in a DevOps workshop. Our findings indicate that the DevOps phenomenon originated from continuous deployment as an evolution of agile software development, informed by a lean principles background. It was also concluded that successful adoption of DevOps requires agile software development.},
  isbn = {978-3-319-49094-6}
}

@article{maer-mateiSkillNeedsEarly2019,
  title = {Skill {{Needs}} for {{Early Career Researchers}}\textemdash{{A Text Mining Approach}}},
  author = {{Maer-Matei}, Monica Mihaela and Georgescu, Tiberiu Marian and Mocanu, Cristina and Zamfir, Ana-Maria},
  year = {2019/01/01////},
  journal = {Sustainability},
  volume = {11},
  number = {10},
  issn = {20711050},
  doi = {10/ghkb9m},
  abstract = {Research and development activities are one of the main drivers for progress, economic growth and wellbeing in many societies. This article proposes a text mining approach applied to a large amount of data extracted from job vacancies advertisements, aiming to shed light on the main skills and demands that characterize first stage research positions in Europe. Results show that data handling and processing skills are essential for early career researchers, irrespective of their research field. Also, as many analyzed first stage research positions are connected to universities, they include teaching activities to a great extent. Management of time, risks, projects, and resources plays an important part in the job requirements included in the analyzed advertisements. Such information is relevant not only for early career researchers who perform job selection taking into account the match of possessed skills with the required ones, but also for educational institutions that are responsible for skills development of the future R\&D professionals.},
  language = {English},
  keywords = {advertising,economic development,employment opportunities,Europe,professionals,research and development,risk management,time management,universities}
}

@article{margoluisUsingConceptualModels2009,
  title = {Using Conceptual Models as a Planning and Evaluation Tool in Conservation},
  author = {Margoluis, Richard and Stem, Caroline and Salafsky, Nick and Brown, Marcia},
  year = {2009},
  month = may,
  journal = {Evaluation and Program Planning},
  volume = {32},
  number = {2},
  pages = {138--147},
  issn = {0149-7189},
  doi = {10/brz2m3},
  abstract = {Conservation projects are dynamic interventions that occur in complex contexts involving intricate interactions of social, political, economic, cultural, and environmental factors. These factors are constantly changing over time and space as managers learn more about the context within which they work. This complex context poses challenges for planning and evaluating conservation project. In order for conservation managers and evaluation professionals to design good interventions and measure project success, they simultaneously need to embrace and deconstruct contextual complexity. In this article, we describe conceptual models\textemdash a tool that helps articulate and make explicit assumptions about a project's context and what a project team hopes to achieve. We provide real-world examples of conceptual models, discuss the relationship between conceptual models and other evaluation tools, and describe various ways that conceptual models serve as a key planning and evaluation tool. These include, for example, that they document assumptions about a project site and they provide a basis for analyzing theories of change. It is impractical to believe that we can completely eliminate detail or dynamic complexity in projects. Nevertheless, conceptual models can help reduce the effects of this complexity by helping us understand it.},
  keywords = {Adaptive management,Conceptual model,Conservation project,Evaluation,Impact,Management,Monitoring,Planning,Theory of change}
}

@article{markuskonkolPublishingComputationalResearch2020,
  title = {Publishing Computational Research - a Review of Infrastructures for Reproducible and Transparent Scholarly Communication},
  author = {{Markus Konkol} and {Daniel N\"ust} and {Laura Goulier}},
  year = {2020},
  month = jul,
  journal = {Research Integrity and Peer Review},
  volume = {5},
  number = {1},
  pages = {1--8},
  issn = {2058-8615},
  doi = {10/ghd4vb},
  abstract = {Abstract Background The trend toward open science increases the pressure on authors to provide access to the source code and data they used to compute the results reported in their scientific papers. Since sharing materials reproducibly is challenging, several projects have developed solutions to support the release of executable analyses alongside articles. Methods We reviewed 11 applications that can assist researchers in adhering to reproducibility principles. The applications were found through a literature search and interactions with the reproducible research community. An application was included in our analysis if it (i) was actively maintained at the time the data for this paper was collected, (ii) supports the publication of executable code and data, (iii) is connected to the scholarly publication process. By investigating the software documentation and published articles, we compared the applications across 19 criteria, such as deployment options and features that support authors in creating and readers in studying executable papers. Results From the 11 applications, eight allow publishers to self-host the system for free, whereas three provide paid services. Authors can submit an executable analysis using Jupyter Notebooks or R Markdown documents (10 applications support these formats). All approaches provide features to assist readers in studying the materials, e.g., one-click reproducible results or tools for manipulating the analysis parameters. Six applications allow for modifying materials after publication. Conclusions The applications support authors to publish reproducible research predominantly with literate programming. Concerning readers, most applications provide user interfaces to inspect and manipulate the computational analysis. The next step is to investigate the gaps identified in this review, such as the costs publishers have to expect when hosting an application, the consideration of sensitive data, and impacts on the review process.},
  keywords = {Computational statistics,General Works,Open reproducible research,Open science,Scholarly communication},
  annotation = {mlzsync1:0035\{"extrafields":\{"publisher":"BMC"\}\} QID: Q97593284},
  file = {/Users/awwillc/Zotero/storage/WZGHNYDA/Markus Konkol et al. - 2020 - Publishing computational research - a review of in.pdf}
}

@phdthesis{martijandaAutomationContinuousIntegration,
  type = {{{bachelorThesis}}},
  title = {Automation of the {{Continuous Integration}} ({{CI}}) - {{Continuous Delivery}}/{{Deployment}} ({{CD}}) {{Software Development}}},
  author = {Mart{\'i} Janda, Jordi Gabriel},
  abstract = {Continuous Integration (CI) is a practice in software development where developers periodically merge code changes in a central shared repository, after which automatic versions and tests are executed. CI entails an automation component (the target of this project) and a cultural one, as developers have to learn to integrate code periodically. The main goal of CI is to reduce the time to feedback over the software integration process, allowing to locate and fix bugs more easily and quickly, thus enhancing it quality while reducing the time to validate and publish new so},
  school = {Universitat Polit\`ecnica de Catalunya},
  keywords = {Àrees temàtiques de la UPC::Enginyeria de la telecomunicació,Automation,Automatització,Automatización,Continuous Delivery,Continuous Integration,Despliegue Contínuo,Enginyeria de programari,Integración Contínua,Software engineering}
}

@article{Marwick2017424,
  title = {Computational Reproducibility in Archaeological Research: {{Basic}} Principles and a Case Study of Their Implementation},
  author = {Marwick, B.},
  year = {2017},
  journal = {Journal of Archaeological Method and Theory},
  volume = {24},
  number = {2},
  pages = {424--450},
  publisher = {{Springer New York LLC}},
  issn = {10725369},
  doi = {10.1007/s10816-015-9272-9},
  abbrev_source_title = {J. Archaeol. Method and Theory},
  abstract = {The use of computers and complex software is pervasive in archaeology, yet their role in the analytical pipeline is rarely exposed for other researchers to inspect or reuse. This limits the progress of archaeology because researchers cannot easily reproduce each other's work to verify or extend it. Four general principles of reproducible research that have emerged in other fields are presented. An archaeological case study is described that shows how each principle can be implemented using freely available software. The costs and benefits of implementing reproducible research are assessed. The primary benefit, of sharing data in particular, is increased impact via an increased number of citations. The primary cost is the additional time required to enhance reproducibility, although the exact amount is difficult to quantify. \textcopyright{} 2016, Springer Science+Business Media New York.},
  affiliation = {Department of Anthropology, University of Washington, Seattle, WA, United States; Center for Archaeological Science, University of Wollongong, Wollongong, Australia},
  author_keywords = {Australian archaeology; Computer programming; Open science; Reproducible research; Software engineering},
  correspondence_address1 = {Marwick, B.; Department of Anthropology, United States; email: bmarwick@uw.edu},
  document_type = {Article},
  language = {English},
  source = {Scopus}
}

@article{marwickComputationalReproducibilityArchaeological2017,
  title = {Computational {{Reproducibility}} in {{Archaeological Research}}: {{Basic Principles}} and a {{Case Study}} of {{Their Implementation}}},
  author = {Marwick, Ben},
  year = {2017},
  journal = {Journal of Archaeological Method and Theory},
  volume = {24},
  number = {2},
  pages = {424},
  issn = {1072-5369},
  doi = {10/gd6b3b},
  abstract = {The use of computers and complex software is pervasive in archaeology, yet their role in the analytical pipeline is rarely exposed for other researchers to inspect or reuse. This limits the progress of archaeology because researchers cannot easily reproduce each other's work to verify or extend it. Four general principles of reproducible research that have emerged in other fields are presented. An archaeological case study is described that shows how each principle can be implemented using freely available software. The costs and benefits of implementing reproducible research are assessed. The primary benefit, of sharing data in particular, is increased impact via an increased number of citations. The primary cost is the additional time required to enhance reproducibility, although the exact amount is difficult to quantify.},
  keywords = {Australian archaeology,Computer programming,Open science,Reproducible research,Software engineering},
  annotation = {mlzsync1:0062\{"extrafields":\{"place":"New York","publisher":"Springer US"\}\} QID: Q55923845},
  file = {/Users/awwillc/Zotero/storage/S9QX6XIP/Marwick - 2017 - Computational Reproducibility in Archaeological Re.pdf}
}

@article{marwickPackagingDataAnalytical2018,
  title = {Packaging {{Data Analytical Work Reproducibly Using R}} (and {{Friends}})},
  author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
  year = {2018},
  month = jan,
  journal = {The American Statistician},
  volume = {72},
  number = {1},
  pages = {80--88},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10/gdhvm8},
  abstract = {ABSTRACTComputers are a central tool in the research process, enabling complex and large-scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognizable way for organizing the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
  file = {/Users/awwillc/Zotero/storage/CY3FHAV6/Marwick et al. - 2018 - Packaging Data Analytical Work Reproducibly Using .pdf}
}

@article{maylorGanttChartProject2001,
  title = {Beyond the {{Gantt}} Chart:: {{Project}} Management Moving On},
  shorttitle = {Beyond the {{Gantt}} Chart},
  author = {Maylor, Harvey},
  year = {2001},
  month = feb,
  journal = {European Management Journal},
  volume = {19},
  number = {1},
  pages = {92--100},
  issn = {0263-2373},
  doi = {10/bvftgq},
  abstract = {Large-scale engineering projects have traditionally dominated the subject of project management. Today, however, project management has become a core business process for most organisations. This paper argues that the academic subject and many of the practices have lagged this change. Particular problems are identified with the role of strategy and planning, the units of assessment, the planning process itself and the body of knowledge of the subject. An alternative view of project management is proposed based on an integrative model and areas for further development are identified.},
  language = {en},
  keywords = {Gantt charts,Operations management,Project management,Strategy},
  file = {/Users/awwillc/Zotero/storage/Z3IHIYJP/Maylor - 2001 - Beyond the Gantt chart Project management moving.pdf;/Users/awwillc/Zotero/storage/3H2Q2M3Y/S0263237300000748.html}
}

@article{mesnardReproducibleWorkflowPublic2020,
  title = {Reproducible {{Workflow}} on a {{Public Cloud}} for {{Computational Fluid Dynamics}}},
  author = {Mesnard, O. and Barba, L.A. and Thiruvathukal, G.K.},
  year = {2020},
  month = jan,
  journal = {Computing in Science \& Engineering, Comput. Sci. Eng.},
  volume = {22},
  number = {1},
  pages = {102--116},
  issn = {1521-9615},
  doi = {10/d2hr},
  abstract = {In a new effort to make our research transparent and reproducible by others, we developed a workflow to run and share computational studies on the public cloud Microsoft Azure. It uses Docker containers to create an image of the application software stack. We also adopt several tools that facilitate creating and managing virtual machines on compute nodes and submitting jobs to these nodes. The configuration files for these tools are part of an expanded ``reproducibility package'' that includes workflow definitions for cloud computing, in addition to input files and instructions. This facilitates recreating the cloud environment to rerun the computations under the same conditions. Although cloud providers have improved their offerings, many researchers using high-performance computing (HPC) are still skeptical about cloud computing. Thus, we ran benchmarks for tightly coupled applications to confirm that the latest HPC nodes of Microsoft Azure are indeed a viable alternative to traditional on-site HPC clusters. We also show that cloud offerings are now adequate to complete computational fluid dynamics studies with in-house research software that uses parallel computing with GPUs. Finally, we share with the community what we have learned from nearly two years of using Azure cloud to enhance the transparency and reproducibility in our computational simulations.},
  keywords = {Application software,Benchmark testing,Bioengineering,Cloud computing,Communication; Networking and Broadcast Technologies,Computational modeling,Computing and Processing,Research and development,Runtime environment,Software packages,Virtual machining},
  annotation = {mlzsync1:0050\{"extrafields":\{"place":"USA","publisher":"IEEE"\}\}},
  file = {/Users/awwillc/Zotero/storage/MH8Y8MUM/Mesnard et al. - 2020 - Reproducible Workflow on a Public Cloud for Comput.pdf}
}

@article{milkowskiReplicabilityReproducibilityReplication2018,
  title = {Replicability or Reproducibility? {{On}} the Replication Crisis in Computational  Neuroscience and Sharing Only Relevant Detail.},
  author = {Mi{\l}kowski, Marcin and Hensel, Witold M. and Hohol, Mateusz},
  year = {2018},
  month = dec,
  journal = {Journal of computational neuroscience},
  volume = {45},
  number = {3},
  pages = {163--172},
  issn = {1573-6873 0929-5313 0929-5313},
  doi = {10/gfgt3m},
  abstract = {Replicability and reproducibility of computational models has been somewhat  understudied by "the replication movement." In this paper, we draw on methodological  studies into the replicability of psychological experiments and on the mechanistic  account of explanation to analyze the functions of model replications and model  reproductions in computational neuroscience. We contend that model replicability, or  independent researchers' ability to obtain the same output using original code and  data, and model reproducibility, or independent researchers' ability to recreate a  model without original code, serve different functions and fail for different  reasons. This means that measures designed to improve model replicability may not  enhance (and, in some cases, may actually damage) model reproducibility. We claim  that although both are undesirable, low model reproducibility poses more of a threat  to long-term scientific progress than low model replicability. In our opinion, low  model reproducibility stems mostly from authors' omitting to provide crucial  information in scientific papers and we stress that sharing all computer code and  data is not a solution. Reports of computational studies should remain selective and  include all and only relevant bits of code.},
  language = {eng},
  pmcid = {PMC6306493},
  pmid = {30377880},
  keywords = {*Computational Biology,*Computational modeling,*Computer Simulation,*Direct and conceptual replication,*Methodology of computational neuroscience,*Models; Neurological,*Neurosciences,*Replication and reproduction,*Replication studies,Animals,Humans,Reproducibility of Results},
  annotation = {QID: Q58088709},
  file = {/Users/awwillc/Zotero/storage/II58TR8X/Miłkowski et al. - 2018 - Replicability or reproducibility On the replicati.pdf}
}

@article{Murray2021,
  title = {Data Freshness in Ecology and Conservation.},
  author = {et al. Murray, NJ},
  year = {2021},
  journal = {Trends in Ecology \& Evolution},
  volume = {36},
  number = {6},
  pages = {485--487},
  address = {{College of Science and Engineering, James Cook University, Townsville, Queensland 4811, Australia. Electronic address: nicholas.murray@jcu.edu.au. Remote Sensing Research Centre, School of Earth and Environmental Sciences, University of Queensland, Brisbane, Queensland, 4072, Australia; Australian Institute of Marine Science, Townsville, Queensland 4810, Australia. Australian Research Council Centre of Excellence for Coral Reef Studies, James Cook University, Townsville, Queensland 4811, Australia. Centre for Ecosystem Science, School of Biological, Earth and Environmental Sciences, University of New South Wales, New South Wales, Australia.}},
  doi = {10.1016/j.tree.2021.03.005},
  abstract = {Evolving capabilities in environmental data collection, sharing, and processing, are enabling unprecedented use of data from a wide range of sources. Yet data freshness, an important quality dimension associated with the age of data, is a poorly reported aspect of data quality that can lead to additional uncertainty in research findings.}
}

@article{mysariContinuousIntegrationContinuous2020,
  title = {Continuous {{Integration}} and {{Continuous Deployment Pipeline Automation Using Jenkins Ansible}}},
  author = {Mysari, Sriniketan and Bejgam, Vaibhav},
  year = {2020},
  month = feb,
  journal = {2020 International Conference on Emerging Trends in Information Technology and Engineering (ic-ETITE), Emerging Trends in Information Technology and Engineering (ic-ETITE), 2020 International Conference on},
  pages = {1--4},
  issn = {978-1-7281-4142-8},
  doi = {10/ghkb8v},
  abstract = {Automation is what every company needs to handle big projects where two or more people work together. CI/CD using Jenkins ansible is an optimized way of building and hosting any web applications. This paper focuses on building and integration using Jenkins with pipeline methodology and deploying using the ansible tool and gives you a basic skeleton of it. Integration using Jenkins is an easy task as it is open source and have many plug-in options. Ansible is a configuration management tool which is also an open source and the configuration format is YAML which can be easily readable by humans. Saving resources like time is a major challenge faced by the developing companies, so automation in integration and deployment using Jenkins ansible saves a lot of time and also if there are changes which need to be done in the project frequently, it can be easily updated. Using Ansible the shh access is simple and also it can run on Jenkins node.},
  keywords = {Ansible,Communication; Networking and Broadcast Technologies,Components; Circuits; Devices and Systems,Computing and Processing,Continuous Deployment,Continuous Integration,Fields; Waves and Electromagnetics,General Topics for Engineers,Jenkins,Pipeline Automation,Signal Processing and Analysis},
  annotation = {mlzsync1:0036\{"extrafields":\{"publisher":"IEEE"\}\}}
}

@article{Nüst20211300,
  title = {Practical Reproducibility in Geography and Geosciences},
  author = {N{\"u}st, D. and Pebesma, E.},
  year = {2021},
  journal = {Annals of the American Association of Geographers},
  volume = {111},
  number = {5},
  pages = {1300--1310},
  publisher = {{Taylor and Francis Ltd.}},
  issn = {24694452},
  doi = {10.1080/24694452.2020.1806028},
  abbrev_source_title = {Ann. Am. Assoc. Geogr.},
  abstract = {Reproducible research is often perceived as a technological challenge, but it is rooted in the challenge to improve scholarly communication in an age of digitization. When computers become involved and researchers want to allow other scientists to inspect, understand, evaluate, and build on their work, they need to create a research compendium that includes the code, data, computing environment, and script-based workflows used. Here, we present the state of the art for approaches to reach this degree of computational reproducibility, addressing literate programming and containerization while paying attention to working with geospatial data (digital maps, geographic information systems). We argue that all researchers working with computers should understand these technologies to control their computing environment, and we present the benefits of reproducible workflows in practice. Example research compendia illustrate the presented concepts and are the basis for challenges specific to geography and geosciences. Based on existing surveys and best practices from different scientific domains, we conclude that researchers today can overcome many barriers and achieve a very high degree of reproducibility. If the geography and geosciences communities adopt reproducibility and the underlying technologies in practice and in policies, they can transform the way researchers conduct and communicate their work toward increased transparency, understandability, openness, trust, productivity, and innovation. \textcopyright{} 2020 by American Association of Geographers.},
  affiliation = {Institute for Geoinformatics, University of M\"unster, Germany},
  author_keywords = {computational reproducibility; reproducible research; scholarly communication},
  document_type = {Article},
  language = {English},
  source = {Scopus}
}

@book{nustRockerversePackagesApplications2020,
  title = {The {{Rockerverse}}: {{Packages}} and {{Applications}} for {{Containerization}} with {{R}}},
  author = {N{\"u}st, Daniel and Eddelbuettel, Dirk and Bennett, Dom and Cannoodt, Robrecht and Clark, Dav and Dar{\'o}czi, Gergely and Edmondson, Mark and Fay, Colin and Hughes, Ellis and Lopp, Sean and Marwick, Ben and Nolis, Heather and Nolis, Jacqueline and Ooi, Hong and Ram, Karthik and Ross, Noam and Shepherd, Lori and Turaga, Nitesh and Willis, Craig and Petegem, Charlotte},
  year = {2020},
  month = jan,
  abstract = {The Rocker Project provides widely-used Docker images for R across different application scenarios. This articles surveys downstream projects building upon Rocker and presents the current state of R packages for managing Docker images and controlling containers. These use cases and the variety of applications demonstrate the power of Rocker specifically and containerisation in general. We identified common themes across this diversity: reproducible environments, scalability and efficiency, and portability across clouds.}
}

@article{obelsAnalysisOpenData2020,
  title = {Analysis of {{Open Data}} and {{Computational Reproducibility}} in {{Registered Reports}} in {{Psychology}}},
  author = {Obels, Pepijn and Lakens, Dani{\"e}l and Coles, Nicholas and Gottfried, Jaroslav and Green, Seth},
  year = {2020},
  month = may,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {3},
  pages = {251524592091887},
  doi = {10/gg4vw4},
  abstract = {Ongoing technological developments have made it easier than ever before for scientists to share their data, materials, and analysis code. Sharing data and analysis code makes it easier for other researchers to reuse or check published research. However, these benefits will emerge only if researchers can reproduce the analyses reported in published articles and if data are annotated well enough so that it is clear what all variable and value labels mean. Because most researchers are not trained in computational reproducibility, it is important to evaluate current practices to identify those that can be improved. We examined data and code sharing for Registered Reports published in the psychological literature from 2014 to 2018 and attempted to independently computationally reproduce the main results in each article. Of the 62 articles that met our inclusion criteria, 41 had data available, and 37 had analysis scripts available. Both data and code for 36 of the articles were shared. We could run the scripts for 31 analyses, and we reproduced the main results for 21 articles. Although the percentage of articles for which both data and code were shared (36 out of 62, or 58\%) and the percentage of articles for which main results could be computationally reproduced (21 out of 36, or 58\%) were relatively high compared with the percentages found in other studies, there is clear room for improvement. We provide practical recommendations based on our observations and cite examples of good research practices in the studies whose main results we reproduced.},
  file = {/Users/awwillc/Zotero/storage/H84XYKXR/Obels et al. - 2020 - Analysis of Open Data and Computational Reproducib.pdf}
}

@misc{OpenSourceFramework,
  title = {An {{Open Source Framework}} for {{Interactive}}, {{Collaborative}} and {{Reproducible Scientific Computing}} and {{EducationOpen Source Tools}} for {{Interactive}}, {{Collaborative}} and {{Reproducible Computing}}},
  howpublished = {https://ipython.org/\_static/sloangrant/sloan-grant.html},
  file = {/Users/awwillc/Zotero/storage/VULW5GNM/sloan-grant.html}
}

@article{parkerOpinionatedAnalysisDevelopment2017,
  title = {Opinionated Analysis Development},
  author = {Parker, Hilary},
  year = {2017},
  month = aug,
  journal = {PeerJ Preprints},
  volume = {5},
  pages = {e3210v1},
  issn = {2167-9843},
  doi = {10/gfc5jx},
  abstract = {Traditionally, statistical training has focused primarily on mathematical derivations and proofs of statistical tests. The process of developing the technical artifact\textemdash that is, the paper, dashboard, or other deliverable\textemdash is much less frequently taught, presumably because of an aversion to cookbookery or prescribing specific software choices. In this paper I argue that it's critical to teach analysts how to go about developing an analysis in order to maximize the probability that their analysis is reproducible, accurate, and collaborative. A critical component of this is adopting a blameless postmortem culture. By encouraging the use of and fluency in tooling that implements these opinions, as well as a blameless way of correcting course as analysts encounter errors, we as a community can foster the growth of processes that fail the practitioners as infrequently as possible.},
  keywords = {blameless postmortems,data science,opinionated software,python,reproducibility,rstats,software engineering,statistics}
}

@book{pearsonElicitingGroupJudgements2021,
  title = {Eliciting Group Judgements about Replicability: A Technical Implementation of the {{IDEA Protocol}}},
  shorttitle = {Eliciting Group Judgements about Replicability},
  author = {Pearson, Ross and Fraser, Hannah and Bush, Martin and Mody, Fallon and Widjaja, Ivo and Head, Andy and Wilkinson, David Peter and Sinnott, Richard and Wintle, Bonnie and Burgman, Mark and Fidler, Fiona and Vesk, Peter},
  year = {2021},
  month = jan,
  pages = {461},
  abstract = {In recent years there has been increased interest in replicating prior research. One of the biggest challenges to assessing replicability is the cost in resources and time that it takes to repeat studies. Thus there is an impetus to develop rapid elicitation protocols that can, in a practical manner, estimate the likelihood that research findings will successfully replicate. We employ a novel implementation of the IDEA (`Investigate', `Discuss', `Estimate' and `Aggregate) protocol, realised through the repliCATS platform. The repliCATS platform is designed to scalably elicit expert opinion about replicability of social and behavioural science research. The IDEA protocol provides a structured methodology for eliciting judgements and reasoning from groups.  This paper describes the repliCATS platform as a multi-user cloud-based software platform featuring (1) a technical implementation of the IDEA protocol for eliciting expert opinion on research replicability, (2) capture of consent and demographic data, (3) on-line training on replication concepts, and (4) exporting of completed judgements. The platform has, to date, evaluated 3432 social and behavioural science research claims from 637 participants.},
  copyright = {Attribution-NonCommercial-NoDerivatives 4.0 International},
  isbn = {978-0-9981331-4-0},
  language = {English},
  annotation = {Accepted: 2020-12-24T19:03:41Z},
  file = {/Users/awwillc/Zotero/storage/GX2N2ZRK/Pearson et al. - 2021 - Eliciting group judgements about replicability a .pdf}
}

@article{Peer2021,
  title = {Active Maintenance: {{A}} Proposal for the Long-Term Computational Reproducibility of Scientific Results},
  author = {Peer, L. and Orr, L.V. and Coppock, A.},
  year = {2021},
  journal = {PS - Political Science and Politics},
  publisher = {{Cambridge University Press}},
  issn = {10490965},
  doi = {10.1017/s1049096521000366},
  abbrev_source_title = {PS Polit. Sci. Polit.},
  abstract = {Computational reproducibility, or the ability to reproduce analytic results of a scientific study on the basis of publicly available code and data, is a shared goal of many researchers, journals, and scientific communities. Researchers in many disciplines including political science have made strides toward realizing that goal. A new challenge, however, has arisen. Code too often becomes obsolete within only a few years. We document this problem with a random sample of studies posted to the Institution for Social and Policy Studies (ISPS) Data Archive; we encountered nontrivial errors in seven of 20 studies. In line with similar proposals for the long-term maintenance of data and commercial software, we propose that researchers dedicated to computational reproducibility should have a plan in place for "active maintenance"of their analysis code. We offer concrete suggestions for how data archives, journals, and research communities could encourage and reward the active maintenance of scientific code and data. \textcopyright{} The Author(s), 2021. Published by Cambridge University Press on behalf of the American Political Science Association.},
  affiliation = {Yale University, United States},
  document_type = {Article},
  language = {English},
  source = {Scopus},
  file = {/Users/awwillc/Zotero/storage/3XXSTJ7H/Peer et al. - 2021 - Active maintenance A proposal for the long-term c.pdf}
}

@techreport{peikertReproducibleDataAnalysis2019,
  title = {A {{Reproducible Data Analysis Workflow}} with {{R Markdown}}, {{Git}}, {{Make}}, and {{Docker}}},
  author = {Peikert, Aaron and Brandmaier, Andreas Markus},
  year = {2019},
  month = nov,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/8xzqy},
  abstract = {In this tutorial, we describe a workflow to ensure long-term reproducibility of R-based data analyses. The workflow leverages established tools and practices from software engineering. It combines the benefits of various open-source software tools including R Markdown, Git, Make, and Docker, whose interplay ensures seamless integration of version management, dynamic report generation conforming to various journal styles, and full cross-platform and long-term computational reproducibility. The workflow ensures meeting the primary goals that 1) the reporting of statistical results is consistent with the actual statistical results (dynamic report generation), 2) the analysis exactly reproduces at a later point in time even if the computing platform or software is changed (computational reproducibility), and 3) changes at any time (during development and post-publication) are tracked, tagged, and documented while earlier versions of both data and code remain accessible. While the research community increasingly recognizes dynamic document generation and version management as tools to ensure reproducibility, we demonstrate with practical examples that these alone are not sufficient to ensure long-term computational reproducibility. Combining containerization, dependence management, version management, and dynamic document generation, the proposed workflow increases scientific productivity by facilitating later reproducibility and reuse of code and data.},
  keywords = {containerization,dependency management,literate programming,Meta-science,open science,Quantitative Methods,R,reproducibility,Social and Behavioral Sciences,Statistical Methods,Theory and Philosophy of Science,version management},
  file = {/Users/awwillc/Zotero/storage/B9BWLKYX/Peikert and Brandmaier - 2019 - A Reproducible Data Analysis Workflow with R Markd.pdf}
}

@article{pengReproducibleResearchComputational2011,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  year = {2011},
  month = dec,
  journal = {Science},
  volume = {334},
  number = {6060},
  pages = {1226},
  doi = {10/fdv356},
  abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
  keywords = {Astronomical surveys,Cognition,Computer programming,Computer software,Datasets,Field research,Instructional materials,Observational research,Primates,Problem solving},
  annotation = {mlzsync1:0083\{"extrafields":\{"publisher":"American Association for the Advancement of Science"\}\}tex.ids: rogerd.pengReproducibleResearchComputational2011 QID: Q27921795},
  file = {/Users/awwillc/Zotero/storage/EAQV43M4/Peng - 2011 - Reproducible Research in Computational Science.pdf}
}

@article{piccoloToolsTechniquesComputational2016,
  title = {Tools and Techniques for Computational Reproducibility.},
  author = {Piccolo, Stephen R and Frampton, Michael B},
  year = {2016},
  month = jul,
  journal = {GigaScience},
  volume = {5},
  number = {1},
  pages = {30},
  issn = {2047-217X},
  doi = {10/gfs3cq},
  abstract = {When reporting research findings, scientists document the steps they followed so that others can verify and build upon the research. When those steps have been described in sufficient detail that others can retrace the steps and obtain similar results, the research is said to be reproducible. Computers play a vital role in many research disciplines and present both opportunities and challenges for reproducibility. Computers can be programmed to execute analysis tasks, and those programs can be repeated and shared with others. The deterministic nature of most computer programs means that the same analysis tasks, applied to the same data, will often produce the same outputs. However, in practice, computational findings often cannot be reproduced because of complexities in how software is packaged, installed, and executed-and because of limitations associated with how scientists document analysis steps. Many tools and techniques are available to help overcome these challenges; here we describe seven such strategies. With a broad scientific audience in mind, we describe the strengths and limitations of each approach, as well as the circumstances under which each might be applied. No single strategy is sufficient for every scenario; thus we emphasize that it is often useful to combine approaches.},
  keywords = {Computational Biology/*methods,Computational reproducibility*,Literate programming*,Practice of science*,Reproducibility of Results,Research Design,Software,Software containers*,Software frameworks*,Virtualization*},
  annotation = {mlzsync1:0079\{"extrafields":\{"place":"United States","publisher":"Oxford University Press"\}\} QID: Q29002201},
  file = {/Users/awwillc/Zotero/storage/GNZ9VCDU/Piccolo and Frampton - 2016 - Tools and techniques for computational reproducibi.pdf}
}

@book{pirroAgileManagementPhD2019,
  title = {Agile Management of {{PhD}} Projects: A Risk-Mitigation Tool for Graduate Education},
  author = {Pirro, Laura and Thybaut, Joris and Montero Carrero, Marina and Contino, Francesco},
  year = {2019},
  month = nov,
  file = {/Users/awwillc/Zotero/storage/WZY48RVB/Pirro et al. - 2019 - Agile management of PhD projects a risk-mitigatio.pdf}
}

@book{pirroAgileManagementPhD2019a,
  title = {Agile Management of {{PhD}} Projects: A Risk-Mitigation Tool for Graduate Education},
  author = {Pirro, Laura and Thybaut, Joris and Montero Carrero, Marina and Contino, Francesco},
  year = {2019},
  month = nov
}

@article{potdarPerformanceEvaluationDocker2020,
  title = {Performance {{Evaluation}} of {{Docker Container}} and {{Virtual Machine}}},
  author = {Potdar, Amit M and D G, Narayan and Kengond, Shivaraj and Mulla, Mohammed Moin},
  year = {2020/01/01/January 2020///},
  journal = {Procedia Computer Science},
  volume = {171},
  pages = {1419--1428},
  issn = {1877-0509},
  doi = {10/ghkb9c},
  abstract = {Server virtualization is a technological innovation broadly used in IT enterprises. Virtualization provides a platform to run different services of operating systems on the cloud. It facilitates to build multiple virtual machines on a single basic physical machine either in the form of hypervisors or containers. To host many microservice applications, the emergent technology has introduced a model which consists of different operations performed by smaller individual deployed services. Thus, the demand for low-overhead virtualization technique is rapidly developing. There are many lightweight virtualization technologies; docker is one among them, which is an open-source platform. This technology allows developers and system admins to build, create, and run applications using docker engine. This paper provides the performance evaluation of Docker containers and virtual machines using standard benchmark tools such as Sysbench, Phoronix, and Apache benchmark, which include CPU performance, Memory throughput, Storage read/write performance, load test, and operation speed measurement.},
  keywords = {Benchmark tools,Docker Container,Virtual Machine,Virtualization},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Elsevier B.V."\}\}}
}

@article{pouchardComputationalReproducibilityScientific2019,
  title = {Computational Reproducibility of Scientific Workflows at Extreme Scales},
  author = {Pouchard, Line and Baldwin, Sterling and Elsethagen, Todd and Jha, Shantenu and Raju, Bibi and Stephan, Eric and Tang, Li and Van Dam, Kerstin Kleese},
  year = {2019},
  month = sep,
  journal = {INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS},
  volume = {33},
  number = {5},
  pages = {763--776},
  issn = {10943420},
  doi = {10/ggfp8j},
  keywords = {Chimbuko,Computational reproducibility,performance analysis,ProvEn,provenance,scientific workflows},
  file = {/Users/awwillc/Zotero/storage/P7ACKY27/Pouchard et al. - 2019 - Computational reproducibility of scientific workfl.pdf}
}

@article{powersOpenScienceReproducibility2019,
  title = {Open Science, Reproducibility, and Transparency in Ecology.},
  author = {Powers, Stephen M and Hampton, Stephanie E},
  year = {2019},
  month = jan,
  journal = {Ecological applications : a publication of the Ecological Society of America},
  volume = {29},
  number = {1},
  pages = {e01822},
  issn = {1051-0761},
  doi = {10/gfs56x},
  abstract = {Reproducibility is a key tenet of the scientific process that dictates the reliability and generality of results and methods. The complexities of ecological observations and data present novel challenges in satisfying needs for reproducibility and also transparency. Ecological systems are dynamic and heterogeneous, interacting with numerous factors that sculpt natural history and that investigators cannot completely control. Observations may be highly dependent on spatial and temporal context, making them very difficult to reproduce, but computational reproducibility can still be achieved. Computational reproducibility often refers to the ability to produce equivalent analytical outcomes from the same data set using the same code and software as the original study. When coded workflows are shared, authors and editors provide transparency for readers and allow other researchers to build directly and efficiently on primary work. These qualities may be especially important in ecological applications that have important or controversial implications for science, management, and policy. Expectations for computational reproducibility and transparency are shifting rapidly in the sciences. In this work, we highlight many of the unique challenges for ecology along with practical guidelines for reproducibility and transparency, as ecologists continue to participate in the stewardship of critical environmental information and ensure that research methods demonstrate integrity. (\textcopyright{} 2018 The Authors. Ecological Applications published by Wiley Periodicals, Inc. on behalf of Ecological Society of America.)},
  keywords = {collaborative tools*,data policy*,data science*,ecoinformatics*,Ecology*,ecosystem*,environmental science*,open science*,repeatability*,replicability*,Reproducibility of Results,reproducible*,Research Design,Software*,transparent*,workflows*},
  annotation = {mlzsync1:0085\{"extrafields":\{"place":"United States","publisher":"Ecological Society of America"\}\} QID: Q58555099},
  file = {/Users/awwillc/Zotero/storage/JV2ZKLJ7/Powers and Hampton - 2019 - Open science, reproducibility, and transparency in.pdf}
}

@inproceedings{punjabiUserStoriesUser2016,
  title = {User Stories to User Reality: {{A DevOps}} Approach for the Cloud},
  author = {Punjabi, Rahul and Bajaj, Ruhi},
  year = {2016},
  month = may,
  pages = {662},
  doi = {10.1109/RTEICT.2016.7807905},
  abstract = {The `DevOps' phenomenon that advocates a collaborative and unified method for delivering software, has been gaining tremendous attention from various sectors of the IT industry with organizations adopting this movement exhibiting significant growth in performance. It can be challenging for an organization to commence their DevOps journey owing to the abundant and diverse resources available. There is a need to have an all-inclusive picture of DevOps and how its related concepts can be leveraged to improve delivery of software applications to end-users while enhancing quality and reducing lead time. This paper strives to bring insight into the practices associated with DevOps. An end-to-end solution is provided through an integrated toolchain and a customizable workflow. The role of Docker containers is considered in the context of extending infrastructure provisioning capability of the workflow. In a bid to accelerate delivery and improve testability of applications, a framework to automate Model-View-Controller architectures has been proposed. Through these processes, the cyclical journey of an application is traced from `User Stories' to a running state \textemdash{} `User Reality' on the cloud.}
}

@article{punjabiUserStoriesUser2016a,
  title = {User Stories to User Reality: {{A DevOps}} Approach for the Cloud},
  author = {Punjabi, Rahul and Bajaj, Ruhi},
  year = {2016},
  month = may,
  journal = {2016 IEEE International Conference on Recent Trends in Electronics, Information \& Communication Technology (RTEICT), Recent Trends in Electronics, Information \& Communication Technology (RTEICT), IEEE International Conference on},
  pages = {658--662},
  issn = {978-1-5090-0774-5},
  doi = {10/ghkb9d},
  abstract = {The `DevOps' phenomenon that advocates a collaborative and unified method for delivering software, has been gaining tremendous attention from various sectors of the IT industry with organizations adopting this movement exhibiting significant growth in performance. It can be challenging for an organization to commence their DevOps journey owing to the abundant and diverse resources available. There is a need to have an all-inclusive picture of DevOps and how its related concepts can be leveraged to improve delivery of software applications to end-users while enhancing quality and reducing lead time. This paper strives to bring insight into the practices associated with DevOps. An end-to-end solution is provided through an integrated toolchain and a customizable workflow. The role of Docker containers is considered in the context of extending infrastructure provisioning capability of the workflow. In a bid to accelerate delivery and improve testability of applications, a framework to automate Model-View-Controller architectures has been proposed. Through these processes, the cyclical journey of an application is traced from `User Stories' to a running state \textemdash{} `User Reality' on the cloud.},
  keywords = {Application Lifecycle Management,Automation,Collaboration,Communication; Networking and Broadcast Technologies,Components; Circuits; Devices and Systems,Computing and Processing,Containers,Continuous Delivery,DevOps,Engineering Profession,Navigation,Photonics and Electrooptics,Power; Energy and Industry Applications,Production,Robotics and Control Systems,Servers,Signal Processing and Analysis,Software Engineering,Testing},
  annotation = {mlzsync1:0036\{"extrafields":\{"publisher":"IEEE"\}\}},
  file = {/Users/awwillc/Zotero/storage/HIX3XELN/Punjabi and Bajaj - 2016 - User stories to user reality A DevOps approach fo.pdf}
}

@article{qashaSharingPerformanceOptimization2019,
  title = {Sharing and Performance Optimization of Reproducible Workflows in the Cloud},
  author = {Qasha, Rawaa and Wen, Zhenyu and Ca{\l}a, Jacek and Watson, Paul},
  year = {2019/09/01/September 2019///},
  journal = {Future Generation Computer Systems},
  volume = {98},
  pages = {487--502},
  issn = {0167-739X},
  doi = {10/ggqfkb},
  abstract = {Scientific workflows play a vital role in modern science as they enable scientists to specify, share and reuse computational experiments. To maximizethe benefits, workflows need to support the reproducibility of the experimental methods they capture. Reproducibility enables effective sharing as scientists can re-execute experiments developed by others and quickly derive new or improved results. However, achieving reproducibility in practice is problematic \textemdash ~previous analyses highlight issues due to uncontrolled changes in the input data, configuration parameters, workflow description and the software used to implement the workflow tasks. The resulting problems have become known as workflow decay.In this paper we present a novel framework that addresses workflow decay through the integration of system description, version control, container management and automated deployment techniques. It then introduces a set of performance optimization techniques that significantly reduce the runtime overheads caused by making workflows reproducible. The resulting system significantly improves the performance, repeatability and also the ability to share and re-use workflows by combining a method to uniquely identify task and workflow images with an automated image capture facility and a multi-level cache.The system is evaluated through an extensive set of experiments that validate the approach and highlight the key benefits of the proposed optimizations. This includes methods for reducing the runtime of workflows by up to an order of magnitude in cases where they are enacted concurrently on the same host VM and in different Clouds, and where they share tasks.},
  keywords = {Cloud computing,Container-based virtualization,Provisioning optimization,Workflow deployment,Workflow reproducibility},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Elsevier B.V."\}\}}
}

@misc{QualitativeStudyDevOps,
  title = {A {{Qualitative Study}} of {{DevOps Usage}} in {{Practice}}},
  journal = {ResearchGate},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/316879884\_A\_Qualitative\_Study\_of\_DevOps\_Usage\_in\_Practice?amp\%3BenrichSource=Y292ZXJQYWdlOzMxNjg3OTg4NDtBUzo1OTM0MDMzNTE5Mjg4MzJAMTUxODQ4OTc5MjcyOQ\%3D\%3D\&amp\%3Bel=1\_x\_2\&amp\%3B\_esc=publicationCoverPdf},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/43UKA63A/316879884_A_Qualitative_Study_of_DevOps_Usage_in_Practice.html}
}

@article{rahmanSystematicMappingStudy2019,
  title = {A Systematic Mapping Study of Infrastructure as Code Research},
  author = {Rahman, Akond and {Mahdavi-Hezaveh}, Rezvan and Williams, Laurie},
  year = {2019},
  month = apr,
  journal = {Information and Software Technology},
  volume = {108},
  pages = {65--77},
  issn = {0950-5849},
  doi = {10/ggs8t8},
  abstract = {Context: Infrastructure as code (IaC) is the practice to automatically configure system dependencies and to provision local and remote instances. Practitioners consider IaC as a fundamental pillar to implement DevOps practices, which helps them to rapidly deliver software and services to end-users. Information technology (IT) organizations, such as GitHub, Mozilla, Facebook, Google and Netflix have adopted IaC. A systematic mapping study on existing IaC research can help researchers to identify potential research areas related to IaC, for example defects and security flaws that may occur in IaC scripts. Objective: The objective of this paper is to help researchers identify research areas related to infrastructure as code (IaC) by conducting a systematic mapping study of IaC-related research. Method: We conduct our research study by searching five scholar databases. We collect a set of 31,498 publications by using seven search strings. By systematically applying inclusion and exclusion criteria, which includes removing duplicates and removing non-English and non peer-reviewed publications, we identify 32 publications related to IaC. We identify topics addressed in these publications by applying qualitative analysis. Results: We identify four topics studied in IaC-related publications: (i) framework/tool for infrastructure as code; (ii) adoption of infrastructure as code; (iii) empirical study related to infrastructure as code; and (iv) testing in infrastructure as code. According to our analysis, 50.0\% of the studied 32 publications propose a framework or tool to implement the practice of IaC or extend the functionality of an existing IaC tool. Conclusion: Our findings suggest that framework or tools is a well-studied topic in IaC research. As defects and security flaws can have serious consequences for the deployment and development environments in DevOps, we observe the need for research studies that will study defects and security flaws for IaC.},
  keywords = {Configuration as code,Configuration script,Continuous deployment,Devops,Infrastructure as code,Software engineering,Systematic mapping study},
  file = {/Users/awwillc/Zotero/storage/AWYE6EDP/Rahman et al. - 2019 - A systematic mapping study of infrastructure as co.pdf}
}

@inproceedings{reyPackagingDevelopmentUsing2019,
  title = {R Packaging Development Using {{GitLab CI}}/{{CD}}},
  booktitle = {{{useR}}! 2019},
  author = {Rey, Jean-Fran{\c c}ois and Houde, Lo{\"i}c},
  year = {2019},
  month = jul,
  pages = {1 p.},
  publisher = {{Institut National de la Recherche Agronomique (INRA). FRA.}},
  address = {{Toulouse, France}},
  abstract = {Nowadays computer project management tools are widely widespread, many of them provide a specific part of project life cycle management or are thirdparties solutions. Here we introduce GitLab CE (Community Edition), an open core, free and full solution to manage R packages developments, delivery and many more. We focus in its Continuous Integration and Delivery pipeline part, using Docker and VirtualBox, for R packaging. This local solution uses in our laboratory allows us to develop R codes in a collaborative mode and to automate R packages checking and building. This process allows us to share private and/or in development R packages on multiples OS and to accelerate CRAN submission by decreasing checking error.},
  keywords = {automation,automatisation,CI/CD,Docker,gestion de projet,GitLab,informatique de gestion,logiciel libre,open ource software,Package,plateforme collaborative,project management,Virtualbox},
  file = {/Users/awwillc/Zotero/storage/J4GEGPZ7/Rey and Houde - 2019 - R packaging development using GitLab CICD.pdf}
}

@book{riasetiawanScienceForgeCollaborativeScientific2010,
  title = {Science-{{Forge}}: {{A}} Collaborative Scientific Framework},
  author = {Riasetiawan, Mardhani and Mahmood, Ahmad Kamil},
  year = {2010},
  month = nov,
  pages = {668},
  doi = {10.1109/ISIEA.2010.5679381},
  abstract = {Scientific work now facing the needs on dynamic scientific data. Scientific data need to be interactive, reproducible, collaborative, and dynamic and have the reputation and influences. The common collaborative framework such as cloud and semantic technologies has being give influences to the scientific data. The development of new framework is compete with the needs of multidisciplinary research, the exploding of digital universe, the industry needs on long-term use and access, and some issues in next generation data, such as data integration, annotation, provenance and security. In this research, we introduced Science-Forge, the scientific collaboration framework that addresses the issues in dynamic scientific data and tools. The framework inspired by GForge system that enabled software developer to share and collaborate in software development. We build the scientific preservation based on GForge system, and implementing several data process. The framework has capabilities to handling data collection, data processing. The research aimed is to establishment of the new framework for scientific collaboration works.},
  file = {/Users/awwillc/Zotero/storage/Y42VHX4Z/Riasetiawan and Mahmood - 2010 - Science-Forge A collaborative scientific framewor.pdf}
}

@article{robertgentlemanStatisticalAnalysesReproducible2007,
  title = {Statistical {{Analyses}} and {{Reproducible Research}}},
  author = {{Robert Gentleman} and {Duncan Temple Lang}},
  year = {2007},
  journal = {Journal of Computational and Graphical Statistics},
  volume = {16},
  number = {1},
  pages = {1},
  issn = {10618600},
  doi = {10/b8f7nn},
  abstract = {It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them. This integration allows readers to both verify and adapt the claims in the documents. Authors can easily reproduce the results in the future, and they can present the document's contents in a different medium, for example, with interactive controls. This article describes a software framework for both authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents\textemdash including figures, tables, and so on\textemdash can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or "source" document from which one can generate different views in the form of traditional, derived documents for different audiences. We introduce the concept of a compendium as a container for one or more dynamic documents and the different elements needed when processing them, such as code and data. The compendium serves as a means for distributing, managing, and updating the collection. The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. Some of the issues involved in paradigms for the production, distribution, and use of such reproducible research are discussed.},
  keywords = {Archives,Compendium,Computational statistics,Computer programming,Computer software,Data analysis,Dynamic documents,Literate programming,Markup language,Markups,Perl,Programming languages,Python,R,Research methods,Software development tools,XML},
  annotation = {mlzsync1:0145\{"extrafields":\{"publisher":"American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America"\}\}},
  file = {/Users/awwillc/Zotero/storage/5XMAV2T4/Robert Gentleman and Duncan Temple Lang - 2007 - Statistical Analyses and Reproducible Research.pdf}
}

@incollection{russoBenefitsOpenSource2016,
  title = {Benefits of {{Open Source Software}} in {{Defense Environments}}},
  author = {Russo, Daniel},
  year = {2016},
  month = jan,
  volume = {422},
  pages = {123--131},
  doi = {10.1007/978-3-319-27896-4_11},
  abstract = {Even though the use of Open Source Software (OSS) might seem paradoxical in Defense environments, this has been proven to be wrong. The use of OSS does not harm security; on the contrary, it enhances it. Even with some drawbacks, OSS is highly reliable and maintained by a huge software community, thus decreasing implementation costs and increasing reliability. Moreover, it allows military software engineers to move away from proprietary applications and single-vendor contracts. Furthermore, it decreases the cost of long-term development and lifecycle management, besides avoiding vendor's lock in. Nevertheless, deploying OSS deserves an appropriate organization of its life cycle and maintenance, which has a relevant impact on the project's budget that cannot be overseen. In this paper, we will describe some of the major trends in OSS in Defense environments. The community for OSS has a pivotal role, since it is the core development unit. With Agile and the newest DevOps methodologies, government officials could leverage OSS capabilities, decreasing the Design (or Technical) Debt. Software for Defense purposes could perform better, increase the number of the releases, enhance coordination through the different IT Departments (and the community), and increase release automation, decreasing the probability of errors.},
  file = {/Users/awwillc/Zotero/storage/NRJNTVPP/Russo - 2016 - Benefits of Open Source Software in Defense Enviro.pdf}
}

@article{saariImplementingNewContinuous2017,
  title = {Implementing New Continuous Integration Tool},
  author = {Saari, M. (Marko)},
  year = {2017},
  month = jun,
  abstract = {This thesis studied the implementation of new Continuous Integration tool by focusing on existing problems and possible arising problems when implementing the new Continuous Integration tool. The thesis supported a project run by one international software development company with the main goal of replacing the current Continuous Integration tool from CruiseControl.NET with some more suitable alternative tool. The purpose of this thesis was to research about the topic and the existing tool to support the project in the implementation of the new Continuous Integration tool.On the literature review, first the current state of Continuous Integration tool in the company was discussed. Then the literature review focused on the research about Continuous Integration, Continuous Delivery and Continuous Deployment. Alternative Continuous Integration tools were also studied as the company had two Continuous Integration tools to choose from: Bamboo and Jenkins.The problems of the current Continuous Integration tool in the company were studied by conducting a survey. This survey was based on existing studies on the problems of Continuous Integration tools. Pilot testing and reviews also had impact on the final survey. 37 people out of the target population (89) participated in the survey. Survey results showed that those 37 people had different background but most of them had a long history in the company. Some participants did not answer all of the questions.Two lists of issues were created by analyzing the survey results: Issues of current Continuous Integration tool and Issues when implementing new Continuous Integration tool. Two biggest issues from the list of issues of the current Continuous Integration tool were Lack of hardware and Build duration. Solution for these is that better hardware solves the Lack of hardware and improves the build duration with better hardware capacity and parallelization. Two biggest issues from the list of issues when implementing new Continuous Integration tool were Resistance to change and Lack of knowledge. The findings from past research suggest that implementing new Continuous Integration tool requires change of work of everyone to actually work. The solution for Lack of knowledge was that training is required for employees to actually know the way of using the new Continuous Integration tool. Suggested solutions were based on existing research and on the survey results.The study provided two lists of Continuous Integration tool problems and proposals for possible solutions for those. The results can be used for selecting Continuous Integration tool as the study compared the results between Bamboo and Jenkins. Comprehensive study on the problems of Continuous Integration tool and the comparison of Continuous Integration tools provided reasoned support for the project of the company.},
  keywords = {⛔ No DOI found,Information Processing Science}
}

@article{sanchez-morcilioOPTIMIZEDAGILETECHNIQUE2018,
  title = {{{AN OPTIMIZED AGILE TECHNIQUE TO EFFECTIVELY IMPLEMENT AGILE METHODS IN PROJECT MANAGEMENT}}: {{A RESEARCH PROPOSITION}}.},
  author = {{S{\'a}nchez-Morcilio}, Rosarito and {Quiles-Torres}, Francisco},
  year = {2018},
  month = apr,
  journal = {Issues in Information Systems},
  volume = {19},
  number = {2},
  pages = {119--131},
  issn = {15297314},
  abstract = {Discerning the most relevant information about agile project management can become overwhelming since there is plenty of material available. This study provides a synthesis of the literature review to find out guidance on how to implement agile methodologies to manage projects adequately. An optimized agile technique (OAT) is proposed for achieving agile methodologies to successful project management. OAT suggests selecting the right agile tools, authenticating quality to create a value-added outcome for customers, and establishing frequent targeted meetings among working teams, as communication is still the principal success factor in project management, especially in agile environments. [ABSTRACT FROM AUTHOR]},
  keywords = {⛔ No DOI found,Agile methodologies,agile optimization,agile technique,COMPUTER software development,LITERATURE reviews,Project Management,PROJECT management,Software Development}
}

@inproceedings{sandbergMeetingIndustryacademiaResearch2017,
  title = {Meeting Industry-Academia Research Collaboration Challenges with Agile Methodologies},
  booktitle = {Proceedings - 2017 {{IEEE}}/{{ACM}} 39th {{International Conference}} on {{Software Engineering}}: {{Software Engineering}} in {{Practice Track}}, {{ICSE}}-{{SEIP}} 2017},
  author = {Sandberg, A.B. and Crnkovic, I.},
  year = {2017},
  pages = {73--82},
  doi = {10/gbvrpp},
  abstract = {Continuous and long-term collaboration between industry and academia is crucial to develop front-line research in context-dependent areas like software development where both practitioners and researchers are searched for data collection, analysis and results. Despite many mutual benefits, this collaboration is often challenging, not only due to different goals, but also because of different pace in providing the results. The software development industry has during the last decade aligned around and organized their development adopting agile methodologies. For the researchers, the agile methodologies are a topic for a research, rather than a means of performing the research itself. We can state a question, whether the agile methodologies can be a good common ground for enabling successful research collaboration between industry and academia? This paper reports on a longitudinal industry - academia research collaboration case, which has stepwise adapted SCRUM over a six-year period. The implementation of SCRUM and the collaboration successes and challenges are presented, and findings are discussed. \textcopyright{} 2017 IEEE.},
  keywords = {agile methodologies,case study,collaboration,industry-academia research},
  file = {/Users/awwillc/Zotero/storage/UUV3FF5J/Sandberg and Crnkovic - 2017 - Meeting industry-academia research collaboration c.pdf}
}

@article{santiago-duranGearboxModelProcessing2020,
  title = {A Gearbox Model for Processing Large Volumes of Data by Using Pipeline Systems Encapsulated into Virtual Containers},
  author = {{Santiago-Duran}, Miguel and {Gonzalez-Compean}, J.L. and Brinkmann, Andr{\'e} and {Reyes-Anastacio}, Hugo G. and Carretero, Jesus and Montella, Raffaele and Toscano Pulido, Gregorio},
  year = {2020/05/01/May 2020///},
  journal = {Future Generation Computer Systems},
  volume = {106},
  pages = {304--319},
  issn = {0167-739X},
  doi = {10/ghkb8r},
  abstract = {Software pipelines enable organizations to chain applications for adding value to contents (e.g., confidentially, reliability, and integrity) before either sharing them with partners or sending them to the cloud. However, the pipeline components add overhead when processing large volumes of data, which can become critical in real-world scenarios. This paper presents a gearbox model for processing large volumes of data by using pipeline systems encapsulated into virtual containers. In this model, the gears represent applications, whereas gearboxes represent software pipelines. This model was implemented as a collaborative system that automatically performs Gear up (by using parallel patterns) and/or Gear down (by using in-memory storage) until all gears produce uniform data processing velocities. This model reduces delays and bottlenecks produced by the heterogeneous performance of applications included in software pipelines. The new container tool capsule has been designed to encapsulate both the collaborative system and the software pipelines into a virtual container and deploy it on IT infrastructures. We conducted case studies to evaluate the performance of capsule when processing medical images and PDF repositories. The incorporation of a capsule to a cloud storage service for pre-processing medical imagery was also studied. The experimental evaluation revealed the feasibility of applying the gearbox model to the deployment of software pipelines in real-world scenarios as it can significantly improve the end-user service experience when pre-processing large-scale data in comparison with state-of-the-art solutions such as Sacbe and Parsl.},
  keywords = {Cloud storage,Continuous delivery,In-memory storage,Parallel patterns,Software pipelines,Virtual containers},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Elsevier B.V."\}\}}
}

@article{sarafoglouTeachingGoodResearch2019,
  title = {Teaching {{Good Research Practices}}: {{Protocol}} of a {{Research Master Course}}},
  author = {Sarafoglou, Alexandra and Hoogeveen, Suzanne and Matzke, Dora and Wagenmakers, Eric-Jan},
  year = {2019},
  month = jul,
  journal = {Psychology Learning \& Teaching},
  volume = {19},
  number = {1},
  pages = {46--59},
  publisher = {{SAGE Publications}},
  issn = {1475-7257},
  doi = {10/gf4wtz},
  abstract = {The current crisis of confidence in psychological science has spurred on field-wide reforms to enhance transparency, reproducibility, and replicability. To solidify these reforms within the scientific community, student courses on open science practices are essential. Here we describe the content of our Research Master course ?Good Research Practices? which we have designed and taught at the University of Amsterdam. Supported by Chambers? recent book The 7 Deadly Sins of Psychology, the course covered topics such as QRPs, the importance of direct and conceptual replication studies, preregistration, and the public sharing of data, code, and analysis plans. We adopted a pedagogical approach that: (a) reduced teacher-centered lectures to a minimum; (b) emphasized practical training on open science practices; and (c) encouraged students to engage in the ongoing discussions in the open science community on social media platforms.},
  file = {/Users/awwillc/Zotero/storage/DYZ4IYP2/Sarafoglou et al. - 2019 - Teaching Good Research Practices Protocol of a Re.pdf}
}

@misc{ScienceAmateurSoftware2020,
  title = {Science as {{Amateur Software Development}}},
  year = {2020},
  month = sep,
  abstract = {Science is one of humanity's greatest inventions. Academia, on the other hand, is not. It is remarkable how successful science has been, given the often chaotic habits of scientists. In contrast to other fields, like say landscaping or software engineering, science as a profession is largely *unprofessional*\textemdash apprentice scientists are taught less about how to work responsibly than about how to earn promotions. This results in ubiquitous and costly errors. Software development has become indispensable to scientific work. I want to playfully ask how it can become even more useful by transferring some aspects of its professionalism, the day-to-day tracking and back-tracking and testing that is especially part of distributed, open-source software development. Science, after all, aspires to be distributed, open-source knowledge development.}
}

@article{ScientificWorkflowsComputational2017,
  title = {Scientific Workflows for Computational Reproducibility in the Life Sciences: {{Status}}, Challenges and Opportunities},
  year = {2017},
  journal = {Future Generation Computer Systems},
  pages = {284},
  issn = {0167-739X},
  doi = {10/ggb87f},
  abstract = {With the development of new experimental technologies, biologists are faced with an avalanche of data to be computationally analyzed for scientific advancements and discoveries to emerge. Faced with the complexity of analysis pipelines, the large number of computational tools, and the enormous amount of data to manage, there is compelling evidence that many if not most scientific discoveries will not stand the test of time: increasing the reproducibility of computed results is of paramount importance.},
  keywords = {Workflow software},
  annotation = {mlzsync1:0045\{"extrafields":\{"publisher":"Elsevier B.V."\}\} QID: Q57971792},
  file = {/Users/awwillc/Zotero/storage/7RJWBN2C/2017 - Scientific workflows for computational reproducibi.pdf}
}

@article{Sequeira2021,
  title = {A Standardisation Framework for Bio-logging Data to Advance Ecological Research and Conservation},
  author = {et al. Sequeira, Ana M. M.},
  year = {2021},
  journal = {Methods in Ecology and Evolution},
  volume = {12},
  number = {6},
  pages = {996--1007},
  doi = {10.1111/2041-210x.13593},
  file = {/Users/awwillc/Zotero/storage/NZGKKKLY/Sequeira - 2021 - A standardisation framework for bio‐logging data t.pdf}
}

@article{shahinContinuousIntegrationDelivery2017,
  title = {Continuous {{Integration}}, {{Delivery}} and {{Deployment}}: {{A Systematic Review}} on {{Approaches}}, {{Tools}}, {{Challenges}} and {{Practices}}},
  author = {Shahin, Mojtaba and Babar, Muhammad Ali and Zhu, Liming},
  year = {2017},
  journal = {IEEE ACCESS},
  volume = {5},
  pages = {3909--3943},
  issn = {21693536},
  doi = {10/gg2bwd},
  keywords = {continuous delivery,continuous deployment,Continuous integration,continuous software engineering,empirical software engineering,systematic literature review},
  annotation = {QID: Q57277797},
  file = {/Users/awwillc/Zotero/storage/YGI62M2I/Shahin et al. - 2017 - Continuous Integration, Delivery and Deployment A.pdf}
}

@article{shahinEmpiricalStudyArchitecting2019,
  title = {An Empirical Study of Architecting for Continuous Delivery and Deployment},
  author = {Shahin, Mojtaba and Zahedi, Mansooreh and Babar, Muhammad Ali and Zhu, Liming},
  year = {2019},
  month = jun,
  journal = {EMPIRICAL SOFTWARE ENGINEERING},
  volume = {24},
  number = {3},
  pages = {1061--1108},
  issn = {13823256},
  doi = {10/ghjv3r},
  keywords = {Continuous delivery,Continuous deployment,DevOps,Empirical study,Software architecture},
  file = {/Users/awwillc/Zotero/storage/KZ59YWWQ/Shahin et al. - 2019 - An empirical study of architecting for continuous .pdf}
}

@incollection{siebraEmpoweringContinuousDelivery2019,
  title = {Empowering {{Continuous Delivery}} in {{Software Development}}: {{The DevOps Strategy}}},
  author = {Siebra, Clauirton and Lacerda, Rosberg and Cerqueira, Italo and Quintino, Jonysberg and Florentin, Fabiana and Silva, Fabio and Santos, Andre},
  year = {2019},
  month = aug,
  pages = {247--265},
  doi = {10.1007/978-3-030-29157-0_11},
  abstract = {Continuous Delivery refers to a software development practice where members of a team frequently integrate their work, so that the process of delivery can be easily conducted. However, this continuous integration and delivery requires a reliable collaboration between development and IT operation teams. The DevOps practices support this collaboration since they enable that the operation staff making use of the same infrastructure as developers for their systems work. Our study aims at presenting a practical DevOps implementation and analyzing how the process of software delivery and infrastructure changes was automated. Our approach follows the principles of infrastructure as code, where a configuration platform \textendash{} PowerShell DSC \textendash{} was used to automatically define reliable environments for continuous software delivery. In this context, we defined the concept of ``stage for dev'', also using the Docker technology, which involves all the elements that enable members of a team to have the same production environment, locally configured in their personal machines and thus empowering the continuous integration and delivery of system releases.},
  isbn = {978-3-030-29156-3},
  file = {/Users/awwillc/Zotero/storage/HVPUX9XR/Siebra et al. - 2019 - Empowering Continuous Delivery in Software Develop.pdf}
}

@inproceedings{siebraTheoryPracticeChallenges2018,
  title = {From {{Theory}} to {{Practice}}: {{The Challenges}} of a {{DevOps Infrastructure}} as {{Code Implementation}}},
  author = {Siebra, Clauirton and Lacerda, Rosberg and Quintino, Jonysberg and Cerqueira, Italo and Silva, Fabio and Santos, Andr{\'e}},
  year = {2018},
  month = jul,
  doi = {10.5220/0006826104270436},
  abstract = {DevOps is a recent approach that intends to improve the collaboration between development and IT operations teams, in order to establish a continuous and efficient deployment process. Previous studies show that DevOps is based on dimensions, such as culture of collaboration, automation and monitoring. However, few studies discuss the current frameworks that support such dimensions, so that there is a lack in information that could assist development teams in deciding for the most adequate framework according to their needs. This work aims at presenting a practical DevOps implementation and analysing how the process of software delivery and infrastructure changes was automated. Our approach follows the principles of infrastructure as code, where a configuration platform \textendash{} PowerShell DSC \textendash{} was used to automatically define reliable environments for continuous software delivery. Then, we compare this approach with other alternative such as Chef and Puppet tools, stressing the features, advantages and challenges of each strategy. The lessons learned from this work are then used to create a more concrete set of practices that could assist the transition from traditional approaches to an automation process of continuous software delivery.}
}

@article{sizilioneryEmpiricalStudyRelationship2019,
  title = {An {{Empirical Study}} of the {{Relationship}} between {{Continuous Integration}} and {{Test Code Evolution}}},
  author = {Sizilio Nery, Gustavo and {Alencar da Costa}, Daniel and Kulesza, Uira},
  year = {2019},
  month = sep,
  journal = {2019 IEEE International Conference on Software Maintenance and Evolution (ICSME), Software Maintenance and Evolution (ICSME), 2019 IEEE International Conference on},
  pages = {426--436},
  issn = {978-1-7281-3094-1},
  doi = {10/ghkb82},
  abstract = {Continuous Integration (CI) is the practice of automating and improving the frequency of code integration. CI has been widely adopted by software development teams and has brought the attention of researchers to study its benefits. Existing research shows that CI can improve software quality by identifying the errors earlier in the software development life-cycle. One question that remains open, however, is whether CI increases the adoption of testing practices in software projects. The goal of our work is to investigate the evolution of software tests and its relationship with the adoption of Continuous Integration. We set out to compare 82 projects that adopted CI (CI projects) and 82 projects that have never adopted CI (NOCI projects). In total, we studied 3,936 versions of our studied projects to investigate trends on the test code ratio and coverage. We observe that 40.2\% of the CI projects have a rising test-code ratio trend while only 17\% of the NOCI projects have a rising trend. Additionally, we find evidences that CI projects have improved the overall test coverage while NOCI projects do not experience the same growth. Finally, we build a mixed-effects model to study software development factors than can possibly explain the test ratio. Our models reveal that test ratio is largely explained by the project inherent context rather than code or process factors. In overall, our work demonstrates that Continuous Integration can be empirically associated with a healthier test code evolution.},
  keywords = {Computer bugs,Computing and Processing,Market research,Measurement,Productivity,Software quality,software testing; continuous integration; code coverage; empirical study,Testing},
  annotation = {mlzsync1:0036\{"extrafields":\{"publisher":"IEEE"\}\}}
}

@inproceedings{sjobergRelationshipSoftwareProcess2016,
  title = {The {{Relationship Between Software Process}}, {{Context}} and {{Outcome}}},
  booktitle = {Product-{{Focused Software Process Improvement}}},
  author = {Sj{\o}berg, Dag I. K.},
  editor = {Abrahamsson, Pekka and Jedlitschka, Andreas and Nguyen Duc, Anh and Felderer, Michael and Amasaki, Sousuke and Mikkonen, Tommi},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {3--11},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10/ghkb9n},
  abstract = {Most practitioners and researchers agree that when developing software, process affects product, and the usefulness of a process depends on the context. However, which processes are most useful for a specific company or project is generally unknown. When studying the relation between context, process and product, one challenge is that experiments often lack realism, which makes the transfer of results to industry difficult. In contrast, most of the important factors vary beyond the researcher's control in case studies, which makes it difficult to identify cause and effect relationships. This paper reports a study where realism was combined with control over certain context and process factors. Four companies developed the same system, and the price varied by a factor of six. Certain patterns of relationships were expected (expensive company, low cost, schedule overrun); others were unexpected (cheap company, maintainable system because of small code). The community needs to identify the most important relationships among process, context and outcome.},
  isbn = {978-3-319-49094-6},
  language = {en},
  keywords = {Controlled multiple-case study,Measurement,Software engineering folklore,Software industry,Software process improvement,Theory},
  file = {/Users/awwillc/Zotero/storage/WH9V6DFZ/Sjøberg - 2016 - The Relationship Between Software Process, Context.pdf}
}

@article{stewartEmpiricalApproachIdentifying2021,
  type = {Article},
  title = {An Empirical Approach to Identifying Employability Skills Required of Graduates in the Environmental Sciences},
  author = {Stewart, Barbara A.},
  year = {2021},
  month = apr,
  journal = {INDUSTRY AND HIGHER EDUCATION},
  volume = {35},
  number = {2},
  pages = {89--101},
  publisher = {{SAGE PUBLICATIONS LTD}},
  address = {{1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND}},
  issn = {0950-4222},
  doi = {10.1177/0950422220936869},
  abstract = {Universities are under pressure to produce work-ready graduates. This study analyzed 130 job advertisements to identify skills required by environmental science employers in Australia. For degree-related criteria, the most frequently required were content knowledge, a tertiary qualification and experience. Other desired skills were an understanding of environmental legislation, and an ability to undertake Geographical Information Systems (GIS) analysis, fieldwork, ecological surveys and species identification. For generic skills, more than half of advertisements required strong interpersonal, communication, writing and project management skills. It was concluded that universities should prioritize skills that occur most frequently in advertisements, and students should be given opportunities to participate in work experience. This would involve nurturing oral and written communication and teamwork skills, while equipping students with the ability to undertake ecological surveys in the field, identify important plants and animals, and conduct data analysis using GIS approaches. Senior undergraduate and postgraduate programs should include content on environmental policy and legislation, and the opportunity for students to hone their project and time management skills.},
  language = {English},
  keywords = {Degree-related skills,environmental sciences,generic skills,graduate employability,job advertisements}
}

@article{stoddenEmpiricalAnalysisJournal2018,
  title = {An Empirical Analysis of Journal Policy Effectiveness for Computational Reproducibility},
  author = {Stodden, Victoria and Seiler, Jennifer and Ma, Zhaokun},
  year = {2018},
  journal = {Proceedings of the National Academy of Sciences of the United States},
  number = {11},
  pages = {2584},
  issn = {0027-8424},
  doi = {10/gc8gkw},
  abstract = {A key component of scientific communication is sufficient information for other researchers in the field to reproduce published findings. For computational and data-enabled research, this has often been interpreted to mean making available the raw data from which results were generated, the computer code that generated the findings, and any additional information needed such as workflows and input parameters. Many journals are revising author guidelines to include data and code availability. This work evaluates the effectiveness of journal policy that requires the data and code necessary for reproducibility be made available postpublication by the authors upon request. We assess the effectiveness of such a policy by (i) requesting data and code from authors and (ii) attempting replication of the published findings. We chose a random sample of 204 scientific papers published in the journal Science after the implementation of their policy in February 2011. We found that we were able to obtain artifacts from 44\% of our sample and were able to reproduce the findings for 26\%. We find this policy--author remission of data and code postpublication upon request--an improvement over no policy, but currently insufficient for reproducibility. reproducible research | data access | code access | reproducibility policy | open science},
  keywords = {Communication in science -- Methods,Electronic data processing -- Methods,Scholarly publishing -- Methods},
  annotation = {mlzsync1:0060\{"extrafields":\{"publisher":"National Academy of Sciences"\}\} QID: Q52659627},
  file = {/Users/awwillc/Zotero/storage/JRJ34Z77/Stodden et al. - 2018 - An empirical analysis of journal policy effectiven.pdf}
}

@article{stoddenReproducibleComputationalResearch2013,
  title = {Toward {{Reproducible Computational Research}}: {{An Empirical Analysis}} of {{Data}} and {{Code Policy Adoption}} by {{Journals}}.},
  author = {Stodden, Victoria and Guo, Peixuan and Ma, Zhaokun},
  year = {2013},
  month = jun,
  journal = {PLoS ONE},
  volume = {8},
  number = {6},
  pages = {1--8},
  issn = {19326203},
  abstract = {Journal policy on research data and code availability is an important part of the ongoing shift toward publishing reproducible computational science. This article extends the literature by studying journal data sharing policies by year (for both 2011 and 2012) for a referent set of 170 journals. We make a further contribution by evaluating code sharing policies, supplemental materials policies, and open access status for these 170 journals for each of 2011 and 2012. We build a predictive model of open data and code policy adoption as a function of impact factor and publisher and find higher impact journals more likely to have open data and code policies and scientific societies more likely to have open data and code policies than commercial publishers. We also find open data policies tend to lead open code policies, and we find no relationship between open data and code policies and either supplemental material policies or open access journal status. Of the journals in this study, 38\% had a data policy, 22\% had a code policy, and 66\% had a supplemental materials policy as of June 2012. This reflects a striking one year increase of 16\% in the number of data policies, a 30\% increase in code policies, and a 7\% increase in the number of supplemental materials policies. We introduce a new dataset to the community that categorizes data and code sharing, supplemental materials, and open access policies in 2011 and 2012 for these 170 journals. [ABSTRACT FROM AUTHOR]},
  keywords = {⛔ No DOI found,Biological data management,Biology,Communications,Computational biology,Computer science,Databases,DATABASES,EMPIRICAL research,Information science,Information storage and retrieval,Information technology,Intellectual property,LITERATURE,Mathematics,Peer review,PREDICTION models,Publication ethics,Publication practices,PUBLICATIONS,PUBLISHING,Reproducibility,Research Article,Research assessment,Research integrity,Research monitoring,Research reporting guidelines,Research validity,SCIENCE \& state,Science policy,Social and behavioral sciences,Statistics,Technology development},
  annotation = {mlzsync1:0057\{"extrafields":\{"publisher":"Public Library of Science"\}\} QID: Q27826355}
}

@article{strozziScalableWorkflowsReproducible2019,
  title = {Scalable {{Workflows}} and {{Reproducible Data Analysis}} for {{Genomics}}},
  author = {Strozzi, Francesco and Janssen, Roel and Wurmus, Ricardo and Crusoe, Michael R. and Githinji, George and Di Tommaso, Paolo and Belhachemi, Dominique and M{\"o}ller, Steffen and Smant, Geert and {de Ligt}, Joep and Prins, Pjotr},
  year = {2019},
  journal = {Methods in Molecular Biology (Clifton, N.J.)},
  volume = {1910},
  pages = {723--745},
  issn = {1940-6029},
  doi = {10/ggv5zh},
  abstract = {Biological, clinical, and pharmacological research now often involves analyses of genomes, transcriptomes, proteomes, and interactomes, within and between individuals and across species. Due to large volumes, the analysis and integration of data generated by such high-throughput technologies have become computationally intensive, and analysis can no longer happen on a typical desktop computer.In this chapter we show how to describe and execute the same analysis using a number of workflow systems and how these follow different approaches to tackle execution and reproducibility issues. We show how any researcher can create a reusable and reproducible bioinformatics pipeline that can be deployed and run anywhere. We show how to create a scalable, reusable, and shareable workflow using four different workflow engines: the Common Workflow Language (CWL), Guix Workflow Language (GWL), Snakemake, and Nextflow. Each of which can be run in parallel.We show how to bundle a number of tools used in evolutionary biology by using Debian, GNU Guix, and Bioconda software distributions, along with the use of container systems, such as Docker, GNU Guix, and Singularity. Together these distributions represent the overall majority of software packages relevant for biology, including PAML, Muscle, MAFFT, MrBayes, and BLAST. By bundling software in lightweight containers, they can be deployed on a desktop, in the cloud, and, increasingly, on compute clusters.By bundling software through these public software distributions, and by creating reproducible and shareable pipelines using these workflow engines, not only do bioinformaticians have to spend less time reinventing the wheel but also do we get closer to the ideal of making science reproducible. The examples in this chapter allow a quick comparison of different solutions.},
  language = {eng},
  pmid = {31278683},
  keywords = {Big data,Big Data,Bioconda,Bioinformatics,Biological Evolution,Cloud computing,Cloud Computing,Cluster computing,Common Workflow Language,Computational Biology,CWL,Data Analysis,Debian Linux,Evolutionary biology,Genomics,GNU Guix,Guix Workflow Language,Humans,MPI,MrBayes,Nextflow,Parallelization,Reproducibility of Results,Snakemake,Software,Virtual machine,Workflow},
  annotation = {QID: Q91668892},
  file = {/Users/awwillc/Zotero/storage/9UMVJQWW/Strozzi et al. - 2019 - Scalable Workflows and Reproducible Data Analysis .pdf}
}

@article{tenopirChangesDataSharing2015,
  title = {Changes in {{Data Sharing}} and {{Data Reuse Practices}} and {{Perceptions}} among {{Scientists Worldwide}}},
  author = {Tenopir, Carol and Dalton, Elizabeth D. and Allard, Suzie and Frame, Mike and Pjesivac, Ivanka and Birch, Ben and Pollock, Danielle and Dorsett, Kristina},
  year = {2015},
  month = aug,
  journal = {PLOS ONE},
  volume = {10},
  number = {8},
  pages = {e0134826},
  publisher = {{Public Library of Science}},
  doi = {10/8fw},
  abstract = {The incorporation of data sharing into the research lifecycle is an important part of modern scholarly debate. In this study, the DataONE Usability and Assessment working group addresses two primary goals: To examine the current state of data sharing and reuse perceptions and practices among research scientists as they compare to the 2009/2010 baseline study, and to examine differences in practices and perceptions across age groups, geographic regions, and subject disciplines. We distributed surveys to a multinational sample of scientific researchers at two different time periods (October 2009 to July 2010 and October 2013 to March 2014) to observe current states of data sharing and to see what, if any, changes have occurred in the past 3\textendash 4 years. We also looked at differences across age, geographic, and discipline-based groups as they currently exist in the 2013/2014 survey. Results point to increased acceptance of and willingness to engage in data sharing, as well as an increase in actual data sharing behaviors. However, there is also increased perceived risk associated with data sharing, and specific barriers to data sharing persist. There are also differences across age groups, with younger respondents feeling more favorably toward data sharing and reuse, yet making less of their data available than older respondents. Geographic differences exist as well, which can in part be understood in terms of collectivist and individualist cultural differences. An examination of subject disciplines shows that the constraints and enablers of data sharing and reuse manifest differently across disciplines. Implications of these findings include the continued need to build infrastructure that promotes data sharing while recognizing the needs of different research communities. Moving into the future, organizations such as DataONE will continue to assess, monitor, educate, and provide the infrastructure necessary to support such complex grand science challenges.},
  file = {/Users/awwillc/Zotero/storage/4VVXQ2G2/Tenopir et al. - 2015 - Changes in Data Sharing and Data Reuse Practices a.pdf}
}

@article{tenopirDataSharingScientists2011,
  title = {Data {{Sharing}} by {{Scientists}}: {{Practices}} and {{Perceptions}}},
  author = {Tenopir, Carol and Allard, Suzie and Douglass, Kimberly and Aydinoglu, Arsev Umur and Wu, Lei and Read, Eleanor and Manoff, Maribeth and Frame, Mike},
  year = {2011},
  month = jun,
  journal = {PLOS ONE},
  volume = {6},
  number = {6},
  pages = {e21101},
  publisher = {{Public Library of Science}},
  doi = {10/fgppw4},
  abstract = {Background Scientific research in the 21st century is more data intensive and collaborative than in the past. It is important to study the data practices of researchers \textendash{} data accessibility, discovery, re-use, preservation and, particularly, data sharing. Data sharing is a valuable part of the scientific method allowing for verification of results and extending research from prior results.   Methodology/Principal Findings A total of 1329 scientists participated in this survey exploring current data sharing practices and perceptions of the barriers and enablers of data sharing. Scientists do not make their data electronically available to others for various reasons, including insufficient time and lack of funding. Most respondents are satisfied with their current processes for the initial and short-term parts of the data or research lifecycle (collecting their research data; searching for, describing or cataloging, analyzing, and short-term storage of their data) but are not satisfied with long-term data preservation. Many organizations do not provide support to their researchers for data management both in the short- and long-term. If certain conditions are met (such as formal citation and sharing reprints) respondents agree they are willing to share their data. There are also significant differences and approaches in data management practices based on primary funding agency, subject discipline, age, work focus, and world region.   Conclusions/Significance Barriers to effective data sharing and preservation are deeply rooted in the practices and culture of the research process as well as the researchers themselves. New mandates for data management plans from NSF and other federal agencies and world-wide attention to the need to share and preserve data could lead to changes. Large scale programs, such as the NSF-sponsored DataNET (including projects like DataONE) will both bring attention and resources to the issue and make it easier for scientists to apply sound data management principles.},
  file = {/Users/awwillc/Zotero/storage/CJEK4PWV/Tenopir et al. - 2011 - Data Sharing by Scientists Practices and Percepti.pdf}
}

@misc{TestAllThings,
  title = {Test All the Things in {{GitLab CI}} with {{Docker}} by Example},
  journal = {GitLab},
  abstract = {Running tests is easier than you think \textendash{} guest author Gabriel Le Breton shares his presentation about testing everything automatically with GitLab CI/CD.},
  howpublished = {https://about.gitlab.com/blog/2018/02/05/test-all-the-things-gitlab-ci-docker-examples/},
  language = {en},
  file = {/Users/awwillc/Zotero/storage/2LNB7ZKZ/test-all-the-things-gitlab-ci-docker-examples.html}
}

@misc{TitleDevOps101,
  title = {Title: {{DevOps}} 101: {{Continuous Delivery}}},
  shorttitle = {Title},
  abstract = {Found on Google from davidtucker.net},
  howpublished = {https://www.google.com.au/imgres},
  language = {en},
  keywords = {DevOps,workflow},
  file = {/Users/awwillc/Zotero/storage/CXWIH5YW/imgres.html}
}

@misc{TitleWhatDevOps,
  title = {Title: {{What}} Is {{DevOps}}, {{It}}'s {{Working}}, {{Benefits}}, {{Tools}} in {{Detail}}},
  shorttitle = {Title},
  abstract = {Found on Google from dotnettricks.com},
  howpublished = {https://www.google.com.au/imgres},
  language = {en},
  keywords = {DevOps},
  file = {/Users/awwillc/Zotero/storage/8WQMRE2L/imgres.html}
}

@misc{ToolsManagingRSE2018,
  title = {Tools for Managing {{RSE}} Projects},
  year = {2018},
  month = may,
  journal = {Research Software Engineers International},
  abstract = {Managing an RSE team can involve carrying out a broad range of tasks relating to the management of people and projects. The exact nature of these tasks will depend on the size of team, and the how the leadership role is defined within any particular institution, but they typically include scheduling, resource allocation, reporting, communication, task management and record keeping. Our discussion at the RSE Leaders Workshop in January 2018 focused on sharing knowledge about effective tools for managing these processes.},
  howpublished = {https://researchsoftware.org/2018/05/04/rse-project-management-tools.html},
  language = {en},
  keywords = {Research Software Engineering},
  file = {/Users/awwillc/Zotero/storage/MNN7J9UG/rse-project-management-tools.html}
}

@article{ToolsTechniquesComputational2016,
  title = {Tools and Techniques for Computational Reproducibility.},
  year = {2016},
  month = dec,
  journal = {GigaScience},
  volume = {5},
  number = {1},
  pages = {1--13},
  issn = {2047217X},
  abstract = {When reporting research findings, scientists document the steps they followed so that others can verify and build upon the research. When those steps have been described in sufficient detail that others can retrace the steps and obtain similar results, the research is said to be reproducible. Computers play a vital role in many research disciplines and present both opportunities and challenges for reproducibility. Computers can be programmed to execute analysis tasks, and those programs can be repeated and shared with others. The deterministic nature of most computer programs means that the same analysis tasks, applied to the same data, will often produce the same outputs. However, in practice, computational findings often cannot be reproduced because of complexities in how software is packaged, installed, and executed\textemdash and because of limitations associated with how scientists document analysis steps. Many tools and techniques are available to help overcome these challenges; here we describe seven such strategies. With a broad scientific audience in mind, we describe the strengths and limitations of each approach, as well as the circumstances under which each might be applied. No single strategy is sufficient for every scenario; thus we emphasize that it is often useful to combine approaches. [ABSTRACT FROM AUTHOR]},
  keywords = {⛔ No DOI found,Computational reproducibility,Literate programming,LITERATE programming,Practice of science,REPRODUCIBLE research,Software containers,Software frameworks,SOFTWARE frameworks,Virtualization},
  annotation = {QID: Q29002201}
}

@book{trimbleTraditionalLeanAgile2013,
  title = {From {{Traditional}}, to {{Lean}}, to {{Agile Development}}: {{Finding}} the {{Optimal Software Engineering Cycle}}},
  author = {Trimble, Jay and Webster, Christopher},
  year = {2013},
  month = jan,
  pages = {4833},
  doi = {10.1109/HICSS.2013.237},
  abstract = {In 2008, our team at NASA Ames Research Center launched a five-year project to deliver a user-centric software platform for mission control. We began with a six-month delivery cycle. Within two years we were delivering functional software every three weeks. Our evolution from traditional, to lean, then agile, did not happen because of a focused goal to become lean or agile. Rather, we responded iteratively to problems, we were disconnected from our customer, the long delivery cycles created issues with testing and verification, and we were unable to effectively measure our progress. We changed our delivery cycle first to six weeks, then three, with the team focused on the highest-priority features and bug fixes. Our one measure of progress became working code. We delivered a nightly build to our customer. Our QA team tested features as they rolled out. In our journey from traditional to agile, we tailored our processes to our team culture and our context of work. We found that agile methods increased customer and team satisfaction, and enabled us to use limited team resources where they were most effective -- the design and development of the software.},
  isbn = {978-1-4673-5933-7}
}

@article{vanatteveldtOpenComputationalCommunication2019,
  title = {Toward {{Open Computational Communication Science}}: {{A Practical Road Map}} for {{Reusable Data}} and {{Code}}.},
  author = {VAN ATTEVELDT, WOUTER and STRYCHARZ, JOANNA and TRILLING, DAMIAN and WELBERS, KASPER},
  year = {2019},
  month = jan,
  journal = {International Journal of Communication (19328036)},
  volume = {13},
  pages = {3935--3954},
  issn = {19328036},
  abstract = {Computational communication science (CCS) offers an opportunity to accelerate the scope and pace of discovery in communication research. This article argues that CCS will profit from adopting open science practices by fostering the reusability of data and code. We discuss the goals and challenges related to creating reusable data and code and offer practical guidance to individual researchers to achieve this. More specifically, we argue for integration of the research process into reusable workflows and recognition of tools and data as academic work. The challenges and road map are also critically discussed in terms of the additional burden they place on individual scholars, which culminates in a call to action for the field to support and incentivize the reusability of tools and data. [ABSTRACT FROM AUTHOR]},
  keywords = {⛔ No DOI found,Communication,computational communication science,Computer software reusability,Databases,open science,reproducibility,Reproducible research,reusability,Tools,workflow,Workflow},
  annotation = {mlzsync1:0086\{"extrafields":\{"publisher":"University of Southern California, USC Annenberg Press"\}\}}
}

@article{vanatteveldtOpenComputationalCommunication2019a,
  title = {Toward {{Open Computational Communication Science}}: {{A Practical Road Map}} for {{Reusable Data}} and {{Code}}.},
  author = {VAN ATTEVELDT, WOUTER and STRYCHARZ, JOANNA and TRILLING, DAMIAN and WELBERS, KASPER},
  year = {2019},
  month = jan,
  journal = {International Journal of Communication (19328036)},
  volume = {13},
  pages = {3935--3954},
  issn = {19328036},
  abstract = {Computational communication science (CCS) offers an opportunity to accelerate the scope and pace of discovery in communication research. This article argues that CCS will profit from adopting open science practices by fostering the reusability of data and code. We discuss the goals and challenges related to creating reusable data and code and offer practical guidance to individual researchers to achieve this. More specifically, we argue for integration of the research process into reusable workflows and recognition of tools and data as academic work. The challenges and road map are also critically discussed in terms of the additional burden they place on individual scholars, which culminates in a call to action for the field to support and incentivize the reusability of tools and data. [ABSTRACT FROM AUTHOR]},
  keywords = {⛔ No DOI found,Communication,computational communication science,Computer software reusability,Databases,open science,reproducibility,Reproducible research,reusability,Tools,workflow,Workflow},
  annotation = {mlzsync1:0086\{"extrafields":\{"publisher":"University of Southern California, USC Annenberg Press"\}\}},
  file = {/Users/awwillc/Zotero/storage/UIFMT992/VAN ATTEVELDT et al. - 2019 - Toward Open Computational Communication Science A.pdf}
}

@article{vuorreSharingOrganizingResearch2020,
  title = {Sharing and Organizing Research Products as {{R}} Packages},
  author = {Vuorre, Matti and Crump, Matthew},
  year = {2020},
  month = sep,
  journal = {Behavior Research Methods},
  pages = {1--11},
  doi = {10/gg9w4c},
  abstract = {A consensus on the importance of open data and reproducible code is emerging. How should data and code be shared to maximize the key desiderata of reproducibility, permanence, and accessibility? Research assets should be stored persistently in formats that are not software restrictive, and documented so that others can reproduce and extend the required computations. The sharing method should be easy to adopt by already busy researchers. We suggest the R package standard as a solution for creating, curating, and communicating research assets. The R package standard, with extensions discussed herein, provides a format for assets and metadata that satisfies the above desiderata, facilitates reproducibility, open access, and sharing of materials through online platforms like GitHub and Open Science Framework. We discuss a stack of R resources that help users create reproducible collections of research assets, from experiments to manuscripts, in the RStudio interface. We created an R package, vertical, to help researchers incorporate these tools into their workflows, and discuss its functionality at length in an online supplement. Together, these tools may increase the reproducibility and openness of psychological science.},
  annotation = {QID: Q98896402},
  file = {/Users/awwillc/Zotero/storage/PFDE9T7P/Vuorre and Crump - 2020 - Sharing and organizing research products as R pack.pdf}
}

@article{vuorreSharingOrganizingResearch2020a,
  title = {Sharing and Organizing Research Products as {{R}} Packages},
  author = {Vuorre, Matti and Crump, Matthew},
  year = {2020},
  month = sep,
  journal = {Behavior Research Methods},
  pages = {1--11},
  doi = {10/gg9w4c},
  abstract = {A consensus on the importance of open data and reproducible code is emerging. How should data and code be shared to maximize the key desiderata of reproducibility, permanence, and accessibility? Research assets should be stored persistently in formats that are not software restrictive, and documented so that others can reproduce and extend the required computations. The sharing method should be easy to adopt by already busy researchers. We suggest the R package standard as a solution for creating, curating, and communicating research assets. The R package standard, with extensions discussed herein, provides a format for assets and metadata that satisfies the above desiderata, facilitates reproducibility, open access, and sharing of materials through online platforms like GitHub and Open Science Framework. We discuss a stack of R resources that help users create reproducible collections of research assets, from experiments to manuscripts, in the RStudio interface. We created an R package, vertical, to help researchers incorporate these tools into their workflows, and discuss its functionality at length in an online supplement. Together, these tools may increase the reproducibility and openness of psychological science.},
  annotation = {QID: Q98896402}
}

@article{Weissgerber2021,
  title = {Null and Void? {{Errors}} in Meta-Analysis on Perceptual Disfluency and Recommendations to Improve Meta-Analytical Reproducibility},
  author = {Weissgerber, S.C. and Brunmair, M. and Rummer, R.},
  year = {2021},
  journal = {Educational Psychology Review},
  publisher = {{Springer}},
  issn = {1040726X},
  doi = {10.1007/s10648-020-09579-1},
  abbrev_source_title = {Educ. Psychol. Rev.},
  abstract = {In the 2018 meta-analysis of Educational Psychology Review entitled ``Null effects of perceptual disfluency on learning outcomes in a text-based educational context'' by Xie, Zhou, and Liu, we identify some errors and inconsistencies in both the methodological approach and the reported results regarding coding and effect sizes. While from a technical point of view the meta-analysis aligns with current meta-analytical guidelines (e.g., PRISMA) and conforms to general meta-analytical requirements (e.g., considering publication bias), it exemplifies certain insufficient practices in the creation and review of meta-analysis. We criticize the lack of transparency and negligence of open-science practices in the generation and reporting of results, which complicate evaluation of the meta-analytical reproducibility, especially given the flexibility in subjective choices regarding the analytical approach and the flexibility in creating the database. Here we present a framework applicable to pre- and post-publication review on improving the Methods Reproducibility of meta-analysis. Based on considerations of the transparency and openness (TOP)-guidlines (Nosek et al. Science 348: 1422\textendash 1425, 2015), the Reproducibility Enhancement Principles (REP; Stodden et al. Science 354:1240\textendash 1241, 2016), and recommendations by Lakens et al. (BMC Psychology 4: Article 24, 2016), we outline Computational Reproducibility (Level 1), Computational Verification (Level 2), Analysis Reproducibility (Level 3), and Outcome Reproducibility (Level 4). Applying reproducibility checks to TRANSFER performance as the chosen outcome variable, we found Xie's and colleagues' results to be (rather) robust. Yet, regarding RECALL performance and the moderator analysis, the identified problems raise doubts about the credibility of the reported results. \textcopyright{} 2021, The Author(s).},
  affiliation = {Institute of Psychology, Department of Cognitive Psychology, University of Kassel, Holl\"andische Str. 36-38, Kassel, 34127, Germany; University of W\"urzburg, R\"ontgenring 10, W\"urzburg, 97070, Germany},
  author_keywords = {Disfluency effect; Meta-analytical standards; Open-science; Reproducibility; Transparency},
  correspondence_address1 = {Weissgerber, S.C.; Institute of Psychology, Holl\"andische Str. 36-38, Germany; email: scweissgerber@uni-kassel.de},
  document_type = {Note},
  language = {English},
  source = {Scopus},
  file = {/Users/awwillc/Zotero/storage/QUX2JBG9/Weissgerber et al. - 2021 - Null and void Errors in meta-analysis on perceptu.pdf}
}

@article{whiteDevelopingAutomatedIterative2019,
  title = {Developing an Automated Iterative Near-Term Forecasting System for an Ecological Study},
  author = {White, Ethan P. and Yenni, Glenda M. and Taylor, Shawn D. and Christensen, Erica M. and Bledsoe, Ellen K. and Simonis, Juniper L. and Ernest, S. K. Morgan},
  year = {2019},
  journal = {Methods in Ecology and Evolution},
  volume = {10},
  number = {3},
  pages = {332--344},
  issn = {2041-210X},
  doi = {10/gfknh6},
  abstract = {Most forecasts for the future state of ecological systems are conducted once and never updated or assessed. As a result, many available ecological forecasts are not based on the most up-to-date data, and the scientific progress of ecological forecasting models is slowed by a lack of feedback on how well the forecasts perform. Iterative near-term ecological forecasting involves repeated daily to annual scale forecasts of an ecological system as new data becomes available and regular assessment of the resulting forecasts. We demonstrate how automated iterative near-term forecasting systems for ecology can be constructed by building one to conduct monthly forecasts of rodent abundances at the Portal Project, a long-term study with over 40 years of monthly data. This system automates most aspects of the six stages of converting raw data into new forecasts: data collection, data sharing, data manipulation, modelling and forecasting, archiving, and presentation of the forecasts. The forecasting system uses R code for working with data, fitting models, making forecasts, and archiving and presenting these forecasts. The resulting pipeline is automated using continuous integration (a software development tool) to run the entire pipeline once a week. The cyberinfrastructure is designed for long-term maintainability and to allow the easy addition of new models. Constructing this forecasting system required a team with expertise ranging from field site experience to software development. Automated near-term iterative forecasting systems will allow the science of ecological forecasting to advance more rapidly and provide the most up-to-date forecasts possible for conservation and management. These forecasting systems will also accelerate basic science by allowing new models of natural systems to be quickly implemented and compared to existing models. Using existing technology, and teams with diverse skill sets, it is possible for ecologists to build automated forecasting systems and use them to advance our understanding of natural systems.},
  copyright = {\textcopyright{} 2018 The Authors. Methods in Ecology and Evolution  published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
  language = {en},
  keywords = {forecasting,iterative forecasting,mammals,Portal Project,prediction},
  annotation = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13104},
  file = {/Users/awwillc/Zotero/storage/BPJRE4P2/White et al. - 2019 - Developing an automated iterative near-term foreca.pdf;/Users/awwillc/Zotero/storage/KIBVQ5MW/2041-210X.html}
}

@article{wiedemannResearchPracticeDevOps2019,
  title = {Research for {{Practice}}. {{The DevOps Phenomenon}}},
  author = {Wiedemann, Anna and Forsgren, Nicole and Wiesche, Manuel and Gewald, Heiko and Krcmar, Helmut},
  year = {2019},
  month = aug,
  journal = {COMMUNICATIONS OF THE ACM},
  volume = {62},
  number = {8},
  pages = {44--49},
  issn = {00010782},
  doi = {10/ghkb9w},
  file = {/Users/awwillc/Zotero/storage/6EGW5DDV/Wiedemann et al. - 2019 - Research for Practice. The DevOps Phenomenon.pdf}
}

@article{wilsonGoodEnoughPractices2017,
  title = {Good Enough Practices in Scientific Computing},
  author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
  year = {2017},
  month = jun,
  journal = {PLOS Computational Biology},
  volume = {13},
  number = {6},
  pages = {e1005510},
  publisher = {{Public Library of Science}},
  doi = {10.1371/journal.pcbi.1005510},
  abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
  file = {/Users/awwillc/Zotero/storage/LILUPIX9/Wilson et al. - 2017 - Good enough practices in scientific computing.pdf}
}

@article{wittmanGuideToolboxReplicability2020,
  title = {A {{Guide}} and {{Toolbox}} to {{Replicability}} and {{Open Science}} in {{Entomology}}},
  author = {Wittman, Jacob and Aukema, Brian},
  year = {2020},
  month = may,
  journal = {Journal of insect science (Online)},
  volume = {20},
  doi = {10/ghkb9q},
  abstract = {The ability to replicate scientific experiments is a cornerstone of the scientific method. Sharing ideas, workflows, data, and protocols facilitates testing the generalizability of results, increases the speed that science progresses, and enhances quality control of published work. Fields of science such as medicine, the social sciences, and the physical sciences have embraced practices designed to increase replicability. Granting agencies, for example, may require data management plans and journals may require data and code availability statements along with the deposition of data and code in publicly available repositories. While many tools commonly used in replicable workflows such as distributed version control systems (e.g., 'git') or script programming languages for data cleaning and analysis may have a steep learning curve, their adoption can increase individual efficiency and facilitate collaborations both within entomology and across disciplines. The open science movement is developing within the discipline of entomology, but practitioners of these concepts or those desiring to work more collaboratively across disciplines may be unsure where or how to embrace these initiatives. This article is meant to introduce some of the tools entomologists can incorporate into their workflows to increase the replicability and openness of their work. We describe these tools and others, recommend additional resources for learning more about these tools, and discuss the benefits to both individuals and the scientific community and potential drawbacks associated with implementing a replicable workflow.},
  annotation = {QID: Q95645507},
  file = {/Users/awwillc/Zotero/storage/HJP2I34Q/Wittman and Aukema - 2020 - A Guide and Toolbox to Replicability and Open Scie.pdf}
}

@article{yadavPerformanceComparisonVirtual2018,
  title = {Performance {{Comparison Between Virtual Machines}} and {{Docker Containers}}.},
  author = {Yadav, R. R. and Sousa, E. T. G. and Callou, G. R. A.},
  year = {2018},
  month = aug,
  journal = {IEEE Latin America Transactions},
  volume = {16},
  number = {8},
  pages = {2282},
  issn = {15480992},
  doi = {10/ghkb94},
  abstract = {Containers emerged as a new alternative to the virtual machines in large enterprise systems due to their virtualization mechanism that demands a low utilization level of the computational resources. Performance evaluation of Containers and virtual machines provides to practitioners and system administrators information about the quality of the services provisioned for virtualization. The main goal of this paper is to conduct a comparative study of the performance evaluation of virtual machines and containers. In order to accomplish this, a methodology is proposed to evaluate the performance of Docker containers and virtual machines. Additionally, a real-world case study is presented to illustrate the applicability of the proposed approach. For all the experiments, the Docker container shown lower execution times for the requests against virtual machine. [ABSTRACT FROM AUTHOR]},
  keywords = {Benchmark testing,Containers,IEEE transactions,Performance evaluation,Random access memory,Virtual machine monitors,Virtual Machines,Virtual machining}
}

@article{yasminalnoamanyComputationalReproducibilityResearcher2018,
  title = {Towards Computational Reproducibility: Researcher Perspectives on the Use and Sharing of Software},
  author = {{Yasmin AlNoamany} and {John A. Borghi}},
  year = {2018},
  month = sep,
  journal = {PeerJ Computer Science},
  volume = {4},
  pages = {e163-e163},
  issn = {2376-5992},
  doi = {10/ghkb9j},
  abstract = {Research software, which includes both source code and executables used as part of the research process, presents a significant challenge for efforts aimed at ensuring reproducibility. In order to inform such efforts, we conducted a survey to better understand the characteristics of research software as well as how it is created, used, and shared by researchers. Based on the responses of 215 participants, representing a range of research disciplines, we found that researchers create, use, and share software in a wide variety of forms for a wide variety of purposes, including data collection, data analysis, data visualization, data cleaning and organization, and automation. More participants indicated that they use open source software than commercial software. While a relatively small number of programming languages (e.g., Python, R, JavaScript, C++, MATLAB) are used by a large number, there is a long tail of languages used by relatively few. Between-group comparisons revealed that significantly more participants from computer science write source code and create executables than participants from other disciplines. Differences between researchers from computer science and other disciplines related to the knowledge of best practices of software creation and sharing were not statistically significant. While many participants indicated that they draw a distinction between the sharing and preservation of software, related practices and perceptions were often not aligned with those of the broader scholarly communications community.},
  keywords = {Code,Electronic computers. Computer science,Finding software,QA75.5-76.95,Reproducibility,Research software,Sharing software,Software sustainability},
  annotation = {mlzsync1:0042\{"extrafields":\{"publisher":"PeerJ Inc."\}\}tex.ids: alnoamanyComputationalReproducibilityResearcher2018},
  file = {/Users/awwillc/Zotero/storage/KYIUN9D6/Yasmin AlNoamany and John A. Borghi - 2018 - Towards computational reproducibility researcher .pdf}
}

@article{yenniDevelopingModernData2019,
  title = {Developing a Modern Data Workflow for Regularly Updated Data.},
  author = {Yenni, Glenda M. and Christensen, Erica M. and Bledsoe, Ellen K. and Supp, Sarah R. and Diaz, Renata M. and White, Ethan P. and Ernest, S. K. Morgan},
  year = {2019},
  month = jan,
  journal = {PLoS Biology},
  volume = {17},
  number = {1},
  pages = {1--12},
  issn = {15449173},
  abstract = {Over the past decade, biology has undergone a data revolution in how researchers collect data and the amount of data being collected. An emerging challenge that has received limited attention in biology is managing, working with, and providing access to data under continual active collection. Regularly updated data present unique challenges in quality assurance and control, data publication, archiving, and reproducibility. We developed a workflow for a long-term ecological study that addresses many of the challenges associated with managing this type of data. We do this by leveraging existing tools to 1) perform quality assurance and control; 2) import, restructure, version, and archive data; 3) rapidly publish new data in ways that ensure appropriate credit to all contributors; and 4) automate most steps in the data pipeline to reduce the time and effort required by researchers. The workflow leverages tools from software development, including version control and continuous integration, to create a modern data management system that automates the pipeline. [ABSTRACT FROM AUTHOR]},
  keywords = {⛔ No DOI found,ACQUISITION of data,Archives,Biological data management,Biology and life sciences,Careers in research,Community Page,Computational biology,Computer and information sciences,Data management,Databases,DATABASES,Engineering and technology,Industrial engineering,INDUSTRIAL engineering,Information centers,Information technology,People and places,Population groupings,Professions,Programming languages,Quality control,QUALITY control,Reproducibility,Research and analysis methods,Research assessment,Research facilities,Science and technology workforce,Science policy,Scientists,WORKFLOW},
  annotation = {mlzsync1:0057\{"extrafields":\{"publisher":"Public Library of Science"\}\} QID: Q63607824},
  file = {/Users/awwillc/Zotero/storage/KURGI2LQ/Yenni et al. - 2019 - Developing a modern data workflow for regularly up.pdf}
}


